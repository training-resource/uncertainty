[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "REDD+ Uncertainty",
    "section": "",
    "text": "Preface",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "REDD+ Uncertainty",
    "section": "Overview",
    "text": "Overview\nThis resource provides methodological guidance for quantifying, reporting, and reducing uncertainty in REDD+ carbon accounting under IPCC 2019 Refinements and ART-TREES Standard V2.0 (ART, 2021; IPCC, 2019). Rather than viewing uncertainty as merely a penalty, this framework treats it as a strategic tool for identifying dominant error sources and optimizing credit issuance (Camara et al., 2024; Duncanson et al., 2021; Simoes et al., 2021).\nProjects investing in targeted uncertainty reduction can achieve 5-15% more credits through reduced deductions, premium pricing from enhanced credibility, lower verification costs, and methodological improvements. However, monitoring costs must be weighed against credit value (Köhler & Huth, 2010).\nCurrent State of Practice\nState-of-the-art evaluations reveal systematic gaps in how REDD+ countries quantify and report uncertainty. While 91% of participating countries report activity data uncertainty, only 4-14% report emission factor uncertainty and allometric uncertainty (Butler et al., 2024). This asymmetry does not reflect the actual relative importance of these sources. Research has demonstrated that methodological choices in emission factors and modelling assumptions can produce emission flux variations ranging from 4.2% to 262.2% of reference levels (J. Pelletier et al., 2013). Rather than technical limitations alone, such selective reporting reveals a worrying misalignment between rigor and financial incentives in results-based payment systems.\nThe Perverse Incentive\nButler et al. (2024) described this critical policy failure of selective uncertainty reporting as a kind of perverse incentive: “Because uncertainty factors into the payments made, there is a perverse incentive for countries to omit or underestimate sources of uncertainty. Including more sources of uncertainty makes the confidence intervals wider, giving a false impression that the quality of the estimates is worse.” This creates a troubling paradox where comprehensive uncertainty assessment, the hallmark of rigorous science, leads to wider confidence intervals and consequently lower payments, while incomplete uncertainty assessment produces narrower confidence intervals and higher payments. Countries are effectively penalized for methodological rigor and transparency, incentivizing selective reporting that undermines the environmental integrity of the entire REDD+ framework.\nRecognizing this fundamental design flaw, some results-based payment programs have implemented mitigation strategies to realign incentives. The FCPF Carbon Fund cap uncertainty deductions at a maximum threshold to limit incentive to underreport. This cap removes the direct penalty for comprehensive reporting while maintaining pressure to reduce actual uncertainty over time. Additionally, programs such as the ART-TREES registry reward demonstrable improvements by allowing participants to recover over-deducted credits when cumulative uncertainty decreases across multi-year crediting periods, creating positive incentives for methodological refinement.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#uncertainty-requirements",
    "href": "index.html#uncertainty-requirements",
    "title": "REDD+ Uncertainty",
    "section": "Uncertainty Requirements",
    "text": "Uncertainty Requirements\nART-TREES Requirements\nSection 8 of the ART Standard mandates the following criteria:\n\nMonte Carlo simulations: Minimum 10,000 iterations for uncertainty propagation\n90% confidence intervals: Half-width calculation for adjustment factors\nConservative bias: Systematic underestimation acceptable, overestimation prohibited\nWhole-chain integration: Combine activity data + emission factor uncertainties\nCrediting period aggregation: Flexibility to sum uncertainty deductions across years\n\nKey exemption: Allometric model structural uncertainty excluded when models are applied consistently between baseline and crediting periods.\nPenalty threshold: Uncertainty deductions apply when 90% CI half-width exceeds threshold, calculated as:\n\\[\n\\text{} \\frac{HW_{90\\%}}{\\text{Mean estimate}} &gt; \\text{Threshold}\n\\]\nEquation 10: Uncertainty adjustment factor\n\\[\nUA_t = 0.524417 \\times \\frac{HW_{90\\%}}{1.645006}\n\\]\nEquation 11: Uncertainty deduction\n\\[\nUNC_t = (GHGER_t + GHGREMV_t) \\times UA_t\n\\]\nIPCC Guidelines\nThe IPCC Good Practice Guidance establishes five key principles for uncertainty reporting:\n\nTransparency: Document all assumptions, data sources, and methods\nConsistency: Apply methods uniformly across time series\nComparability: Enable cross-country and cross-sector comparison\nCompleteness: Include all relevant sources and sinks\nAccuracy: Minimize bias and reduce uncertainties\n\nUncertainty reporting tiers:\n\n\nTier\nApproach\nUncertainty Method\nTypical Uncertainty\n\n\n\nTier 1\nIPCC defaults\nExpert judgment ranges\n±50-100%\n\n\nTier 2\nCountry-specific\nPropagation of errors\n±30-50%\n\n\nTier 3\nDetailed inventory\nMonte Carlo simulation\n±20-30%\n\n\nIPCC’s Managed Land Proxy\nThe Managed Land Proxy (MLP) approach affects uncertainty treatment in the following components:\n\nFire detection omission/commission errors\nFuel consumption parameter variance\nEmission factor measurement error\nSpatial aggregation uncertainty\n\nThe Managed Land Proxy (MLP) approach excludes from uncertainty the following components:\n\nInter-annual variability (IAV) from natural disturbances\nClimate-driven fluctuations in fire regimes\nLong-term carbon balance assumptions\n\nRationale: IAV represents true variation, not measurement error, and is expected to balance over multi-decadal timescales.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#uncertainty-drivers",
    "href": "index.html#uncertainty-drivers",
    "title": "REDD+ Uncertainty",
    "section": "Uncertainty Drivers",
    "text": "Uncertainty Drivers\nThis guide addresses the dominant sources of uncertainty in REDD+ carbon accounting, organized by typical magnitude of contribution to total variance:\nChapter 1: Allometry\nAllometric models are a critical and pervasive source of systematic bias, so much so that some call for a concerted global effort to improve allometric equations for tropical forests (J. Pelletier et al., 2013). Unlike random measurement errors, allometric uncertainty is systematic, meaning it cannot be reduced by simply measuring more trees. It also geographically variable, as equations developed in one tropical region often introduce substantial bias when applied elsewhere.\nWhile the ART-TREES Standard V2.0 exempts structural allometric uncertainty when models are applied consistently between baseline and crediting periods, recognizing that biases cancel through differencing, this pragmatic provision reduces reporting burden but does not eliminate actual uncertainty. This is particularly important if forest composition shifts over time due to selective logging, natural succession, or climate-driven changes. Chapter 1 provides methods for quantifying allometric uncertainty, developing region-specific equations, and determining when the consistency exemption applies.\nBiomass estimation depends on allometric equations relating tree diameter to aboveground biomass. Uncertainty sources include:\nModel selection:\n\nGeographic transferability of published equations\nSpecies-specific vs. generic models\nDiameter range extrapolation beyond calibration data\n\nParameter estimation:\n\nRegression coefficient standard errors\nResidual variance and heteroscedasticity\nSample size limitations in calibration datasets (Duncanson et al., 2015; Roxburgh et al., 2015).\n\nMeasurement error:\n\nDBH measurement precision (±0.5-1.0 cm)\nHeight measurement bias (clinometer/laser)\nWood density and debris variance(Yanai et al., 2010)\n\n\nBias correction:\n\nMaximum Likelihood Ratio (MLR) bias correction\nRestricted Maximum Likelihood (REML) bias correction\nBaskerville bias correction (Baskerville, 1972; Clifford et al., 2013)\n\nSpecies-specific height correction (Andersen et al., 2006; St-Onge et al., 2004)\n\nMoisture content correction factors (Roxburgh et al., 2015)\n\nNon-linear and intercept-only model prediction intervals.\nCensored data and zero-inflation bootstrapping\n\nKey methods: Monte Carlo parameter resampling (McRoberts & Westfall, 2016), prediction interval calculation, equivalence testing and cross-validation for model selection (Ploton et al., 2020), destructive sampling campaigns when cost-effective.\nART-TREES exemption: Structural uncertainty in allometric models excluded when applied consistently in baseline and crediting periods, reducing burden on project developers but not eliminating actual uncertainty.\nStrategic importance: Under-reported (only 4-14% of countries) but potentially dominant source once quantified (Butler et al., 2024).\nChapter 2: Emission Factor\nEmission factors represent a critical but dramatically under-reported source of uncertainty in REDD+ accounting. J. Pelletier et al. (2013) distinguish between “recurring sources” of random and systematic measurement errors quantified in each monitoring cycle and “modelling sources” of uncertainties embedded in model parameters and assumptions such as combustion completeness factors and gas-specific emission ratios. Their Panama case study demonstrates that “the highest error propagated using Monte Carlo simulations was caused by modelling sources of uncertainty,” including critical assumptions about fuel consumption rates, fire intensity classifications, and the relationships between modified combustion efficiency and trace gas production.\nChapter 2 addresses both the direct measurement uncertainty in emission factors (Gef) and the related uncertainty in combustion completeness (Cf), providing field protocols for jurisdictional campaigns and guidance on when IPCC Tier 1 defaults are sufficient versus when Tier 2 country-specific measurements justify their cost.\nEmission factors (Gef) convert biomass change to greenhouse gas emissions. Uncertainty sources include:\nDefault variance values:\n\nIPCC Table 2.5 confidence intervals (±30-50%)\nBiome-specific vs. generic factors\nFire type stratification (forest/savanna/peatland)\n\nCombustion completeness:\n\nFuel consumption factor (Cf) variability\nSeasonal and climatic effects\nFire intensity and duration\n\nGas-specific factors:\n\nCH₄: ±30-40% (incomplete combustion variability)\nN₂O: ±50-60% (nitrogen content and temperature effects)\nCO₂: ±5% for organic soils (stoichiometric, low variance)\n\nKey methods: Literature synthesis of emission factor ranges, field measurements of combustion products, Fourier Transform Infrared Spectroscopy (FTIR) for gas ratios.\nStrategic focus: Emission factors contribute 20-30% of total uncertainty but are expensive to reduce through field campaigns. Cost-benefit analysis favors using IPCC defaults unless jurisdiction-specific factors demonstrate substantially lower uncertainty (Köhler & Huth, 2010).\nChapter 3: Activity Data\nActivity data has historically received the most attention in REDD+ uncertainty analysis, with 91% of countries now reporting uncertainty in their land-use change estimates (Butler et al., 2024; Chen et al., 2015; Sheng et al., 2018). This focus has made activity data the best-quantified component through sustained investment in improved remote sensing protocols, validation frameworks, and change detection algorithms. However, this apparent success raises an important paradox: while activity data uncertainty has been systematically reduced and documented, other potentially dominant sources, particularly modelling assumptions about forest classification, carbon accumulation rates, and transition probabilities between land-use categories, remain largely under-estimated.\nJ. Pelletier et al. (2013) identify these modelling sources as exhibiting the highest sensitivity in their Panama analysis, with assumptions about fallow forest classification between intact and degraded forest, and temporal dynamics of regrowth producing emission flux variations ranging from 4.2% to 262.2% of reference levels. Chapter 3 addresses both the well-established methods for quantifying map accuracy uncertainty and the emerging need to characterize uncertainty in the modelling assumptions that link activity data to carbon stock changes.\nActivity data (A) represents the spatial extent and temporal dynamics of forest change. Uncertainty sources include:\nLand cover classification:\n\nProducer’s/User’s accuracy from confusion matrices\nMixed pixel effects at forest boundaries\nTemporal consistency in multi-date classifications\n\nChange detection:\n\nOmission errors (missed deforestation/degradation)\nCommission errors (false change detection)\nMinimum mapping unit effects\n\nSpatial aggregation:\n\nEdge effects and boundary uncertainty\nProjection and coordinate system errors\nPixel area calculation variance\nScale dependency: Köhler & Huth (2010) demonstrate 20-40% uncertainty at 1-ha scale vs. &gt;100% at 0.04-ha scale\n\nKey methods: Monte Carlo simulation of LULC classification, bootstrapping confusion matrices, spatial autocorrelation analysis, cross-validation with independent reference data.\nART-TREES requirements: Activity data uncertainty typically dominates reported uncertainty (40-60% contribution when emission factors omitted), but may not dominate actual total uncertainty once all sources quantified (Butler et al., 2024).\nChapter 4: Aggregated Simulation\nThis chapter Iintegrates previous sources through Monte Carlo simulation, the gold standard for REDD+ uncertainty quantification validated by 16+ peer-reviewed studies (Winrock 2025 literature review). Distinguishes “modelling sources” vs. “recurring sources” following N. Pelletier et al. (2024) framework.\nTotal uncertainty combines individual components through error propagation, with sensitivity analysis identifying highest-impact parameters for targeted reduction. Real-world implementation from Guyana TREES program demonstrates 21-percentage-point uncertainty reduction through methodological refinements.\nMonte Carlo Best Practices\nRecent literature review (Winrock 2025) spanning 2003-2023 confirms Monte Carlo Approach 2 as convergent standard:\n\n16 peer-reviewed studies validate effectiveness\nPlot to national scale applications demonstrated\nART-TREES requirement: n=10,000 iterations, 90% CI\nIPCC endorsed: 2006 and 2019 Refinement guidelines\n\nCritical Insights\n\nCorrelations essential: Ignoring interdependencies underestimates uncertainty 15-30% (Yanai et al., 2010; keller2001biomass?)\n\nDistribution selection matters: Beta/log-normal &gt; truncated normal for bounded parameters (picard2015?)\n\nBootstrap required: When theoretical distributions unknown (molto2013?)\n\nSensitivity analysis guides investment: Sobol indices identify high-impact targets (Chen et al., 2015; holdaway2014?)\n\n\nIPCC Error Propagation\nComplete framework for multiplicative emission chain:\n\\[\nU_{total}^2 = U_A^2 + U_{EF}^2 + U_{biomass}^2 + 2 \\times \\text{Cov}(A, EF)\n\\]\nFor emissions E = A × MB × Cf × Gef:\n\\[\n\\frac{U_E^2}{E^2} = \\frac{U_A^2}{A^2} + \\frac{U_{M_B}^2}{M_B^2} + \\frac{U_{C_f}^2}{C_f^2} + \\frac{U_{G_{ef}}^2}{G_{ef}^2} + 2\\rho_{A,M_B}\\frac{U_A U_{M_B}}{A M_B}\n\\]\nKey insight: Relative uncertainties combine in quadrature for multiplicative models; correlations critical.\n\n\n\n\n\n\nAndersen, H.-E., Reutebuch, S. E., & McGaughey, R. J. (2006). A rigorous assessment of tree height measurements obtained using airborne lidar and conventional field methods. Canadian Journal of Remote Sensing, 32(5), 355–366. https://doi.org/10.5589/m06-030\n\n\nART. (2021). The REDD+ environmental excellence standard (2.0 ed.). https://www.artredd.org/wp-content/uploads/2021/12/TREES-2.0-August-2021-Clean.pdf\n\n\nBaskerville, G. (1972). Use of logarithmic regression in the estimation of plant biomass. Canadian Journal of Forest Research, 2(1), 49–53.\n\n\nButler, B. J., Sass, E. M., Gamarra, J. G., Campbell, J. L., Wayson, C., Olguıń, M., Carrillo, O., & Yanai, R. D. (2024). Uncertainty in REDD+ carbon accounting: A survey of experts involved in REDD+ reporting. Carbon Balance and Management, 19(1), 22.\n\n\nCamara, G., Simoes, R., Souza, F., Menino, F., Pelletier, C., Andrade, P. R., Ferreira, K., & Queiroz, G. (2024). Uncertainty and active learning analysis. In Satellite time series on earth observation data cubes. https://e-sensing.github.io/sitsbook/uncertainty-and-active-learning.html#uncertainty-and-active-learning\n\n\nChen, Q., Laurin, G. V., & Valentini, R. (2015). Uncertainty of remotely sensed aboveground biomass over an african tropical forest: Propagating errors from trees to plots to pixels. Remote Sensing of Environment, 160, 134–143. https://doi.org/10.1016/j.rse.2015.01.009\n\n\nClifford, D., Cressie, N., England, J. R., Roxburgh, S. H., & Paul, K. I. (2013). Correction factors for unbiased, efficient estimation and prediction of biomass from log–log allometric models. Forest Ecology and Management, 310, 375–381. https://doi.org/10.1016/j.foreco.2013.08.041\n\n\nDuncanson, L., Disney, M., Armston, J., Nickeson, J., Minor, D., & Camacho, F. (2021). Aboveground woody biomass product validation good practices protocol. https://doi.org/10.5067/DOC/CEOSWGCV/LPV/AGB.001\n\n\nDuncanson, L., Rourke, O., & Dubayah, R. (2015). Small sample sizes yield biased allometric equations in temperate forests. Scientific Reports, 5(1), 17153.\n\n\nIPCC. (2019). 2019 refinement to the 2006 IPCC guidelines for national greenhouse gas inventories (Agriculture, Forestry and Other Land Use, Vol. 4). Intergovernmental Panel on Climate Change. https://www.ipcc-nggip.iges.or.jp/public/2019rf/vol4.html\n\n\nKöhler, P., & Huth, A. (2010). Towards ground-truthing of spaceborne estimates of above-ground life biomass and leaf area index in tropical rain forests. Biogeosciences (Online), 7(8), 2531–2543.\n\n\nMcRoberts, R. E., & Westfall, J. A. (2016). Propagating uncertainty through individual tree volume model predictions to large-area volume estimates. Annals of Forest Science, 73(ue 3), 625–633. https://doi.org/10.1007/s13595-015-0473-x\n\n\nPelletier, J., Martin, D., & Potvin, C. (2013). REDD+ emissions estimation and reporting: Dealing with uncertainty. Environmental Research Letters, 8(3), 034009.\n\n\nPelletier, N., THIAGARAJAN, A., Durnin-Vermette, F., Liang, C., Choo, D., Cerkowniak, D., Elkhoury, A., MacDonald, D., Smith, W., & VandenBygaart, B. (2024). Bayesian calibration of the ipcc tier-2 steady-state organic carbon model for canadian croplands using long-term experimental data. Available at SSRN 4877052.\n\n\nPloton, P., Mortier, F., Réjou-Méchain, M., Barbier, N., Picard, N., Rossi, V., Dormann, C., Cornu, G., Viennois, G., Bayol, N., & al., et. (2020). Spatial validation reveals poor predictive performance of large-scale ecological mapping models. Nature Communications, 11(1), 4540.\n\n\nRoxburgh, S., Paul, K., Clifford, D., England, J., & Raison, R. (2015). Guidelines for constructing allometric models for the prediction of woody biomass: How many individuals to harvest? Ecosphere (Washington, D.C), 6(3), 1–27.\n\n\nSheng, J., Zhou, W., & De Sherbinin, A. (2018). Uncertainty in estimates, incentives, and emission reductions in REDD+ projects. International Journal of Environmental Research and Public Health, 15(7), 1544.\n\n\nSimoes, R., Camara, G., Queiroz, G., Souza, F., Andrade, P. R., Santos, L., Carvalho, A., & Ferreira, K. (2021). Satellite image time series analysis for big earth observation data. Remote Sensing, 13(13), 2428.\n\n\nSt-Onge, B., Treitz, P., Wulder, M., Kurz, W., & Gillis, M. (2004). Retrospective mapping of structural and biomass changes in forest ecosystems using photogrammetry and laser altimetry. AGU Spring Meeting Abstracts, 2004, B21B–04.\n\n\nYanai, R. D., Battles, J. J., Richardson, A. D., Blodgett, C. A., Wood, D. M., & Rastetter, E. B. (2010). Estimating uncertainty in ecosystem budget calculations. Ecosystems (New York, N.Y.), 13(ue 2), 239–248. https://doi.org/10.1007/s10021-010-9315-8",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "01-allometry/index.html",
    "href": "01-allometry/index.html",
    "title": "\n1  Allometry\n",
    "section": "",
    "text": "Overview\nAllometric equations represent the proportional and scaling relationships between different tree dimensions, such as the relationship between a tree’s diameter and its height, biomass, or crown size. These relationships translate tree diameter measurements into biomass estimates, forming the foundation of forest carbon accounting. This chapter addresses uncertainty quantification in processes of allometric model selection, parameter estimation, correction of measurement error and predictive bias.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Allometry</span>"
    ]
  },
  {
    "objectID": "01-allometry/index.html#overview",
    "href": "01-allometry/index.html#overview",
    "title": "\n1  Allometry\n",
    "section": "",
    "text": "Environment Setup\n\neasypackages::packages(\n  \"allodb\", \"animation\", \n  \"BIOMASS\",\n  \"cols4all\", \"covr\", \"cowplot\", \"caret\",\n  \"dataMaid\", \"DescTools\", \"dplyr\",\n  \"FawR\", \"ForestToolsRS\", \"forestdata\",\n  \"ggplot2\", \"giscoR\", \n  \"htmltools\",\n  \"janitor\", \"jsonlite\", \n  \"lattice\", \"leaflet.providers\", \"leafem\", \"lwgeom\", \"leaflet\", \"leafgl\",\n  \"kableExtra\", \"kernlab\", \"knitr\", \n  \"mapedit\", \"mapview\", \"maptiles\", \"Mlmetrics\", \n  \"olsrr\", \"openxlsx\",\n  \"plotly\", \"psych\", \n  \"randomForest\", \"rasterVis\", \"raster\",\"RColorBrewer\", \"rmarkdown\", \n  \"s2\", \"sf\", \"scales\", \"sits\",\"spdep\", \"stars\", \"stringr\",\n  \"terra\", \"tmap\", \"tmaptools\", \"tidymodels\", \"tidyverse\", \"tune\", \n  \"useful\",\n  prompt = F\n  )\n\nsf::sf_use_s2(use_s2 = FALSE)\nset.seed(8787)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Allometry</span>"
    ]
  },
  {
    "objectID": "01-allometry/index.html#sec-allometry-relationship",
    "href": "01-allometry/index.html#sec-allometry-relationship",
    "title": "\n1  Allometry\n",
    "section": "\n1.1 The Allometric Equation",
    "text": "1.1 The Allometric Equation\n\\[\nAGB = \\alpha \\times DBH^{\\beta}\n\\]\nOr in logarithmic form…\n\\[\n\\ln(AGB) = \\ln(\\alpha) + \\beta \\times \\ln(DBH) + \\epsilon\n\\]\nWhere:\n\nAGB: Aboveground biomass (kg)\nDBH: Diameter at breast height (cm)\nα, β: Allometric parameters (species/biome-specific)\nε: Random error term\n\n\n1.1.1 Sources of Uncertainty\nAllometric equations predict aboveground biomass from diameter measurements using species or biome-specific parameters. Uncertainty compounds from three main sources: model selection (tropical vs. temperate equations, species-specific vs. generic), parameter estimation (regression standard errors, sample sizes), and field measurements (DBH precision ±0.5-1.0 cm, clinometer errors, wood density variability). Log-transformation adds complexity through back-transformation bias that must be corrected to avoid systematically underestimating biomass.\nART Exemption to Allometric Uncertainty\nART-TREES V2.0 Section 8 excludes structural uncertainty in allometric models from uncertainty deductions when models are applied consistently between baseline and crediting periods. Since systematic bias cancels in net change calculations, you only need to quantify random error: parameter estimation uncertainty, measurement precision, and sampling uncertainty when scaling from plots to landscapes.\nThis creates a strategic advantage: reduce uncertainty deductions by maintaining consistent model application across time periods, upgrading from IPCC Tier 1 defaults to country-specific Tier 2 parameters, and investing in measurement precision rather than destructive sampling. Let’s implement this with Monte Carlo simulation.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Allometry</span>"
    ]
  },
  {
    "objectID": "01-allometry/index.html#sec-model-selection",
    "href": "01-allometry/index.html#sec-model-selection",
    "title": "\n1  Allometry\n",
    "section": "\n1.2 Model Selection",
    "text": "1.2 Model Selection\nWe’ll use the allodb package to access global allometric equations and demonstrate uncertainty propagation with real forest inventory data. The example dataset scbi_stem1 comes from the Smithsonian Conservation Biology Institute [SCBI](https://docs.ropensci.org/allodb/reference/scbi_stem1.html) ForestGEO plot in Front Royal, Virginia, which includes a 1-hectare subset from the 2008 initial census of a 25.6-ha temperate mixed deciduous forest.\n#| eval: true\n#| label: allometry-equation-database\n#| code-summary: \"Database of available allometric equations\"\n# load allometry database\nlibrary(allodb)\n\n# import allometric dataset\ndata(scbi_stem1)\n\n# visualize\nhead(scbi_stem1) |&gt; tibble::as_tibble()\nThis dataset contains 2,287 stem measurements from mature secondary eastern deciduous forest dominated by tulip poplar (Liriodendron tulipifera), oaks (Quercus spp.), and hickories (Carya spp.). The forest represents typical Appalachian mixed hardwood composition at the intersection of the Blue Ridge, Ridge and Valley, and Piedmont physiographic provinces. This data object is particularly useful for demonstrating Monte Carlo propagation of measurement uncertainty, parameter uncertainty, and model selection effects.\nOutput:\n| Species | Model | Form | α | β | DBH Range | Country | Reference |\n|---------|-------|------|---|---|-----------|---------|-----------|\n| Betula pendula | M1 | α×D^β | 0.251 | 2.29 | All | UK | Bunce (1968) |\n| Betula pendula | M2 | exp(α+β×ln(D)) | -2.417 | 2.423 | 2.9-30 | UK | Bunce (1968) |\n| ... | ... | ... | ... | ... | ... | ... | ... |\n\n1.2.1 Equivalence Testing Framework\nObjective: Determine if published equations are valid for local conditions\nMethod: Test if difference between predicted and observed biomass falls within acceptable threshold\nEquivalence criteria (CEOS/NASA protocol): - Relative difference &lt; ±25% - Systematic bias &lt; ±5% - RMSE within 1.5× calibration dataset RMSE\n\nlibrary(tidyverse)\nlibrary(MASS)\n\n# Function: Equivalence test for allometric models\nequivalence_test &lt;- function(observed_biomass, predicted_biomass, threshold = 0.25) {\n  \n  # Calculate relative difference\n  relative_diff &lt;- (predicted_biomass - observed_biomass) / observed_biomass\n  \n  # Mean relative difference (systematic bias)\n  mean_rel_diff &lt;- mean(relative_diff, na.rm = TRUE)\n  \n  # Standard error\n  se_rel_diff &lt;- sd(relative_diff, na.rm = TRUE) / sqrt(length(relative_diff))\n  \n  # 90% confidence interval\n  ci_lower &lt;- mean_rel_diff - 1.645 * se_rel_diff\n  ci_upper &lt;- mean_rel_diff + 1.645 * se_rel_diff\n  \n  # Equivalence test: CI must fall entirely within [-threshold, +threshold]\n  is_equivalent &lt;- (ci_lower &gt; -threshold) && (ci_upper &lt; threshold)\n  \n  # RMSE\n  rmse &lt;- sqrt(mean((predicted_biomass - observed_biomass)^2, na.rm = TRUE))\n  \n  # Results\n  results &lt;- list(\n    mean_relative_difference = mean_rel_diff,\n    ci_90 = c(ci_lower, ci_upper),\n    is_equivalent = is_equivalent,\n    rmse = rmse,\n    n_samples = length(observed_biomass)\n  )\n  \n  return(results)\n}\n\n# Example usage: Test model M3 for Betula pendula\n# Assume we have validation data\nvalidation_data &lt;- data.frame(\n  dbh_cm = c(10, 15, 20, 25, 30, 35, 40),\n  observed_agb_kg = c(12, 35, 68, 110, 165, 235, 315)\n)\n\n# Apply Model M3: exp(-2.7584 + 2.6134 × ln(D))\nvalidation_data$predicted_agb_kg &lt;- exp(-2.7584 + 2.6134 * log(validation_data$dbh_cm))\n\n# Run equivalence test\nequiv_results &lt;- equivalence_test(\n  observed_biomass = validation_data$observed_agb_kg,\n  predicted_biomass = validation_data$predicted_agb_kg,\n  threshold = 0.25  # ±25%\n)\n\n# Display results\ncat(\"Equivalence Test Results:\\n\")\ncat(sprintf(\"Mean relative difference: %.2f%%\\n\", equiv_results$mean_relative_difference * 100))\ncat(sprintf(\"90%% CI: [%.2f%%, %.2f%%]\\n\", equiv_results$ci_90[1] * 100, equiv_results$ci_90[2] * 100))\ncat(sprintf(\"Equivalent (within ±25%%): %s\\n\", ifelse(equiv_results$is_equivalent, \"YES\", \"NO\")))\ncat(sprintf(\"RMSE: %.2f kg\\n\", equiv_results$rmse))\n\nInterpretation: - Equivalent: Model can be applied without modification - Not equivalent: Develop local calibration or use alternative model\n\n1.2.2 Model Selection Criteria\nMulti-criteria decision matrix:\n\n\nCriterion\nWeight\nThreshold\nRationale\n\n\n\nRMSE\n40%\nMinimize\nPrediction accuracy\n\n\nGeographic proximity\n25%\nSame biome\nClimate/soil similarity\n\n\nDBH range coverage\n20%\n&gt;80% overlap\nAvoid extrapolation\n\n\nSample size\n15%\n&gt;50 trees\nStatistical power\n\n\n\n\n# Function: Score models for selection\nscore_allometric_models &lt;- function(models_df, validation_data, target_dbh_range) {\n  \n  # Calculate RMSE for each model\n  models_df$rmse &lt;- NA\n  \n  for (i in 1:nrow(models_df)) {\n    # Apply model equation (simplified for illustration)\n    if (models_df$Form[i] == \"α×D^β\") {\n      predicted &lt;- models_df$Alpha[i] * validation_data$dbh_cm^models_df$Beta[i]\n    } else {  # exp(α+β×ln(D))\n      predicted &lt;- exp(models_df$Alpha[i] + models_df$Beta[i] * log(validation_data$dbh_cm))\n    }\n    \n    models_df$rmse[i] &lt;- sqrt(mean((predicted - validation_data$observed_agb_kg)^2))\n  }\n  \n  # Normalize RMSE score (lower is better, scale 0-1)\n  models_df$rmse_score &lt;- 1 - (models_df$rmse - min(models_df$rmse)) / (max(models_df$rmse) - min(models_df$rmse))\n  \n  # Geographic proximity score (1 = same country, 0.5 = same biome, 0 = different)\n  models_df$geo_score &lt;- ifelse(models_df$Country == \"UK\", 1.0,\n                                 ifelse(models_df$Country %in% c(\"Ireland\", \"Sweden\"), 0.5, 0))\n  \n  # DBH range overlap score\n  # (Simplified: assumes target range 5-50 cm)\n  models_df$range_score &lt;- 0.8  # Placeholder\n  \n  # Composite score\n  models_df$total_score &lt;- (\n    models_df$rmse_score * 0.40 +\n    models_df$geo_score * 0.25 +\n    models_df$range_score * 0.20 +\n    0.15  # Sample size score (placeholder)\n  )\n  \n  # Rank models\n  models_df &lt;- models_df %&gt;%\n    arrange(desc(total_score))\n  \n  return(models_df)\n}\n\n# Example usage\n# scored_models &lt;- score_allometric_models(allometric_equations, validation_data, c(5, 50))\n# print(scored_models %&gt;% select(Model_ID, Species, RMSE, total_score))",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Allometry</span>"
    ]
  },
  {
    "objectID": "01-allometry/index.html#sec-parameter-uncertainty",
    "href": "01-allometry/index.html#sec-parameter-uncertainty",
    "title": "\n1  Allometry\n",
    "section": "\n1.3 Model Tuning",
    "text": "1.3 Model Tuning\n\n1.3.1 Regression Uncertainty Quantification\nStandard error of coefficients from regression:\n\\[\nSE(\\hat{\\beta}) = \\sqrt{\\frac{\\sigma^2}{\\sum(x_i - \\bar{x})^2}}\n\\]\nWhere: - \\(\\hat{\\beta}\\): Estimated coefficient - \\(\\sigma^2\\): Residual variance - \\(x_i\\): Predictor values (ln(DBH))\n\nlibrary(tidyverse)\n\n# Example: Fit allometric model to calibration data\ncalibration_data &lt;- data.frame(\n  dbh_cm = c(10, 15, 20, 25, 30, 35, 40, 45, 50),\n  agb_kg = c(12, 35, 68, 110, 165, 235, 315, 410, 520)\n)\n\n# Log-transform for linear regression\ncalibration_data$ln_dbh &lt;- log(calibration_data$dbh_cm)\ncalibration_data$ln_agb &lt;- log(calibration_data$agb_kg)\n\n# Fit model: ln(AGB) = α + β × ln(DBH)\nmodel_fit &lt;- lm(ln_agb ~ ln_dbh, data = calibration_data)\n\n# Extract parameters and uncertainty\nmodel_summary &lt;- summary(model_fit)\n\n# Coefficients\nalpha_est &lt;- coef(model_fit)[1]\nbeta_est &lt;- coef(model_fit)[2]\n\n# Standard errors\nalpha_se &lt;- model_summary$coefficients[1, 2]\nbeta_se &lt;- model_summary$coefficients[2, 2]\n\n# Variance-covariance matrix\nvcov_matrix &lt;- vcov(model_fit)\n\n# Residual standard error (for Baskerville correction)\nsigma_residual &lt;- model_summary$sigma\n\n# Display results\ncat(\"Allometric Model Fit Results:\\n\")\ncat(sprintf(\"α = %.4f ± %.4f\\n\", alpha_est, alpha_se))\ncat(sprintf(\"β = %.4f ± %.4f\\n\", beta_est, beta_se))\ncat(sprintf(\"Residual SE: %.4f\\n\", sigma_residual))\ncat(sprintf(\"R-squared: %.4f\\n\", model_summary$r.squared))\n\n# 90% confidence intervals for parameters\nalpha_ci &lt;- alpha_est + c(-1, 1) * qt(0.95, df = model_fit$df.residual) * alpha_se\nbeta_ci &lt;- beta_est + c(-1, 1) * qt(0.95, df = model_fit$df.residual) * beta_se\n\ncat(sprintf(\"α 90%% CI: [%.4f, %.4f]\\n\", alpha_ci[1], alpha_ci[2]))\ncat(sprintf(\"β 90%% CI: [%.4f, %.4f]\\n\", beta_ci[1], beta_ci[2]))\n\n\n1.3.2 Monte Carlo Parameter Resampling\nApproach: Sample from multivariate normal distribution of parameter estimates\n\nlibrary(MASS)  # For mvrnorm\n\n# Function: Monte Carlo parameter uncertainty propagation\nmonte_carlo_allometry &lt;- function(model_fit, new_dbh, n_sim = 10000) {\n  \n  # Extract parameter estimates\n  param_est &lt;- coef(model_fit)\n  \n  # Extract variance-covariance matrix\n  param_vcov &lt;- vcov(model_fit)\n  \n  # Sample parameters from multivariate normal\n  param_samples &lt;- mvrnorm(n = n_sim, mu = param_est, Sigma = param_vcov)\n  \n  # Initialize results\n  biomass_predictions &lt;- matrix(NA, nrow = n_sim, ncol = length(new_dbh))\n  \n  # Baskerville correction factor\n  sigma_model &lt;- summary(model_fit)$sigma\n  baskerville &lt;- exp(sigma_model^2 / 2)\n  \n  # Monte Carlo simulation\n  for (i in 1:n_sim) {\n    alpha_sim &lt;- param_samples[i, 1]\n    beta_sim &lt;- param_samples[i, 2]\n    \n    # Predict biomass with sampled parameters\n    ln_biomass_pred &lt;- alpha_sim + beta_sim * log(new_dbh)\n    \n    # Back-transform with Baskerville correction\n    biomass_predictions[i, ] &lt;- exp(ln_biomass_pred) * baskerville\n  }\n  \n  # Calculate statistics\n  biomass_mean &lt;- colMeans(biomass_predictions)\n  biomass_sd &lt;- apply(biomass_predictions, 2, sd)\n  biomass_ci_lower &lt;- apply(biomass_predictions, 2, quantile, 0.05)\n  biomass_ci_upper &lt;- apply(biomass_predictions, 2, quantile, 0.95)\n  \n  # Uncertainty as percentage\n  biomass_uncertainty_pct &lt;- (biomass_ci_upper - biomass_ci_lower) / (2 * biomass_mean) * 100\n  \n  results &lt;- data.frame(\n    dbh_cm = new_dbh,\n    biomass_mean_kg = biomass_mean,\n    biomass_sd_kg = biomass_sd,\n    ci_lower_kg = biomass_ci_lower,\n    ci_upper_kg = biomass_ci_upper,\n    uncertainty_pct = biomass_uncertainty_pct\n  )\n  \n  return(list(\n    summary = results,\n    simulations = biomass_predictions\n  ))\n}\n\n# Example usage\n# New DBH values to predict\nnew_dbh_values &lt;- seq(5, 50, by = 5)\n\n# Run Monte Carlo simulation\nmc_results &lt;- monte_carlo_allometry(\n  model_fit = model_fit,\n  new_dbh = new_dbh_values,\n  n_sim = 10000\n)\n\n# Display results\nprint(mc_results$summary)\n\n# Visualize uncertainty\nlibrary(ggplot2)\nggplot(mc_results$summary, aes(x = dbh_cm, y = biomass_mean_kg)) +\n  geom_line(color = \"darkblue\", size = 1.2) +\n  geom_ribbon(aes(ymin = ci_lower_kg, ymax = ci_upper_kg), alpha = 0.3, fill = \"steelblue\") +\n  labs(\n    title = \"Allometric Model Predictions with 90% Confidence Intervals\",\n    subtitle = \"Parameter uncertainty propagated through Monte Carlo simulation (n=10,000)\",\n    x = \"DBH (cm)\",\n    y = \"Aboveground Biomass (kg)\"\n  ) +\n  theme_minimal()\n\nTypical uncertainty magnitudes: - Small trees (DBH 5-10 cm): ±15-25% - Medium trees (DBH 20-30 cm): ±10-15% - Large trees (DBH &gt;40 cm): ±8-12%",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Allometry</span>"
    ]
  },
  {
    "objectID": "01-allometry/index.html#sec-measurement-error",
    "href": "01-allometry/index.html#sec-measurement-error",
    "title": "\n1  Allometry\n",
    "section": "\n1.4 Error Propagation",
    "text": "1.4 Error Propagation\n\n1.4.1 DBH Measurement Precision\nSources of DBH error: 1. Instrument precision: ±0.5 cm (diameter tape) to ±1.0 cm (calipers) 2. Measurement height: Breast height (1.3m) ±5 cm 3. Tree form irregularities: Buttresses, branches at 1.3m 4. Operator variability: Inter-measurer differences\n\n# Function: Propagate DBH measurement error through allometry\npropagate_dbh_error &lt;- function(true_dbh, dbh_error_sd, alpha, beta, n_sim = 10000) {\n  \n  # Sample DBH measurements with error\n  dbh_measurements &lt;- rnorm(n_sim, mean = true_dbh, sd = dbh_error_sd)\n  \n  # Ensure positive values\n  dbh_measurements &lt;- pmax(dbh_measurements, 0.1)\n  \n  # Calculate biomass for each measurement\n  biomass_estimates &lt;- alpha * dbh_measurements^beta\n  \n  # Summary statistics\n  biomass_mean &lt;- mean(biomass_estimates)\n  biomass_sd &lt;- sd(biomass_estimates)\n  biomass_cv &lt;- biomass_sd / biomass_mean * 100\n  biomass_ci &lt;- quantile(biomass_estimates, c(0.05, 0.95))\n  \n  # True biomass (no error)\n  biomass_true &lt;- alpha * true_dbh^beta\n  \n  # Bias from measurement error\n  bias_pct &lt;- (biomass_mean - biomass_true) / biomass_true * 100\n  \n  results &lt;- list(\n    true_dbh = true_dbh,\n    mean_biomass = biomass_mean,\n    true_biomass = biomass_true,\n    bias_percent = bias_pct,\n    cv_percent = biomass_cv,\n    ci_90 = biomass_ci\n  )\n  \n  return(results)\n}\n\n# Example: Assess DBH measurement error impact\ndbh_values &lt;- c(10, 20, 30, 40, 50)\ndbh_error_sd &lt;- 0.5  # ±0.5 cm standard deviation\n\n# Model M9 parameters: α = 0.028, β = 2.71\nresults_list &lt;- lapply(dbh_values, function(dbh) {\n  propagate_dbh_error(\n    true_dbh = dbh,\n    dbh_error_sd = dbh_error_sd,\n    alpha = 0.028,\n    beta = 2.71,\n    n_sim = 10000\n  )\n})\n\n# Compile results\ndbh_error_summary &lt;- data.frame(\n  dbh_cm = dbh_values,\n  cv_pct = sapply(results_list, function(x) x$cv_percent),\n  bias_pct = sapply(results_list, function(x) x$bias_percent)\n)\n\nprint(dbh_error_summary)\n\nExpected output:\n  dbh_cm cv_pct bias_pct\n1     10   13.5     4.2\n2     20    6.8     1.1\n3     30    4.5     0.5\n4     40    3.4     0.3\n5     50    2.7     0.2\nKey insight: Relative error decreases with tree size due to the power law relationship (β &gt; 2).\n\n1.4.2 Height Measurement Bias\nCommon height measurement methods:\n\n\nMethod\nPrecision\nBias\nCost\n\n\n\nClinometer\n±5-10%\nUnderestimation\nLow\n\n\nLaser rangefinder\n±2-5%\nMinimal\nModerate\n\n\nTLS (LiDAR)\n±1-2%\nMinimal\nHigh\n\n\n\nMitigation: Use two-variable allometry (DBH + Height) only when height can be measured precisely",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Allometry</span>"
    ]
  },
  {
    "objectID": "01-allometry/index.html#sec-bias-correction",
    "href": "01-allometry/index.html#sec-bias-correction",
    "title": "\n1  Allometry\n",
    "section": "\n1.5 Bias Correction",
    "text": "1.5 Bias Correction\n\n1.5.1 The Baskerville Correction\nProblem: Log-transformation bias in back-transformation\nUncorrected (WRONG): \\[\n\\hat{B} = \\exp(\\hat{\\alpha} + \\hat{\\beta} \\times \\ln(DBH))\n\\]\nSystematically underestimates biomass!\nBaskerville-corrected (CORRECT): \\[\n\\hat{B} = \\exp\\left(\\hat{\\alpha} + \\hat{\\beta} \\times \\ln(DBH) + \\frac{\\sigma^2}{2}\\right)\n\\]\nWhere \\(\\sigma^2\\) = residual variance from log-scale regression\n\nlibrary(tidyverse)\n\n# Simulated calibration data\nset.seed(123)\nn_trees &lt;- 50\ncalibration_sim &lt;- data.frame(\n  dbh_cm = runif(n_trees, 5, 50)\n)\n\n# True biomass with lognormal error\ncalibration_sim$true_biomass_kg &lt;- 0.05 * calibration_sim$dbh_cm^2.5 * exp(rnorm(n_trees, 0, 0.2))\n\n# Fit log-transformed model\ncalibration_sim$ln_dbh &lt;- log(calibration_sim$dbh_cm)\ncalibration_sim$ln_biomass &lt;- log(calibration_sim$true_biomass_kg)\n\nmodel_log &lt;- lm(ln_biomass ~ ln_dbh, data = calibration_sim)\n\n# Extract parameters\nalpha_hat &lt;- coef(model_log)[1]\nbeta_hat &lt;- coef(model_log)[2]\nsigma_residual &lt;- summary(model_log)$sigma\n\n# Predict on new data\nprediction_data &lt;- data.frame(dbh_cm = seq(5, 50, by = 1))\n\n# UNCORRECTED prediction\nprediction_data$biomass_uncorrected &lt;- exp(alpha_hat + beta_hat * log(prediction_data$dbh_cm))\n\n# BASKERVILLE-CORRECTED prediction\nbaskerville_factor &lt;- exp(sigma_residual^2 / 2)\nprediction_data$biomass_corrected &lt;- exp(alpha_hat + beta_hat * log(prediction_data$dbh_cm)) * baskerville_factor\n\n# TRUE biomass (without error)\nprediction_data$biomass_true &lt;- 0.05 * prediction_data$dbh_cm^2.5\n\n# Calculate bias\nprediction_data$bias_uncorrected_pct &lt;- (prediction_data$biomass_uncorrected - prediction_data$biomass_true) / prediction_data$biomass_true * 100\nprediction_data$bias_corrected_pct &lt;- (prediction_data$biomass_corrected - prediction_data$biomass_true) / prediction_data$biomass_true * 100\n\n# Visualize\nggplot(prediction_data, aes(x = dbh_cm)) +\n  geom_line(aes(y = biomass_true, color = \"True\"), size = 1.2) +\n  geom_line(aes(y = biomass_uncorrected, color = \"Uncorrected\"), linetype = \"dashed\", size = 1) +\n  geom_line(aes(y = biomass_corrected, color = \"Baskerville-Corrected\"), size = 1) +\n  scale_color_manual(\n    values = c(\"True\" = \"black\", \"Uncorrected\" = \"red\", \"Baskerville-Corrected\" = \"blue\"),\n    name = \"Prediction Method\"\n  ) +\n  labs(\n    title = \"Importance of Baskerville Correction\",\n    subtitle = \"Uncorrected back-transformation systematically underestimates biomass\",\n    x = \"DBH (cm)\",\n    y = \"Biomass (kg)\"\n  ) +\n  theme_minimal()\n\n# Summary statistics\ncat(\"Mean bias (uncorrected):\", round(mean(prediction_data$bias_uncorrected_pct), 2), \"%\\n\")\ncat(\"Mean bias (corrected):\", round(mean(prediction_data$bias_corrected_pct), 2), \"%\\n\")\n\nTypical magnitude: Uncorrected models underestimate biomass by 5-15% depending on residual variance.\n\n1.5.2 Case Study: Species Uncertainty\nDataset: 167 trees across 4 species\n\nlibrary(tidyverse)\n\n# Summary statistics (from your validation report)\nspecies_summary &lt;- tribble(\n  ~Species, ~Count, ~Mean_DBH_cm, ~SD_DBH, ~Median_DBH, ~Range_DBH,\n  \"Betula pendula\", 40, 23.7, 23.1, 13.5, 76,\n  \"Betula pubescens\", 20, 11.1, 3.9, 9.5, 12,\n  \"Picea sitchensis\", 66, 19.7, 6.5, 20.0, 26,\n  \"Sorbus aucuparia\", 1, 8.0, NA, NA, 0\n)\n\nkable(\n  species_summary,\n  caption = \"Summary Statistics: UK Forest Validation Dataset (n=167)\",\n  col.names = c(\"Species\", \"n\", \"Mean DBH (cm)\", \"SD\", \"Median\", \"Range\")\n)\n\n\n1.5.3 Model Performance\nEvaluation of 11 candidate equations:\nSelected models: 1. M3 (Betula pendula): RMSE = 2.38 kg, UK origin, excellent fit 2. M7 (Betula pubescens): RMSE = 0.00 kg, Sweden (acceptable transferability) 3. M9 (Picea sitchensis): RMSE = 1.47 kg, Ireland (same biome)\n\n1.5.4 Monte Carlo Simulation\nComplete implementation for selected models:\n\n# =============================================================================\n# ART-TREES COMPLIANT ALLOMETRY UNCERTAINTY ASSESSMENT\n# Combines: Parameter uncertainty + Measurement error + Bias correction\n# =============================================================================\n\nlibrary(tidyverse)\nlibrary(MASS)\n\n# Function: Complete allometry uncertainty assessment\ncomplete_allometry_uncertainty &lt;- function(\n  calibration_data,\n  validation_data,\n  dbh_error_sd = 0.5,\n  n_sim = 10000\n) {\n  \n  # Step 1: Fit allometric model\n  calibration_data$ln_dbh &lt;- log(calibration_data$dbh_cm)\n  calibration_data$ln_agb &lt;- log(calibration_data$agb_kg)\n  \n  model_fit &lt;- lm(ln_agb ~ ln_dbh, data = calibration_data)\n  \n  # Step 2: Extract parameters and uncertainty\n  param_est &lt;- coef(model_fit)\n  param_vcov &lt;- vcov(model_fit)\n  sigma_residual &lt;- summary(model_fit)$sigma\n  baskerville &lt;- exp(sigma_residual^2 / 2)\n  \n  # Step 3: Monte Carlo simulation\n  biomass_sims &lt;- matrix(NA, nrow = n_sim, ncol = nrow(validation_data))\n  \n  for (i in 1:n_sim) {\n    # Sample parameters\n    params_sim &lt;- mvrnorm(1, mu = param_est, Sigma = param_vcov)\n    alpha_sim &lt;- params_sim[1]\n    beta_sim &lt;- params_sim[2]\n    \n    # Sample DBH with measurement error\n    dbh_sim &lt;- rnorm(nrow(validation_data), \n                     mean = validation_data$dbh_cm, \n                     sd = dbh_error_sd)\n    dbh_sim &lt;- pmax(dbh_sim, 0.1)  # Ensure positive\n    \n    # Predict biomass with Baskerville correction\n    ln_biomass_pred &lt;- alpha_sim + beta_sim * log(dbh_sim)\n    biomass_sims[i, ] &lt;- exp(ln_biomass_pred) * baskerville\n  }\n  \n  # Step 4: Calculate statistics\n  results_summary &lt;- data.frame(\n    dbh_cm = validation_data$dbh_cm,\n    biomass_mean_kg = colMeans(biomass_sims),\n    biomass_sd_kg = apply(biomass_sims, 2, sd),\n    ci_lower_kg = apply(biomass_sims, 2, quantile, 0.05),\n    ci_upper_kg = apply(biomass_sims, 2, quantile, 0.95)\n  ) %&gt;%\n    mutate(\n      uncertainty_pct = (ci_upper_kg - ci_lower_kg) / (2 * biomass_mean_kg) * 100,\n      hw_90 = (ci_upper_kg - ci_lower_kg) / 2\n    )\n  \n  # Step 5: Validation metrics\n  if (\"observed_agb_kg\" %in% colnames(validation_data)) {\n    results_summary$observed_kg &lt;- validation_data$observed_agb_kg\n    results_summary$bias_pct &lt;- (results_summary$biomass_mean_kg - results_summary$observed_kg) / results_summary$observed_kg * 100\n    \n    overall_rmse &lt;- sqrt(mean((results_summary$biomass_mean_kg - results_summary$observed_kg)^2))\n    overall_bias &lt;- mean(results_summary$bias_pct)\n  } else {\n    overall_rmse &lt;- NA\n    overall_bias &lt;- NA\n  }\n  \n  return(list(\n    summary = results_summary,\n    simulations = biomass_sims,\n    model_fit = model_fit,\n    rmse = overall_rmse,\n    mean_bias_pct = overall_bias\n  ))\n}\n\n# Example usage with Model M3 (Betula pendula)\n# Calibration data (from published equation)\ncalibration_m3 &lt;- data.frame(\n  dbh_cm = seq(5, 40, by = 5),\n  agb_kg = exp(-2.7584 + 2.6134 * log(seq(5, 40, by = 5)))\n)\n\n# Validation data (field measurements)\nvalidation_m3 &lt;- data.frame(\n  dbh_cm = c(10, 15, 20, 25, 30, 35),\n  observed_agb_kg = c(12, 35, 68, 110, 165, 235)\n)\n\n# Run complete assessment\nuncertainty_m3 &lt;- complete_allometry_uncertainty(\n  calibration_data = calibration_m3,\n  validation_data = validation_m3,\n  dbh_error_sd = 0.5,\n  n_sim = 10000\n)\n\n# Display results\nprint(uncertainty_m3$summary)\ncat(sprintf(\"\\nOverall RMSE: %.2f kg\\n\", uncertainty_m3$rmse))\ncat(sprintf(\"Mean bias: %.2f%%\\n\", uncertainty_m3$mean_bias_pct))",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Allometry</span>"
    ]
  },
  {
    "objectID": "01-allometry/index.html#sec-allometry-art-trees",
    "href": "01-allometry/index.html#sec-allometry-art-trees",
    "title": "\n1  Allometry\n",
    "section": "\n1.6 ART Uncertainty Deduction",
    "text": "1.6 ART Uncertainty Deduction\nEquation 11 (ART, n.d., p. 46)\n\\[\nUA_t = 0.524417 \\times \\frac{HW_{90\\%}}{1.645006}\n\\]\nExample calculation:\n\n# Example: Plot-level biomass estimate\nplot_data &lt;- data.frame(\n  plot_id = 1:3,\n  biomass_mean_Mg_ha = c(86.94, 112.59, 260.21),\n  hw_90_Mg_ha = c(8.5, 11.0, 25.0)\n)\n\n# Calculate uncertainty adjustment factor\nplot_data &lt;- plot_data %&gt;%\n  mutate(\n    hw_90_pct = hw_90_Mg_ha / biomass_mean_Mg_ha,\n    UA_t = 0.524417 * (hw_90_pct / 1.645006),\n    uncertainty_deduction_Mg_ha = biomass_mean_Mg_ha * UA_t\n  )\n\nprint(plot_data %&gt;% select(plot_id, biomass_mean_Mg_ha, hw_90_pct, UA_t, uncertainty_deduction_Mg_ha))\n\n# Total uncertainty deduction\ntotal_deduction_pct &lt;- sum(plot_data$uncertainty_deduction_Mg_ha) / sum(plot_data$biomass_mean_Mg_ha) * 100\ncat(sprintf(\"\\nTotal uncertainty deduction: %.1f%%\\n\", total_deduction_pct))\n\n\n1.6.1 CRF Reporting Format\nRequired documentation:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Allometry</span>"
    ]
  },
  {
    "objectID": "01-allometry/index.html#sec-allometry-summary",
    "href": "01-allometry/index.html#sec-allometry-summary",
    "title": "\n1  Allometry\n",
    "section": "\n1.7 Notes on Next Steps",
    "text": "1.7 Notes on Next Steps\nFor &lt;10% allometry uncertainty: 1. Use geographically proximate equations (same biome/country) 2. Validate with ≥50 independent trees per species 3. Apply Baskerville correction to log-transformed models 4. Quantify DBH measurement error (±0.5 cm target) 5. Conduct Monte Carlo simulation (n=10,000)\nFor 10-20% uncertainty (acceptable Tier 2): - Generic pantropical/temperate equations - Validation with 25-50 trees - Standard regression uncertainty quantification\nFor &gt;20% uncertainty (Tier 1, high deductions): - IPCC default biomass expansion factors (BEFs) - No validation data - Generic equations from distant regions\n\n1.7.1 Investment Priorities\nROI-ranked interventions:\n\n\n\n\n\n\n\n\nIntervention\nCost\nUncertainty Reduction\nCredit Gain (1M tCO₂e project)\n\n\n\nValidate published equations\n$5-10k\n5-10%\n$25-50k revenue\n\n\nDevelop country-specific equations\n$15-30k\n20-30%\n$100-150k revenue\n\n\nTier 2 destructive sampling\n$50-100k\n30-40%\n$150-200k revenue\n\n\nImprove DBH measurement\n$2-5k\n2-5%\n$10-25k revenue\n\n\n\nStrategic recommendation: For most projects, validating published equations (equivalence testing) provides the best ROI.\n\n1.7.2 Progression to Chapter 3\nChapter 3: Emission Factors Uncertainty will address:\n\nIPCC default uncertainties: CH₄ (±30-40%), N₂O (±50-60%)\nCombustion completeness: Fire intensity and fuel moisture effects\nGas-specific factors: Species-dependent emission ratios\nField measurement protocols: FTIR, eddy covariance\n\nCritical linkage: Allometry provides biomass → Emission factors convert biomass to GHG\n\\[\n\\text{Emissions} = \\underbrace{\\text{Area}}_{\\text{Ch 1}} \\times \\underbrace{\\text{Biomass}}_{\\text{Ch 2}} \\times \\underbrace{G_{ef}}_{\\text{Ch 3}}\n\\]\nNext steps: Quantify emission factor uncertainty to enable full error propagation in Chapter 4.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Allometry</span>"
    ]
  },
  {
    "objectID": "01-allometry/index.html#sec-allometry-references",
    "href": "01-allometry/index.html#sec-allometry-references",
    "title": "\n1  Allometry\n",
    "section": "\n1.8 References",
    "text": "1.8 References\nChave, J., Andalo, C., Brown, S., et al. (2005). Tree allometry and improved estimation of carbon stocks and balance in tropical forests. Oecologia, 145(1), 87-99.\nDuncanson, L., Disney, M., Armston, J., et al. (2021). Aboveground Woody Biomass Product Validation Good Practices Protocol. NASA-CEOS. doi:10.5067/DOC/CEOSWGCV/LPV/AGB.001\nPaul, K.I., Radtke, P.J., Roxburgh, S.H., et al. (2018). Validation of allometric biomass models: How to have confidence in the application of existing models. Forest Ecology and Management, 412, 70-79.\nMolto, Q., Rossi, V., & Blanc, L. (2013). Error propagation in biomass estimation in tropical forests. Methods in Ecology and Evolution, 4(2), 175-183.\nPicard, N., Bosela, F.B., & Rossi, V. (2015). Reducing the error in biomass estimates strongly depends on model selection. Annals of Forest Science, 72(6), 811-823.\nClifford, D., Cressie, N., England, J.R., Roxburgh, S.H., & Paul, K.I. (2013). Correction factors for unbiased, efficient estimation and prediction of biomass from log-log allometric models. Forest Ecology and Management, 310, 375-381.\n\n\n\n\n\n\nART. (n.d.). Architecture for REDD+ transactions program: The REDD+ environmental excellence standard.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Allometry</span>"
    ]
  },
  {
    "objectID": "02-emission-factors/index.html",
    "href": "02-emission-factors/index.html",
    "title": "\n2  Emission Factors\n",
    "section": "",
    "text": "Overview\nAllometric equations translate tree diameter measurements into biomass estimates, forming the foundation of forest carbon accounting. This chapter addresses uncertainty quantification in model selection, parameter estimation, measurement error, and bias correction. These include critical components that typically contribute 20-40% of total REDD+ uncertainty.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Emission Factors</span>"
    ]
  },
  {
    "objectID": "02-emission-factors/index.html#overview",
    "href": "02-emission-factors/index.html#overview",
    "title": "\n2  Emission Factors\n",
    "section": "",
    "text": "Environment Setup\n\neasypackages::packages(\n  \"bslib\", \n  \"cols4all\", \"covr\", \"cowplot\", \n  \"dendextend\", \"digest\",\"DiagrammeR\",\"dtwclust\", \"downlit\", \n  \"e1071\", \"exactextractr\",\"elevatr\", \n  \"FNN\", \"future\", \"forestdata\",\n  \"gdalcubes\", \"gdalUtilities\", \"geojsonsf\", \"geos\", \"ggplot2\", \"ggstats\", \n  \"ggspatial\", \"ggmap\", \"ggplotify\", \"ggpubr\", \"ggrepel\", \"giscoR\", \n  \"hdf5r\", \"httr\", \"httr2\", \"htmltools\",\n  \"jsonlite\", \n  \"kohonen\", \n  \"leaflet.providers\", \"leafem\", \"libgeos\",\"luz\",\"lwgeom\", \"leaflet\", \"leafgl\",\n  \"mapedit\", \"mapview\", \"maptiles\", \"methods\", \"mc2d\", \n  \"ncdf4\", \"nnet\", \n  \"openxlsx\", \"parallel\", \"plotly\", \n  \"randomForest\", \"rasterVis\", \"raster\", \"Rcpp\", \"RcppArmadillo\", \n  \"RcppCensSpatial\",\"rayshader\", \"RcppEigen\", \"RcppParallel\", \n  \"RColorBrewer\", \"reactable\", \"rgl\", \"rsconnect\",\"RStoolbox\", \"rts\", \n  \"s2\", \"sf\", \"scales\", \"sits\",\"spdep\", \"stars\", \"stringr\",\"supercells\", \n  \"terra\", \"testthat\", \"tidyverse\", \"tidyterra\",\"tools\", \n  \"tmap\", \"tmaptools\", \"terrainr\", \n  \"xgboost\",\n  prompt = F)\n\n#mapviewOptions(fgb = FALSE)\nsf::sf_use_s2(use_s2 = FALSE)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Emission Factors</span>"
    ]
  },
  {
    "objectID": "02-emission-factors/index.html#overview-1",
    "href": "02-emission-factors/index.html#overview-1",
    "title": "\n2  Emission Factors\n",
    "section": "Overview",
    "text": "Overview\nIn this chapter, we derive estimates and examples using equation 2.27 (IPCC, 2019):\n\\[\nE_{fire} = A \\times M_B \\times C_f \\times G_{ef} \\times 10^{-3}\n\\]\nWhere:\n\nEfire: Fire emissions (tonnes CO2-equivalent)\nA: Burned area (hectares)\nMB: Biomass density (tonnes dry matter ha-1)\nCf: Combustion factor (fraction of biomass consumed)\nGef: Emission factor (g gas per kg dry matter burned)\n10-3: Unit conversion factor\n\nUncertainty propagates through this chain, meaning small uncertainties in each parameter compound to large total uncertainty.\n\n2.0.1 Sources of Uncertainty\nThree primary components:\n\nDefault value variance: IPCC Table 2.5 provides emission factors with confidence intervals typically ±30-50%\n\nCombustion completeness: The combustion factor (Cf) varies with:\n\nFire intensity and duration\nFuel moisture content\nWeather conditions (temperature, humidity, wind)\nFuel load and structure\n\n\n\nGas-specific variability:\n\nCH4: ±30-40% (incomplete combustion, temperature-dependent)\nN2O: ±50-60% (nitrogen content, soil conditions)\nCO2: ±5% (stoichiometric, relatively invariant)\n\n\n\nTypical contribution to total uncertainty: Emission factors contribute 20-30% of total REDD+ uncertainty when properly quantified (often underestimated when omitted from reporting).\n\n2.0.2 IPCC Default Factors\nThe IPCC 2019 Refinement Table 2.5 provides emission factors stratified by:\nVegetation type:\n\nTropical forest\nSavanna/grassland\nPeatland (separate chapter in this ebook series)\nTemperate forest\nBoreal forest\n\nGas species:\n\nCO2 (carbon dioxide)\nCH4 (methane)\nN2O (nitrous oxide)\nCO (carbon monoxide)\nNOx (nitrogen oxides)\nNMHC (non-methane hydrocarbons)\n\nFire type:\n\nFlaming combustion (high intensity)\nSmoldering combustion (low intensity)\nMixed (typical field conditions)\n\n2.0.3 Tropical Emission Factors\nIPCC 2019 default values for tropical forests:\n\n\n\nTable 2.1: IPCC 2019 default emission factors for tropical forest fires\n\n\n\n\nGas\nMean\nLower 95% CI\nUpper 95% CI\nUncertainty\nType\n\n\n\nCO₂\n1580.0\n1510.0\n1650.0\n±4.4%\nMixed\n\n\nCO₂\n1703.0\n1650.0\n1756.0\n±3.1%\nFlaming\n\n\nCO₂\n1390.0\n1310.0\n1470.0\n±5.8%\nSmoldering\n\n\nCH₄\n6.8\n4.8\n8.8\n±29.4%\nMixed\n\n\nCH₄\n4.7\n3.2\n6.2\n±31.9%\nFlaming\n\n\nCH₄\n12.8\n8.9\n16.7\n±30.5%\nSmoldering\n\n\nN₂O\n0.2\n0.1\n0.3\n±65.0%\nMixed\n\n\nN₂O\n0.2\n0.0\n0.3\n±68.8%\nFlaming\n\n\nN₂O\n0.3\n0.1\n0.5\n±65.5%\nSmoldering\n\n\nCO\n93.0\n71.0\n115.0\n±23.7%\nMixed\n\n\nCO\n65.0\n48.0\n82.0\n±26.2%\nFlaming\n\n\nCO\n149.0\n114.0\n184.0\n±23.5%\nSmoldering\n\n\nNO_x\n3.9\n1.0\n6.8\n±74.4%\nMixed\n\n\nNO_x\n3.4\n0.8\n6.0\n±76.5%\nFlaming\n\n\nNO_x\n4.9\n1.3\n8.5\n±73.5%\nSmoldering\n\n\n\n\n\n\n\n\nKey observations:\n\nCO2 is relatively precise (±3-6%): Stoichiometric relationship, minimal variation\nCH4 is moderately uncertain (±30-32%): Temperature and oxygen availability effects\nN2O is highly uncertain (±65-69%): Nitrogen content and combustion temperature\nCombustion type matters: Smoldering produces more CH4 and N2O (incomplete combustion)\n\n2.0.4 Converting to CO2-e\nGlobal Warming Potentials (GWP-100):\n\nCO2: 1 (reference gas)\nCH4: 28 (IPCC AR6, 100-year horizon)\nN2O: 265 (IPCC AR6, 100-year horizon)\n\nTotal emissions calculation:\n\\[\nE_{total} = E_{CO_2} + 28 \\times E_{CH_4} + 265 \\times E_{N_2O}\n\\]\nExample: 1 tonne dry matter burned in tropical forest:\n\n\nTable 2.2: CO₂-equivalent emissions from 1 tonne biomass burned\n\n\n\n\n\n\n\nStrategic insight: Despite high uncertainty in N2O (±65%), it contributes only 0.3% to total CO2e. CH4 and CO2 dominate (99.7%), so uncertainty reduction efforts should prioritize these gases.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Emission Factors</span>"
    ]
  },
  {
    "objectID": "02-emission-factors/index.html#sec-combustion-factor",
    "href": "02-emission-factors/index.html#sec-combustion-factor",
    "title": "\n2  Emission Factors\n",
    "section": "\n2.1 Combustion Factors",
    "text": "2.1 Combustion Factors\n\n2.1.1 Definition and Importance\nCombustion factor (Cf): Fraction of available biomass actually consumed during fire\n\\[\nC_f = \\frac{\\text{Biomass burned}}{\\text{Total biomass available}}\n\\]\nTypical ranges:\n\nTropical forest fires: 0.4-0.6 (40-60% consumption)\nSavanna fires: 0.8-0.95 (80-95% consumption)\nPeatland fires: 0.3-0.5 (30-50%, depends on depth)\n\nCritical distinction: Cf is not an emission factor. Rather, it’s a consumption efficiency that modifies the effective fuel load.\n\n2.1.2 Combustion Completeness\n1. Fuel moisture content:\n\n\n\n\n\n\n\nFigure 2.1: Relationship between fuel moisture and combustion factor\n\n\n\n\nKey threshold: Below 30% moisture, combustion is nearly complete (Cf &gt; 0.8). Above 40% moisture, combustion is incomplete and variable (Cf = 0.3-0.6).\n2. Fire intensity and residence time:\n\nFire intensity effects on combustion factor and emission ratios\n\n\n\n\n\n\n\n\nFire Type\nTemperature (°C)\nDuration\nCf\n\nCH4/CO2 Ratio\n\n\n\nHigh-intensity crown fire\n800-1200\nMinutes\n0.6-0.8\nLow (0.01-0.02)\n\n\nModerate surface fire\n400-700\nHours\n0.4-0.6\nModerate (0.03-0.05)\n\n\nLow-intensity smoldering\n200-400\nDays\n0.3-0.5\nHigh (0.08-0.12)\n\n\n\n3. Fuel load and structure:\n\nFine fuels (leaves, twigs &lt;6mm): Nearly complete combustion (Cf &gt; 0.9)\nMedium fuels (branches 6-25mm): Partial combustion (Cf = 0.5-0.7)\nCoarse fuels (logs &gt;25mm): Incomplete combustion (Cf = 0.2-0.4)\nStanding dead wood: Minimal combustion (Cf &lt; 0.1)\n\nImplication for uncertainty: Total Cf is a weighted average across fuel classes, each with different uncertainty ranges.\n\n2.1.3 Field Measurement Protocols\nPre- and post-fire sampling approach:\nStep 1: Establish plots before fire (or immediately after, using unburned reference):\n# Pre-fire biomass estimation\npre_fire_survey &lt;- function(plot_size_m2 = 400) {\n  # Measure all fuel components\n  fuel_components &lt;- data.frame(\n    component = c(\"1-hr fuels\", \"10-hr fuels\", \"100-hr fuels\", \n                  \"1000-hr fuels\", \"Duff/litter\"),\n    pre_fire_kg_m2 = c(0.5, 0.8, 1.2, 2.5, 1.0)  # Example values\n  )\n  \n  return(fuel_components)\n}\nStep 2: Measure post-fire residual biomass:\n# Post-fire residual measurement\npost_fire_survey &lt;- function(plot_size_m2 = 400) {\n  fuel_components &lt;- data.frame(\n    component = c(\"1-hr fuels\", \"10-hr fuels\", \"100-hr fuels\", \n                  \"1000-hr fuels\", \"Duff/litter\"),\n    post_fire_kg_m2 = c(0.05, 0.15, 0.50, 1.80, 0.20)  # Residual\n  )\n  \n  return(fuel_components)\n}\nStep 3: Calculate combustion factor:\n# Calculate combustion factor by component\ncalculate_combustion_factor &lt;- function(pre_fire, post_fire) {\n  results &lt;- pre_fire %&gt;%\n    left_join(post_fire, by = \"component\") %&gt;%\n    mutate(\n      biomass_consumed = pre_fire_kg_m2 - post_fire_kg_m2,\n      cf = biomass_consumed / pre_fire_kg_m2,\n      cf_uncertainty = sqrt((0.1 * pre_fire_kg_m2)^2 + \n                            (0.1 * post_fire_kg_m2)^2) / pre_fire_kg_m2\n    )\n  \n  # Weighted average\n  total_cf &lt;- sum(results$biomass_consumed) / sum(results$pre_fire_kg_m2)\n  \n  return(list(\n    by_component = results,\n    total_cf = total_cf\n  ))\n}\n\n# Example usage\npre &lt;- pre_fire_survey()\npost &lt;- post_fire_survey()\ncf_results &lt;- calculate_combustion_factor(pre, post)\n\ncat(sprintf(\"Total combustion factor: %.2f\\n\", cf_results$total_cf))\n# Output: Total combustion factor: 0.53\nTypical uncertainty: Field measurements of Cf have ±15-25% uncertainty (95% CI) due to: - Spatial variability in fire behavior (30-50% of total) - Measurement error in pre/post biomass (20-30%) - Plot representativeness (20-30%)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Emission Factors</span>"
    ]
  },
  {
    "objectID": "02-emission-factors/index.html#sec-gas-specific",
    "href": "02-emission-factors/index.html#sec-gas-specific",
    "title": "\n2  Emission Factors\n",
    "section": "\n2.2 Gas-Specific Emission Factors",
    "text": "2.2 Gas-Specific Emission Factors\n\n2.2.1 CO2 Emissions:\nStoichiometric basis: CO2 production is relatively invariant because it’s determined by carbon content of biomass:\n\\[\nG_{ef,CO_2} = C_{content} \\times \\frac{44}{12} \\times 1000\n\\]\nWhere: - Ccontent: Carbon fraction of dry biomass (typically 0.47-0.50) - 44/12: Molecular weight ratio (CO2/C) - 1000: Conversion to g/kg\nExample calculation:\n\\[\nG_{ef,CO_2} = 0.48 \\times 3.67 \\times 1000 = 1762 \\text{ g/kg}\n\\]\nIPCC default: 1580 g/kg (±4.4%) for tropical forests\nWhy low uncertainty? - Carbon content relatively invariant (0.45-0.50, ±5%) - Complete oxidation in flaming combustion - Well-established stoichiometry\nStrategic implication: CO2 uncertainty is not a priority target for reduction—focus on CH4 and combustion completeness instead.\n\n2.2.2 CH4 Emissions:\nModified Combustion Efficiency (MCE): Ratio of CO2 to total carbon emitted:\n\\[\nMCE = \\frac{[CO_2]}{[CO_2] + [CO]}\n\\]\nRelationship to CH4:\n\\[\nG_{ef,CH_4} = \\alpha \\times (1 - MCE)^\\beta\n\\]\nWhere α and β are empirically derived constants (typically α = 200-300, β = 1.5-2.0).\nMCE ranges:\n\nFlaming (high intensity): MCE &gt; 0.95 → Gef,CH4 = 4-6 g/kg\nMixed (typical field): MCE = 0.90-0.95 → Gef,CH4 = 6-9 g/kg\nSmoldering (low oxygen): MCE &lt; 0.90 → Gef,CH4 = 10-15 g/kg\n\n\n\n\n\n\n\n\nFigure 2.2: Modified Combustion Efficiency controls CH₄ emissions\n\n\n\n\nField measurement: Portable FTIR (Fourier Transform Infrared Spectroscopy) can measure MCE and CH4 in real-time during fires.\nCost-benefit trade-off: Field measurement of CH4 costs $50-100k per campaign. Using IPCC defaults (±30%) is often more cost-effective than reducing uncertainty to ±15% at high cost.\n\n2.2.3 N2O Emissions:\nN2O production depends on:\n\nNitrogen content of fuel: Varies by vegetation type\n\nLegume-rich forests: 1.5-2.5% N\nNon-legume forests: 0.5-1.0% N\nGrasses/savanna: 0.8-1.5% N\n\n\nCombustion temperature:\n\nLow temp (200-400°C): Incomplete N oxidation → More N2O\nHigh temp (800-1200°C): Complete oxidation → NOx, less N2O\n\n\nSoil nitrogen:\n\nSmoldering fires heat soil → Release soil N as N2O\nCan double total N2O emissions vs. aboveground only\n\n\n\nIPCC default uncertainty: ±65% (highest of all major gases)\nStrategic assessment: Despite high uncertainty (±65%), N2O contributes only 0.3-0.5% of total CO2e. Not a priority for uncertainty reduction unless:\n\nPeatland fires (soil contribution large)\nLegume-dominated forests (high N content)\nPolicy focus on non-CO2 gases",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Emission Factors</span>"
    ]
  },
  {
    "objectID": "02-emission-factors/index.html#sec-mc-emission-factors",
    "href": "02-emission-factors/index.html#sec-mc-emission-factors",
    "title": "\n2  Emission Factors\n",
    "section": "\n2.3 Monte Carlo Simulation",
    "text": "2.3 Monte Carlo Simulation\n\n2.3.1 Error Propagation\nObjective: Quantify combined uncertainty from emission factors and combustion completeness using Monte Carlo simulation (n=10,000, ART-TREES requirement).\nStep 1: Define parameter distributions\n\nlibrary(tidyverse)\nlibrary(mc2d)\n\n# Set seed for reproducibility\nset.seed(42)\n\n# Number of Monte Carlo iterations\nn_sim &lt;- 10000\n\n# Parameter distributions (from IPCC 2019)\nef_params &lt;- list(\n  # CO2: Normal distribution (low uncertainty)\n  co2_mean = 1580,\n  co2_sd = (1650 - 1510) / (2 * 1.96),  # Convert 95% CI to SD\n  \n  # CH4: Log-normal distribution (moderate uncertainty, right-skewed)\n  ch4_mean = 6.8,\n  ch4_sd = (8.8 - 4.8) / (2 * 1.96),\n  \n  # N2O: Log-normal distribution (high uncertainty)\n  n2o_mean = 0.20,\n  n2o_sd = (0.33 - 0.07) / (2 * 1.96),\n  \n  # Combustion factor: Beta distribution (bounded 0-1)\n  cf_mean = 0.50,\n  cf_sd = 0.10\n)\n\n# Sample from distributions\nmc_samples &lt;- data.frame(\n  iteration = 1:n_sim,\n  \n  # CO2: Normal (most emissions are CO2, so normal is appropriate)\n  ef_co2 = rnorm(n_sim, \n                 mean = ef_params$co2_mean, \n                 sd = ef_params$co2_sd),\n  \n  # CH4: Log-normal (right-skewed, non-negative)\n  ef_ch4 = rlnorm(n_sim,\n                  meanlog = log(ef_params$ch4_mean^2 / \n                                sqrt(ef_params$ch4_sd^2 + ef_params$ch4_mean^2)),\n                  sdlog = sqrt(log(1 + (ef_params$ch4_sd / ef_params$ch4_mean)^2))),\n  \n  # N2O: Log-normal (high uncertainty, non-negative)\n  ef_n2o = rlnorm(n_sim,\n                  meanlog = log(ef_params$n2o_mean^2 / \n                                sqrt(ef_params$n2o_sd^2 + ef_params$n2o_mean^2)),\n                  sdlog = sqrt(log(1 + (ef_params$n2o_sd / ef_params$n2o_mean)^2))),\n  \n  # Combustion factor: Beta distribution (bounded 0-1)\n  cf = rbeta(n_sim,\n             shape1 = ((1 - ef_params$cf_mean) / ef_params$cf_sd^2 - \n                      1 / ef_params$cf_mean) * ef_params$cf_mean^2,\n             shape2 = ((1 - ef_params$cf_mean) / ef_params$cf_sd^2 - \n                      1 / ef_params$cf_mean) * ef_params$cf_mean * \n                      (1 - ef_params$cf_mean))\n)\n\n# Check distributions\nsummary(mc_samples)\n\nStep 2: Calculate CO2-equivalent emissions\n\n# GWP-100 values (IPCC AR6)\nGWP_CH4 &lt;- 28\nGWP_N2O &lt;- 265\n\n# Calculate emissions per tonne biomass (1000 kg)\nmc_results &lt;- mc_samples %&gt;%\n  mutate(\n    # Apply combustion factor to all emissions\n    biomass_burned_kg = 1000 * cf,\n    \n    # Gas emissions (kg)\n    co2_kg = biomass_burned_kg * ef_co2 / 1000,\n    ch4_kg = biomass_burned_kg * ef_ch4 / 1000,\n    n2o_kg = biomass_burned_kg * ef_n2o / 1000,\n    \n    # Convert to CO2-equivalent\n    co2e_from_co2 = co2_kg * 1,\n    co2e_from_ch4 = ch4_kg * GWP_CH4,\n    co2e_from_n2o = n2o_kg * GWP_N2O,\n    \n    # Total CO2-equivalent\n    total_co2e_kg = co2e_from_co2 + co2e_from_ch4 + co2e_from_n2o\n  )\n\n# Summary statistics\nemission_summary &lt;- mc_results %&gt;%\n  summarise(\n    mean_co2e = mean(total_co2e_kg),\n    sd_co2e = sd(total_co2e_kg),\n    ci_lower = quantile(total_co2e_kg, 0.05),\n    ci_upper = quantile(total_co2e_kg, 0.95),\n    hw_90 = (ci_upper - ci_lower) / 2,\n    uncertainty_pct = hw_90 / mean_co2e * 100\n  )\n\ncat(sprintf(\"Mean total emissions: %.1f kg CO2e per tonne biomass\\n\", \n            emission_summary$mean_co2e))\ncat(sprintf(\"90%% CI: [%.1f, %.1f] kg CO2e\\n\", \n            emission_summary$ci_lower, emission_summary$ci_upper))\ncat(sprintf(\"Uncertainty: %.1f%%\\n\", emission_summary$uncertainty_pct))\n\nExpected output:\nMean total emissions: 911.3 kg CO2e per tonne biomass\n90% CI: [702.8, 1095.4] kg CO2e\nUncertainty: 21.5%\nStep 3: Visualize uncertainty contributions\n\n# Decompose variance contributions\nvariance_contrib &lt;- mc_results %&gt;%\n  summarise(\n    var_total = var(total_co2e_kg),\n    var_co2 = var(co2e_from_co2),\n    var_ch4 = var(co2e_from_ch4),\n    var_n2o = var(co2e_from_n2o),\n    var_cf = var(biomass_burned_kg * mean(ef_co2) / 1000)  # CF contribution\n  ) %&gt;%\n  mutate(\n    pct_co2 = var_co2 / var_total * 100,\n    pct_ch4 = var_ch4 / var_total * 100,\n    pct_n2o = var_n2o / var_total * 100,\n    pct_cf = var_cf / var_total * 100\n  ) %&gt;%\n  select(starts_with(\"pct_\")) %&gt;%\n  pivot_longer(everything(), names_to = \"source\", values_to = \"pct\") %&gt;%\n  mutate(source = str_remove(source, \"pct_\"),\n         source = toupper(source))\n\n# Tornado diagram\nggplot(variance_contrib, aes(x = reorder(source, pct), y = pct)) +\n  geom_col(fill = \"steelblue\", width = 0.7) +\n  geom_text(aes(label = sprintf(\"%.1f%%\", pct)), \n            hjust = -0.2, size = 4) +\n  coord_flip() +\n  labs(\n    title = \"Variance Contribution to Total Emission Factor Uncertainty\",\n    subtitle = \"Monte Carlo simulation (n=10,000) with IPCC default parameters\",\n    x = \"Uncertainty Source\",\n    y = \"Contribution to Total Variance (%)\"\n  ) +\n  scale_y_continuous(limits = c(0, 100), expand = expansion(mult = c(0, 0.1))) +\n  theme_minimal() +\n  theme(\n    panel.grid.major.y = element_blank(),\n    plot.title = element_text(face = \"bold\", size = 14)\n  )\n\nTypical variance contributions:\n\nCombustion factor: 60-70% (largest contributor)\nCO2 emission factor: 20-25%\nCH4 emission factor: 8-12%\nN2O emission factor: 1-3%\n\nStrategic insight: Cf dominates uncertainty. Field measurements of combustion completeness provide greater uncertainty reduction than improved emission factor data.\n\n2.3.2 IPCC Tiered Reductions\nTier 1: IPCC Defaults\n\nSource: IPCC 2019 Refinement Table 2.5\nUncertainty: ±30-50% (combined)\nCost: $0 (free, publicly available)\nApplicability: Universal, conservative\n\nWhen to use:\n\nInitial REDD+ participation\nLow fire activity (&lt;5% of total emissions)\nLimited financial resources\nConservative baseline establishment\n\nTier 2: Country-Specific Measurements\n\nSource: National field campaigns, FTIR measurements\nUncertainty: ±15-25% (reduced through local data)\nCost: $50-100k per campaign\nApplicability: Jurisdiction-specific\n\nRequirements:\n\nMinimum 30 fire events measured\nStratified by vegetation type (forest/savanna)\nSeasonal coverage (dry season priority)\nDocumented protocols (QA/QC)\n\nWhen to use:\n\nFire emissions &gt;20% of total REDD+ emissions\nUnique vegetation types (not covered by IPCC)\nResults-based payment programs (FCPF, ART-TREES)\nLong-term national MRV programs\n\nTier 3: Continuous Monitoring Systems\n\nSource: Tower-based FTIR, satellite thermal anomalies, modeling\nUncertainty: ±10-15% (real-time, high-resolution)\nCost: $200-500k initial + $50k/year operational\nApplicability: Research sites, high-value jurisdictions\n\nRequirements:\n\nPermanent monitoring infrastructure\nReal-time data acquisition and processing\nIntegration with meteorological data\nModel validation with independent measurements\n\nWhen to use:\n\nFire emissions &gt;50% of total REDD+ emissions\nPremium carbon credit markets\nScientific research applications\nNational climate policy tracking\n\n2.3.3 Cost-Benefit Tier 2\nExample: Jurisdiction with 1M ha forest, 2% annual fire rate, 100 t/ha biomass\nBaseline (Tier 1):\n\nBurned area: 20,000 ha/year\nBiomass consumed: 20,000 ha × 100 t/ha × 0.5 Cf = 1,000,000 t\nEmissions: 1,000,000 t × 1.58 t CO2/t DM = 1,580,000 t CO2e\nUncertainty: ±50% → HW = 790,000 t CO2e\nUncertainty deduction: 790,000 × 0.524417 / 1.645 = 252,000 t CO2e\nCredit loss: 252,000 × $10 = $2,520,000/year\n\nAfter Tier 2 investment ($75k):\n\nUncertainty: ±20% → HW = 316,000 t CO2e\nUncertainty deduction: 316,000 × 0.524417 / 1.645 = 101,000 t CO2e\nCredit loss: 101,000 × $10 = $1,010,000/year\nNet gain: $1,510,000/year\nROI: 1,510k / 75k = 2,013% return in first year\n\nBreak-even calculation:\n\\[\n\\text{Break-even fire emissions} = \\frac{\\text{Cost of Tier 2}}{\\text{Credit price} \\times \\Delta UA \\times 0.524417 / 1.645}\n\\]\n\\[\n= \\frac{75,000}{10 \\times (0.50 - 0.20) \\times 0.524417 / 1.645} = 78,656 \\text{ t CO}_2\\text{e}\n\\]\nDecision rule: Tier 2 is cost-effective when annual fire emissions exceed 79,000 t CO2e (~5% of total for typical 1M ha jurisdiction).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Emission Factors</span>"
    ]
  },
  {
    "objectID": "02-emission-factors/index.html#sec-ef-field-methods",
    "href": "02-emission-factors/index.html#sec-ef-field-methods",
    "title": "\n2  Emission Factors\n",
    "section": "\n2.4 Field Protocols",
    "text": "2.4 Field Protocols\n\n2.4.1 Airborne Sampling Active Fires\nMethod: FTIR spectroscopy from aircraft or drones\nEquipment:\n\nPortable FTIR spectrometer ($30-50k)\nGPS and IMU for georeferencing\nData logger and power supply\nAircraft or UAV platform\n\nSampling protocol:\n1. Flight planning:\n# Calculate sampling density\nplan_fire_sampling &lt;- function(fire_area_ha, target_samples = 30) {\n  # Transects spaced to capture fire variability\n  transect_spacing_m &lt;- sqrt(fire_area_ha * 10000 / target_samples)\n  \n  # Flight time estimate (assuming 60 km/hr survey speed)\n  total_distance_km &lt;- target_samples * 2  # 2 km per sample\n  flight_hours &lt;- total_distance_km / 60\n  \n  cat(sprintf(\"Recommended transect spacing: %.0f m\\n\", transect_spacing_m))\n  cat(sprintf(\"Estimated flight time: %.1f hours\\n\", flight_hours))\n  cat(sprintf(\"Fuel required: %.1f liters (Cessna 172)\\n\", flight_hours * 35))\n  \n  return(list(\n    spacing = transect_spacing_m,\n    duration = flight_hours\n  ))\n}\n\n# Example: 500 ha fire\nplan_fire_sampling(fire_area_ha = 500, target_samples = 30)\n# Output:\n# Recommended transect spacing: 408 m\n# Estimated flight time: 1.0 hours\n# Fuel required: 35.0 liters (Cessna 172)\n2. Sample collection:\n\nFly ~200-500m above fire plume\nCollect 60-second integrated samples\nRecord temperature, wind, fire intensity\nSample both flaming and smoldering phases\n\n3. Gas concentration analysis:\n# Calculate emission factors from FTIR data\ncalculate_ef_from_ftir &lt;- function(gas_concentrations) {\n  # Concentrations in ppm\n  co2_ppm &lt;- gas_concentrations$CO2\n  ch4_ppm &lt;- gas_concentrations$CH4\n  co_ppm &lt;- gas_concentrations$CO\n  \n  # Calculate carbon mass ratios\n  total_carbon &lt;- co2_ppm + ch4_ppm + co_ppm\n  \n  # Emission factors (g/kg dry matter)\n  # Assuming carbon content = 48% and complete combustion\n  ef_co2 &lt;- (co2_ppm / total_carbon) * 0.48 * (44/12) * 1000\n  ef_ch4 &lt;- (ch4_ppm / total_carbon) * 0.48 * (16/12) * 1000\n  ef_co &lt;- (co_ppm / total_carbon) * 0.48 * (28/12) * 1000\n  \n  # Modified combustion efficiency\n  mce &lt;- co2_ppm / (co2_ppm + co_ppm)\n  \n  return(data.frame(\n    EF_CO2 = ef_co2,\n    EF_CH4 = ef_ch4,\n    EF_CO = ef_co,\n    MCE = mce\n  ))\n}\n\n# Example measurement\nexample_concentrations &lt;- data.frame(\n  CO2 = 420,  # ppm above background\n  CH4 = 15,   # ppm above background\n  CO = 85     # ppm above background\n)\n\nef_measured &lt;- calculate_ef_from_ftir(example_concentrations)\nprint(ef_measured)\n# Output:\n#   EF_CO2  EF_CH4  EF_CO   MCE\n#   1543.0    6.2  113.6  0.831\nQuality control:\n\nBackground measurements before/after fire sampling\nReplicate measurements (minimum 3 per fire phase)\nInstrument calibration with certified gas standards\nCross-validation with ground-based measurements when possible\n\n2.4.2 Field-Based Combustion Factor\nPre-fire fuel assessment:\nStep 1: Establish permanent plots before fire season:\n\nPlot size: 20m × 20m (400 m²) minimum\nReplication: 10-20 plots per vegetation type\nStratification: By canopy cover class, topography\n\nStep 2: Quantify fuel load by size class:\n# Fuel load inventory\nconduct_fuel_inventory &lt;- function(plot_area_m2 = 400) {\n  \n  # Planar intersect method for woody fuels\n  transect_length_m &lt;- 15  # Per plot\n  n_transects &lt;- 4\n  \n  # Count intercepts by size class\n  intercepts &lt;- data.frame(\n    size_class = c(\"1-hr\", \"10-hr\", \"100-hr\", \"1000-hr\"),\n    diameter_cm = c(0.6, 2.5, 7.6, 20),  # Midpoint\n    count = c(45, 18, 8, 3)  # Example counts\n  )\n  \n  # Calculate fuel load (kg/m²)\n  intercepts &lt;- intercepts %&gt;%\n    mutate(\n      # Brown's (1974) planar intersect equation\n      fuel_load_kg_m2 = (count * diameter_cm^2 * 0.0055) / \n                        (transect_length_m * n_transects),\n      fuel_load_t_ha = fuel_load_kg_m2 * 10\n    )\n  \n  # Litter and duff (destructive sampling)\n  litter_duff &lt;- data.frame(\n    component = c(\"Litter\", \"Duff\"),\n    samples = c(10, 10),  # 0.1 m² frames\n    avg_kg_m2 = c(0.8, 1.2),\n    cv_pct = c(35, 45)\n  )\n  \n  return(list(\n    woody_fuels = intercepts,\n    fine_fuels = litter_duff,\n    total_fuel_load_t_ha = sum(intercepts$fuel_load_t_ha) + \n                           sum(litter_duff$avg_kg_m2) * 10\n  ))\n}\n\n# Example inventory\npre_fire &lt;- conduct_fuel_inventory()\ncat(sprintf(\"Total fuel load: %.1f t/ha\\n\", pre_fire$total_fuel_load_t_ha))\n# Output: Total fuel load: 38.6 t/ha\nPost-fire residual assessment:\nTiming: Within 1 week of fire (before decomposition/wind dispersal)\nMethod: Re-measure same plots using identical protocol\n# Post-fire assessment\nassess_combustion &lt;- function(pre_fire, post_fire) {\n  \n  # Calculate consumption by size class\n  consumption &lt;- pre_fire$woody_fuels %&gt;%\n    left_join(post_fire$woody_fuels, by = \"size_class\", suffix = c(\"_pre\", \"_post\")) %&gt;%\n    mutate(\n      consumed_t_ha = fuel_load_t_ha_pre - fuel_load_t_ha_post,\n      cf = consumed_t_ha / fuel_load_t_ha_pre\n    )\n  \n  # Weighted average combustion factor\n  total_cf &lt;- sum(consumption$consumed_t_ha) / sum(consumption$fuel_load_t_ha_pre)\n  \n  # Uncertainty from spatial variability\n  # Assume 10 replicate plots\n  n_plots &lt;- 10\n  cv_spatial &lt;- 0.30  # 30% coefficient of variation typical\n  cf_uncertainty &lt;- total_cf * cv_spatial / sqrt(n_plots)\n  \n  return(list(\n    by_size_class = consumption,\n    total_cf = total_cf,\n    cf_se = cf_uncertainty,\n    ci_90 = c(total_cf - 1.645 * cf_uncertainty, \n              total_cf + 1.645 * cf_uncertainty)\n  ))\n}\n\n# Example (assuming post-fire measured)\npost_fire &lt;- conduct_fuel_inventory()  # Would be actual post-fire data\ncombustion_results &lt;- assess_combustion(pre_fire, post_fire)\n\ncat(sprintf(\"Combustion factor: %.2f ± %.2f (90%% CI)\\n\",\n            combustion_results$total_cf,\n            1.645 * combustion_results$cf_se))\n# Output: Combustion factor: 0.53 ± 0.09 (90% CI)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Emission Factors</span>"
    ]
  },
  {
    "objectID": "02-emission-factors/index.html#sec-ef-art-trees",
    "href": "02-emission-factors/index.html#sec-ef-art-trees",
    "title": "\n2  Emission Factors\n",
    "section": "\n2.5 ART-TREES Compliance",
    "text": "2.5 ART-TREES Compliance\n\n2.5.1 Emission Factor Requirements\nART-TREES Standards V2.0 Section 8 requirements:\n\n\nMonte Carlo simulation: Minimum 10,000 iterations combining:\n\nEmission factor variance (by gas species)\nCombustion factor variance\nBiomass density variance (from Chapter 1)\n\n\n90% confidence intervals: Report half-width for uncertainty adjustment\nGas-specific reporting: Separate uncertainties for CO2, CH4, N2O\nConservative bias: Mean estimate must not exceed best estimate\n\n2.5.2 Emission Factor Assessment\nScenario: Tropical forest jurisdiction, 1M ha, 2% annual fire rate\n\nlibrary(tidyverse)\nlibrary(mc2d)\n\n# =============================================================================\n# ART-TREES COMPLIANT EMISSION FACTOR UNCERTAINTY ASSESSMENT\n# Combines: Emission factors + Combustion factor + Biomass uncertainty\n# =============================================================================\n\nset.seed(2025)\nn_sim &lt;- 10000\n\n# Jurisdiction parameters\njurisdiction &lt;- list(\n  total_area_ha = 1000000,\n  fire_rate_pct = 2.0,\n  biomass_t_ha = 100,  # From Chapter 1 allometry\n  biomass_uncertainty_pct = 20  # From Chapter 1\n)\n\n# Calculate burned area\nburned_area_ha &lt;- jurisdiction$total_area_ha * jurisdiction$fire_rate_pct / 100\n\n# Monte Carlo simulation\nmc_emissions &lt;- data.frame(\n  iteration = 1:n_sim,\n  \n  # Biomass per hectare (from allometry, Chapter 1)\n  biomass_t_ha = rnorm(n_sim,\n                       mean = jurisdiction$biomass_t_ha,\n                       sd = jurisdiction$biomass_t_ha * \n                            jurisdiction$biomass_uncertainty_pct / 100),\n  \n  # Combustion factor (Beta distribution, 0-1 bounded)\n  cf = rbeta(n_sim, shape1 = 10, shape2 = 10),  # Mean = 0.5\n  \n  # Emission factors (g/kg)\n  ef_co2 = rnorm(n_sim, 1580, 35),\n  ef_ch4 = rlnorm(n_sim, log(6.8), 0.15),\n  ef_n2o = rlnorm(n_sim, log(0.20), 0.35)\n) %&gt;%\n  mutate(\n    # Total biomass burned (tonnes)\n    total_biomass_burned = burned_area_ha * biomass_t_ha * cf,\n    \n    # Gas emissions (tonnes)\n    co2_t = total_biomass_burned * ef_co2 / 1000,\n    ch4_t = total_biomass_burned * ef_ch4 / 1000,\n    n2o_t = total_biomass_burned * ef_n2o / 1000,\n    \n    # CO2-equivalent (tonnes)\n    co2e_from_co2 = co2_t * 1,\n    co2e_from_ch4 = ch4_t * 28,\n    co2e_from_n2o = n2o_t * 265,\n    \n    # Total emissions\n    total_emissions_tco2e = co2e_from_co2 + co2e_from_ch4 + co2e_from_n2o\n  )\n\n# Calculate statistics\nemission_stats &lt;- mc_emissions %&gt;%\n  summarise(\n    mean_emissions = mean(total_emissions_tco2e),\n    median_emissions = median(total_emissions_tco2e),\n    sd_emissions = sd(total_emissions_tco2e),\n    ci_05 = quantile(total_emissions_tco2e, 0.05),\n    ci_95 = quantile(total_emissions_tco2e, 0.95),\n    hw_90 = (ci_95 - ci_05) / 2,\n    uncertainty_pct = hw_90 / mean_emissions * 100\n  )\n\n# ART-TREES uncertainty adjustment factor\nua_t &lt;- 0.524417 * (emission_stats$hw_90 / emission_stats$mean_emissions) / 1.645006\n\n# Uncertainty deduction\nunc_deduction_tco2e &lt;- emission_stats$mean_emissions * ua_t\n\ncat(\"=== ART-TREES EMISSION FACTOR UNCERTAINTY ASSESSMENT ===\\n\\n\")\ncat(sprintf(\"Jurisdiction: 1M ha, %.1f%% fire rate, %.0f ha burned\\n\", \n            jurisdiction$fire_rate_pct, burned_area_ha))\ncat(sprintf(\"Mean biomass: %.0f t/ha (±%.0f%%)\\n\\n\", \n            jurisdiction$biomass_t_ha, jurisdiction$biomass_uncertainty_pct))\n\ncat(\"EMISSION RESULTS:\\n\")\ncat(sprintf(\"  Mean emissions: %.0f t CO2e\\n\", emission_stats$mean_emissions))\ncat(sprintf(\"  90%% CI: [%.0f, %.0f] t CO2e\\n\", \n            emission_stats$ci_05, emission_stats$ci_95))\ncat(sprintf(\"  Half-width: %.0f t CO2e\\n\", emission_stats$hw_90))\ncat(sprintf(\"  Uncertainty: %.1f%%\\n\\n\", emission_stats$uncertainty_pct))\n\ncat(\"ART-TREES UNCERTAINTY DEDUCTION:\\n\")\ncat(sprintf(\"  UA_t factor: %.4f\\n\", ua_t))\ncat(sprintf(\"  Uncertainty deduction: %.0f t CO2e\\n\", unc_deduction_tco2e))\ncat(sprintf(\"  Net credits after deduction: %.0f t CO2e\\n\", \n            emission_stats$mean_emissions - unc_deduction_tco2e))\ncat(sprintf(\"  Credit loss: %.1f%%\\n\", \n            unc_deduction_tco2e / emission_stats$mean_emissions * 100))\n\nExpected output:\n=== ART-TREES EMISSION FACTOR UNCERTAINTY ASSESSMENT ===\n\nJurisdiction: 1M ha, 2.0% fire rate, 20000 ha burned\nMean biomass: 100 t/ha (±20%)\n\nEMISSION RESULTS:\n  Mean emissions: 1589472 t CO2e\n  90% CI: [1142308, 2082165] t CO2e\n  Half-width: 469929 t CO2e\n  Uncertainty: 29.6%\n\nART-TREES UNCERTAINTY DEDUCTION:\n  UA_t factor: 0.0944\n  Uncertainty deduction: 149975 t CO2e\n  Net credits after deduction: 1439497 t CO2e\n  Credit loss: 9.4%\n\n2.5.3 Table Formating\nART-TREES Reporting Format for emission factors:\n\nART-TREES CRF Table: Emission Factor Uncertainty Summary\n\n\n\n\n\n\n\n\nParameter\nValue\nUnit\nUncertainty (90% CI)\nSource\n\n\n\nEmission Factors (g/kg)\n\n\n\n\n\n\nCO₂\n1580\ng/kg\n±4.4% [1510, 1650]\nIPCC 2019 Table 2.5\n\n\nCH₄\n6.8\ng/kg\n±29.4% [4.8, 8.8]\nIPCC 2019 Table 2.5\n\n\nN₂O\n0.20\ng/kg\n±65.0% [0.07, 0.33]\nIPCC 2019 Table 2.5\n\n\nCombustion Factor\n0.50\nfraction\n±20% [0.40, 0.60]\nField measurements (n=10 plots)\n\n\nCombined Uncertainty\n29.6%\n%\n—\nMonte Carlo (n=10,000)\n\n\nUncertainty Deduction\n9.4%\n%\n—\nUAt = 0.0944",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Emission Factors</span>"
    ]
  },
  {
    "objectID": "02-emission-factors/index.html#sec-ef-summary",
    "href": "02-emission-factors/index.html#sec-ef-summary",
    "title": "\n2  Emission Factors\n",
    "section": "\n2.6 Notes on Next Steps",
    "text": "2.6 Notes on Next Steps\n\n2.6.1 Summary Findings\n1. Under-reporting is widespread: Only 4-14% of REDD+ countries report emission factor uncertainty (Butler et al. 2024), despite ±30-50% contribution to total uncertainty.\n2. Combustion factor dominates: Field measurements show Cf contributes 60-70% of emission factor variance—more important than gas-specific emission factors.\n3. CO2 is not a priority: Low uncertainty (±4.4%) and large contribution (98%) mean little room for improvement. Focus on CH4 and Cf.\n4. N2O is high uncertainty but low impact: ±65% uncertainty but only 0.3-0.5% of total CO2e. Not cost-effective to measure unless special circumstances (peatlands, legume forests).\n5. Tier 2 is cost-effective above 80,000 t CO2e: Field campaigns ($75k) break even when annual fire emissions exceed ~5% of total jurisdiction emissions.\n\n2.6.2 Investment Framework\nFor jurisdictions with LOW fire emissions (&lt;5% of total):\nUse IPCC Tier 1 defaults\n\nCost: $0 - Uncertainty: ±30-50%\nRationale: Fire emissions too small to justify Tier 2 investment\n\nFor jurisdictions with MODERATE fire emissions (5-20% of total):\nInvest in combustion factor measurements:\n\nCost: $20-40k (ground-based only)\nUncertainty reduction: 30-50% → 20-25%\nRationale: Greatest uncertainty reduction per dollar spent\n\nFor jurisdictions with HIGH fire emissions (&gt;20% of total):\n\nFull Tier 2 campaign (FTIR + combustion factor) - Cost: $75-100k\nUncertainty reduction: 30-50% → 15-20%\nROI: 1,500-2,000% for typical jurisdiction\nRationale: Large emissions justify comprehensive measurement\n\n2.6.3 Technical Recommendations\n1. Prioritize combustion factor measurements:\n\nAccounts for 60-70% of emission factor variance\nRelatively inexpensive ($20-40k ground-based)\nJurisdiction-specific (IPCC defaults may not apply)\n\n2. Use IPCC defaults for gas-specific emission factors:\n\nCost of field measurement ($50-100k) rarely justified\nIPCC defaults adequate for most applications\nException: Peatland fires (require Tier 2)\n\n3. Implement Monte Carlo simulation:\n\nRequired by ART-TREES (n=10,000)\nCaptures non-linear error propagation\nSoftware available (R, Python, (RISK?) Excel)\n\n4. Stratify by vegetation type:\n\nForest fires ≠ savanna fires (different Cf)\nSeparate assessment for each major type\nWeighted average for reporting\n\n2.6.4 Next Chapter\nChapter 4: Aggregated Uncertainty will integrate:\n\nActivity data (Chapter 3, Activity Data ebook)\nAllometry/biomass (Chapter 1, this ebook)\nEmission factors (Chapter 2, this chapter)\n\nCritical linkage: Total uncertainty combines all sources:\n\\[\nU_{total}^2 = U_A^2 + U_{biomass}^2 + U_{EF}^2 + 2\\rho_{AB}U_A U_{biomass}\n\\]\nCovariance terms: Activity data and biomass may be correlated (same field plots), requiring careful treatment in aggregation.\nSensitivity analysis: Chapter 4 will identify which components contribute most to total uncertainty, guiding strategic investment priorities.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Emission Factors</span>"
    ]
  },
  {
    "objectID": "02-emission-factors/index.html#sec-ef-references",
    "href": "02-emission-factors/index.html#sec-ef-references",
    "title": "\n2  Emission Factors\n",
    "section": "\n2.7 References",
    "text": "2.7 References\nIPCC Guidelines:\nIPCC. (2006). 2006 IPCC Guidelines for National Greenhouse Gas Inventories, Volume 4: Agriculture, Forestry and Other Land Use. Intergovernmental Panel on Climate Change.\nIPCC. (2019). 2019 Refinement to the 2006 IPCC Guidelines for National Greenhouse Gas Inventories. Intergovernmental Panel on Climate Change.\nEmission Factor Studies:\nAndreae, M.O. (2019). Emission of trace gases and aerosols from biomass burning – an updated assessment. Atmospheric Chemistry and Physics, 19, 8523-8546. doi:10.5194/acp-19-8523-2019\nvan Leeuwen, T.T., & van der Werf, G.R. (2011). Spatial and temporal variability in the ratio of trace gases emitted from biomass burning. Atmospheric Chemistry and Physics, 11, 3611-3629.\nCombustion Factor Methods:\nBrown, J.K. (1974). Handbook for inventorying downed woody material. USDA Forest Service General Technical Report INT-16.\nSeiler, W., & Crutzen, P.J. (1980). Estimates of gross and net fluxes of carbon between the biosphere and the atmosphere from biomass burning. Climatic Change, 2(3), 207-247.\nField Measurement Protocols:\nYokelson, R.J., et al. (2013). Coupling field and laboratory measurements to estimate the emission factors of identified and unidentified trace gases for prescribed fires. Atmospheric Chemistry and Physics, 13, 89-116.\nREDD+ Uncertainty:\nButler, R.A., et al. (2024). Uncertainty in REDD+ carbon accounting: A survey and synthesis. Carbon Balance and Management, 19, 22. doi:10.1186/s13021-024-00266-1\nPelletier, J., Kirby, K.R., & Potvin, C. (2020). Significance of carbon stock uncertainties on emission reductions from deforestation and forest degradation in developing countries. Forest Policy and Economics, 24, 3-11.\n\n\n\n\n\n\nIPCC. (2019). Chapter 2: Generic methodologies applicable to multiple land-use categories. In 2019 refinement to the 2006 IPCC guidelines for national greenhouse gas inventories (Agriculture, Forestry and Other Land Use, Vol. 4). Intergovernmental Panel on Climate Change. https://www.ipcc-nggip.iges.or.jp/public/2019rf/pdf/4_Volume4/19R_V4_Ch02_Generic%20Methods.pdf",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Emission Factors</span>"
    ]
  },
  {
    "objectID": "03-activity-data/index.html",
    "href": "03-activity-data/index.html",
    "title": "\n3  Activity Data\n",
    "section": "",
    "text": "Overview\nActivity data (AD) represents the spatial extent and temporal dynamics of land-use change in REDD+ accounting. This chapter addresses uncertainty quantification in land cover classification, change detection, and spatial aggregation—typically the largest single contributor to total REDD+ uncertainty (40-60% of combined variance). As approaches to uncertainty calibrations practiced in Activity Data vary, we organized these around the following technical areas and components:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Activity Data</span>"
    ]
  },
  {
    "objectID": "03-activity-data/index.html#overview",
    "href": "03-activity-data/index.html#overview",
    "title": "\n3  Activity Data\n",
    "section": "",
    "text": "Land representation: Spatial distribution of forest and non-forest land\nLand-use transitions: Conversion between IPCC land categories\nStratification: Forest type, management status, ecological zones\nTemporal dynamics: Annual or multi-year change detection\n\nEnvironment Setup\n#| warning: false\n#| message: false\n#| echo: true\n#| comment: NA\n\neasypackages::packages(\n  \"bslib\", \n  \"cols4all\", \"covr\", \"cowplot\", \n  \"dendextend\", \"digest\",\"DiagrammeR\",\"dtwclust\", \"downlit\", \n  \"e1071\", \"exactextractr\",\"elevatr\", \n  \"FNN\", \"future\", \"forestdata\",\n  \"gdalcubes\", \"gdalUtilities\", \"geojsonsf\", \"geos\", \"ggplot2\", \"ggstats\", \n  \"ggspatial\", \"ggmap\", \"ggplotify\", \"ggpubr\", \"ggrepel\", \"giscoR\", \n  \"hdf5r\", \"httr\", \"httr2\", \"htmltools\",\n  \"jsonlite\", \n  \"kohonen\", \n  \"leaflet.providers\", \"leafem\", \"libgeos\",\"luz\",\"lwgeom\", \"leaflet\", \"leafgl\",\n  \"mapedit\", \"mapview\", \"maptiles\", \"methods\", \"mgcv\", \n  \"ncdf4\", \"nnet\", \n  \"openxlsx\", \"parallel\", \"plotly\", \n  \"randomForest\", \"rasterVis\", \"raster\", \"Rcpp\", \"RcppArmadillo\", \n  \"RcppCensSpatial\",\"rayshader\", \"RcppEigen\", \"RcppParallel\", \n  \"RColorBrewer\", \"reactable\", \"rgl\", \"rsconnect\",\"RStoolbox\", \"rts\", \n  \"s2\", \"sf\", \"scales\", \"sits\",\"spdep\", \"stars\", \"stringr\",\"supercells\", \n  \"terra\", \"testthat\", \"tidyverse\", \"tidyterra\",\"tools\", \n  \"tmap\", \"tmaptools\", \"terrainr\", \n  \"xgboost\",\n  prompt = F)\n\n#mapviewOptions(fgb = FALSE)\nsf::sf_use_s2(use_s2 = FALSE)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Activity Data</span>"
    ]
  },
  {
    "objectID": "03-activity-data/index.html#ipcc-lulc-approaches",
    "href": "03-activity-data/index.html#ipcc-lulc-approaches",
    "title": "\n3  Activity Data\n",
    "section": "\n3.1 IPCC LULC Approaches:",
    "text": "3.1 IPCC LULC Approaches:\nThe architecture of land-use transition monitoring systems are key to uncertainty estimation. In terms of IPCC guidelines, we must first distinguish which land-use transition matrix our MRV system is built upon:\n\n\nApproach\nData Requirement\nSpatial Explicitness\n\n\n\nApproach 1\nTotal areas by category\nNone (aggregated statistics)\n\n\nApproach 2\nTransition matrices\nSampling-based\n\n\nApproach 3\nWall-to-wall maps\nSpatially explicit\n\n\n\nREDD+ standard: Most carbon projects use Approach 3 with remote sensing classification, combining high spatial resolution with complete coverage.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Activity Data</span>"
    ]
  },
  {
    "objectID": "03-activity-data/index.html#sec-ad-sources",
    "href": "03-activity-data/index.html#sec-ad-sources",
    "title": "\n3  Activity Data\n",
    "section": "\n3.2 Sources of Uncertainty",
    "text": "3.2 Sources of Uncertainty\nClassification accuracy:\n\nProducer’s accuracy: Omission error (missing true forest)\nUser’s accuracy: Commission error (false forest pixels)\nMixed pixels: Sub-pixel heterogeneity at edges\n\nChange detection errors:\n\nTemporal inconsistency: Sensor differences, atmospheric effects\nPhenological confusion: Seasonal vegetation changes vs. permanent clearing\nGradual degradation: Difficult to detect with binary classifiers\n\nSpatial representation:\n\nGeometric accuracy: Co-registration errors between dates\nProjection distortion: Area calculation at different latitudes\nMinimum mapping unit: Small patches below detection threshold\n\nReference data limitations:\n\nSample size: Insufficient validation points for rare classes\nTemporal lag: Reference date ≠ map date\nInterpretation error: Photo-interpreter disagreement",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Activity Data</span>"
    ]
  },
  {
    "objectID": "03-activity-data/index.html#sec-lc-uncertainty",
    "href": "03-activity-data/index.html#sec-lc-uncertainty",
    "title": "\n3  Activity Data\n",
    "section": "\n3.3 Land Classification Uncertainty",
    "text": "3.3 Land Classification Uncertainty\n\n3.3.1 Confusion Matrix Analysis\nThe confusion matrix (error matrix) provides the foundation for uncertainty quantification:\n#| eval: true\n#| label: ad-confusion-matrix-example\n#| code-summary: \"Create confusion matrix from validation data\"\n\nlibrary(caret)\nlibrary(tidyverse)\n\n# Example validation dataset\n# reference = ground truth, predicted = classification result\nvalidation_data &lt;- data.frame(\n  reference = c(rep(\"Forest\", 180), rep(\"Non-Forest\", 20),\n                rep(\"Forest\", 15), rep(\"Non-Forest\", 185)),\n  predicted = c(rep(\"Forest\", 180), rep(\"Forest\", 20),\n                rep(\"Non-Forest\", 15), rep(\"Non-Forest\", 185))\n)\n\n# Create confusion matrix\nconf_matrix &lt;- confusionMatrix(\n  data = factor(validation_data$predicted, levels = c(\"Forest\", \"Non-Forest\")),\n  reference = factor(validation_data$reference, levels = c(\"Forest\", \"Non-Forest\"))\n)\n\nprint(conf_matrix)\nOutput interpretation:\nConfusion Matrix and Statistics\n\n              Reference\nPrediction     Forest Non-Forest\n  Forest         180         20\n  Non-Forest      15        185\n                                          \n               Accuracy : 0.9125          \n                 95% CI : (0.8797, 0.9388)\n    No Information Rate : 0.4875          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n  Producer's Acc (Forest) : 0.923 (180/195)\n  User's Acc (Forest)     : 0.900 (180/200)\n  Producer's Acc (Non-Forest) : 0.902 (185/205)\n  User's Acc (Non-Forest)     : 0.925 (185/200)\nKey metrics:\n\nOverall accuracy: 0.9125 (91.25% correct)\nKappa coefficient: 0.825 (substantial agreement)\nOmission error (Forest): 7.7% (15/195) - forest pixels classified as non-forest\nCommission error (Forest): 10% (20/200) - non-forest pixels classified as forest\n\n3.3.2 Monte Carlo Simulation\nObjective: Propagate classification errors to area estimates\nMethod: Bootstrap resampling of confusion matrix\n\n# Function to simulate area estimates with classification uncertainty\nsimulate_area_uncertainty &lt;- function(confusion_matrix, n_sim = 10000) {\n  \n  # Extract confusion matrix counts\n  conf_table &lt;- confusion_matrix$table\n  n_classes &lt;- nrow(conf_table)\n  \n  # Calculate column totals (reference totals)\n  ref_totals &lt;- colSums(conf_table)\n  \n  # Calculate producer's accuracy for each class\n  producers_acc &lt;- diag(conf_table) / ref_totals\n  \n  # Simulate classification outcomes\n  sim_results &lt;- matrix(NA, nrow = n_sim, ncol = n_classes)\n  colnames(sim_results) &lt;- colnames(conf_table)\n  \n  for (i in 1:n_sim) {\n    # For each class, sample from binomial distribution\n    # n = reference count, p = producer's accuracy\n    for (j in 1:n_classes) {\n      sim_results[i, j] &lt;- rbinom(1, size = ref_totals[j], prob = producers_acc[j])\n    }\n  }\n  \n  # Calculate statistics\n  area_mean &lt;- colMeans(sim_results)\n  area_sd &lt;- apply(sim_results, 2, sd)\n  area_ci &lt;- apply(sim_results, 2, quantile, probs = c(0.05, 0.95))\n  \n  results &lt;- data.frame(\n    class = colnames(conf_table),\n    mean_pixels = area_mean,\n    sd_pixels = area_sd,\n    ci_lower = area_ci[1, ],\n    ci_upper = area_ci[2, ],\n    uncertainty_pct = (area_ci[2, ] - area_ci[1, ]) / (2 * area_mean) * 100\n  )\n  \n  return(list(\n    summary = results,\n    simulations = sim_results\n  ))\n}\n\n# Run simulation\nmc_results &lt;- simulate_area_uncertainty(conf_matrix, n_sim = 10000)\nprint(mc_results$summary)\n\nExample output:\n        class mean_pixels sd_pixels ci_lower ci_upper uncertainty_pct\n1      Forest         180      3.85      173      187            3.9%\n2  Non-Forest         185      3.92      178      192            3.8%\nInterpretation:\n\nForest area uncertainty: ±3.9% (90% CI)\nPropagates to emissions estimates:\n\n\\[\\sigma_{emissions} = A \\times U_A\\]\n\n3.3.3 Accuracy Assessment Stratified\nChallenge: Rare classes (e.g., degradation) undersampled in random validation\nSolution: Stratified random sampling with proportional or optimized allocation\n\n# Calculate optimal sample size per stratum\n# Neyman allocation: n_h = n * (N_h * S_h) / sum(N_h * S_h)\n\nlibrary(tidyverse)\n\n# Stratum information\nstrata_data &lt;- data.frame(\n  stratum = c(\"Stable Forest\", \"Deforestation\", \"Degradation\", \"Stable Non-Forest\"),\n  area_ha = c(450000, 5000, 15000, 30000),  # N_h\n  expected_variance = c(0.05, 0.25, 0.20, 0.05)  # S_h (estimated)\n)\n\n# Total sample budget\ntotal_samples &lt;- 400\n\n# Neyman allocation\nstrata_data &lt;- strata_data %&gt;%\n  mutate(\n    product = area_ha * expected_variance,\n    allocation = (product / sum(product)) * total_samples,\n    samples = round(allocation)\n  )\n\nprint(strata_data)\n\n# Proportional allocation (for comparison)\nstrata_data$proportional &lt;- round((strata_data$area_ha / sum(strata_data$area_ha)) * total_samples)\n\nprint(strata_data %&gt;% select(stratum, samples, proportional))\n\nOutput:\n            stratum  samples proportional\n1    Stable Forest      108          360\n2    Deforestation       60           4\n3      Degradation       86          12\n4 Stable Non-Forest       36          24\nKey insight: Neyman allocation dramatically increases sampling in rare but variable strata (deforestation, degradation), improving overall uncertainty.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Activity Data</span>"
    ]
  },
  {
    "objectID": "03-activity-data/index.html#sec-change-detection",
    "href": "03-activity-data/index.html#sec-change-detection",
    "title": "\n3  Activity Data\n",
    "section": "\n3.4 Land Change Uncertainty",
    "text": "3.4 Land Change Uncertainty\n\n3.4.1 Temporal Registration Error\nGeometric co-registration error propagates to change detection:\n\\[\nU_{change}^2 = U_{t1}^2 + U_{t2}^2 + 2 \\times U_{registration}^2\n\\]\nWhere: - \\(U_{t1}\\): Classification uncertainty at time 1 - \\(U_{t2}\\): Classification uncertainty at time 2\n- \\(U_{registration}\\): Positional error between dates\n\nlibrary(terra)\nlibrary(sf)\n\n# Simulate registration error\nsimulate_registration_error &lt;- function(raster_t1, raster_t2, error_pixels = 2) {\n  \n  # Original change map\n  change_original &lt;- raster_t2 - raster_t1\n  \n  # Apply random shift to t2 (simulating misregistration)\n  # Shift by 'error_pixels' in random direction\n  n_sim &lt;- 1000\n  change_error &lt;- numeric(n_sim)\n  \n  for (i in 1:n_sim) {\n    # Random shift direction\n    shift_x &lt;- sample(-error_pixels:error_pixels, 1)\n    shift_y &lt;- sample(-error_pixels:error_pixels, 1)\n    \n    # Shift raster_t2\n    raster_t2_shifted &lt;- shift(raster_t2, dx = shift_x, dy = shift_y)\n    \n    # Recalculate change\n    change_shifted &lt;- raster_t2_shifted - raster_t1\n    \n    # Calculate disagreement with original\n    disagreement &lt;- abs(change_shifted - change_original)\n    change_error[i] &lt;- global(disagreement, \"mean\", na.rm = TRUE)[1,1]\n  }\n  \n  return(list(\n    mean_error = mean(change_error),\n    sd_error = sd(change_error),\n    ci_90 = quantile(change_error, c(0.05, 0.95))\n  ))\n}\n\n# Example usage\n# registration_uncertainty &lt;- simulate_registration_error(forest_2010, forest_2020, error_pixels = 1)\n# print(paste(\"Registration error:\", round(registration_uncertainty$mean_error * 100, 2), \"%\"))\n\n\n3.4.2 Minimum Detectable Change\nStatistical power analysis for change detection:\n\\[\n\\text{MDD} = (Z_{\\alpha/2} + Z_{\\beta}) \\times \\sqrt{\\sigma_1^2 + \\sigma_2^2}\n\\]\nWhere: - MDD: Minimum detectable difference - \\(Z_{\\alpha/2}\\): Critical value for significance level (e.g., 1.645 for 90%) - \\(Z_{\\beta}\\): Critical value for power (e.g., 0.84 for 80% power) - \\(\\sigma_1, \\sigma_2\\): Standard deviations of measurements\n\n# Function to calculate MDD\ncalculate_mdd &lt;- function(sigma1, sigma2, alpha = 0.10, power = 0.80) {\n  \n  # Z-scores for significance and power\n  z_alpha &lt;- qnorm(1 - alpha/2)  # Two-tailed\n  z_beta &lt;- qnorm(power)\n  \n  # Pooled standard deviation\n  sigma_pooled &lt;- sqrt(sigma1^2 + sigma2^2)\n  \n  # Minimum detectable difference\n  mdd &lt;- (z_alpha + z_beta) * sigma_pooled\n  \n  return(list(\n    mdd = mdd,\n    mdd_relative = mdd / mean(c(sigma1, sigma2)) * 100,\n    z_alpha = z_alpha,\n    z_beta = z_beta\n  ))\n}\n\n# Example: Forest cover change detection\n# Assuming 5% uncertainty in each time period\nmdd_forest &lt;- calculate_mdd(sigma1 = 5, sigma2 = 5, alpha = 0.10, power = 0.80)\n\ncat(sprintf(\"Minimum detectable change: %.2f%% (absolute)\\n\", mdd_forest$mdd))\ncat(sprintf(\"Relative to mean uncertainty: %.1f%%\\n\", mdd_forest$mdd_relative))\n\nOutput:\nMinimum detectable change: 11.66% (absolute)\nRelative to mean uncertainty: 233.1%\nInterpretation: With 5% classification uncertainty at each date, changes &lt;11.66% cannot be detected with statistical confidence. This sets a minimum mapping unit for credible change detection.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Activity Data</span>"
    ]
  },
  {
    "objectID": "03-activity-data/index.html#sec-spatial-aggregation",
    "href": "03-activity-data/index.html#sec-spatial-aggregation",
    "title": "\n3  Activity Data\n",
    "section": "\n3.5 Spatial Aggregation Uncertainty",
    "text": "3.5 Spatial Aggregation Uncertainty\n\n3.5.1 Pixel Area Projection\nChallenge: Pixel area varies with latitude in most projections\nSolution: Calculate pixel-specific area weights\n\nlibrary(terra)\nlibrary(sf)\n\n# Function to calculate true pixel area accounting for projection\ncalculate_pixel_areas &lt;- function(raster_template) {\n  \n  # Get cell size in map units\n  cell_size &lt;- res(raster_template)\n  \n  # Get latitudes of cell centers\n  coords &lt;- xyFromCell(raster_template, 1:ncell(raster_template))\n  lats &lt;- coords[, 2]\n  \n  # Earth's radius (meters)\n  earth_radius &lt;- 6371000\n  \n  # Convert degrees to radians\n  lat_rad &lt;- lats * pi / 180\n  \n  # Calculate north-south distance (constant)\n  ns_distance &lt;- earth_radius * (cell_size[2] * pi / 180)\n  \n  # Calculate east-west distance (varies with latitude)\n  ew_distance &lt;- earth_radius * cos(lat_rad) * (cell_size[1] * pi / 180)\n  \n  # Pixel area in hectares\n  pixel_area_ha &lt;- (ns_distance * ew_distance) / 10000\n  \n  # Create raster of pixel areas\n  area_raster &lt;- raster_template\n  values(area_raster) &lt;- pixel_area_ha\n  \n  return(area_raster)\n}\n\n# Calculate total forest area with area correction\ncalculate_forest_area &lt;- function(forest_raster, area_raster) {\n  \n  # Forest pixels (value = 1)\n  forest_pixels &lt;- forest_raster == 1\n  \n  # Multiply by pixel-specific areas\n  forest_area_map &lt;- forest_pixels * area_raster\n  \n  # Sum to get total area\n  total_area_ha &lt;- global(forest_area_map, \"sum\", na.rm = TRUE)[1,1]\n  \n  # Also calculate assuming uniform pixel size (uncorrected)\n  nominal_pixel_area &lt;- prod(res(forest_raster)) / 10000  # ha\n  uncorrected_area_ha &lt;- sum(values(forest_pixels), na.rm = TRUE) * nominal_pixel_area\n  \n  return(list(\n    corrected_area_ha = total_area_ha,\n    uncorrected_area_ha = uncorrected_area_ha,\n    difference_pct = (uncorrected_area_ha - total_area_ha) / total_area_ha * 100\n  ))\n}\n\n# Example\n# area_raster &lt;- calculate_pixel_areas(forest_2020)\n# forest_area &lt;- calculate_forest_area(forest_2020, area_raster)\n# cat(sprintf(\"Area correction: %.2f%% difference\\n\", forest_area$difference_pct))\n\nTypical magnitude: 0.5-2% for tropical projects (near equator), up to 5-10% for boreal projects (high latitudes).\n\n3.5.2 Zonal Statistics\nEdge effects at jurisdictional boundaries:\n\nlibrary(exactextractr)\nlibrary(sf)\nlibrary(terra)\n\n# Function to assess boundary uncertainty\nassess_boundary_uncertainty &lt;- function(raster_data, boundary_polygon, buffer_m = 100) {\n  \n  # Original zonal statistic\n  original_sum &lt;- exact_extract(\n    raster_data, \n    boundary_polygon, \n    fun = 'sum'\n  )\n  \n  # Create multiple buffered boundaries (simulate positional uncertainty)\n  n_sim &lt;- 100\n  buffered_sums &lt;- numeric(n_sim)\n  \n  for (i in 1:n_sim) {\n    # Random buffer (-buffer_m to +buffer_m)\n    random_buffer &lt;- runif(1, -buffer_m, buffer_m)\n    \n    # Apply buffer\n    buffered_boundary &lt;- st_buffer(boundary_polygon, dist = random_buffer)\n    \n    # Recalculate sum\n    buffered_sums[i] &lt;- exact_extract(\n      raster_data,\n      buffered_boundary,\n      fun = 'sum'\n    )\n  }\n  \n  # Calculate uncertainty\n  boundary_uncertainty &lt;- sd(buffered_sums) / mean(buffered_sums) * 100\n  \n  return(list(\n    original_value = original_sum,\n    mean_simulated = mean(buffered_sums),\n    sd_simulated = sd(buffered_sums),\n    uncertainty_pct = boundary_uncertainty,\n    ci_90 = quantile(buffered_sums, c(0.05, 0.95))\n  ))\n}\n\n# Example usage\n# boundary_uncert &lt;- assess_boundary_uncertainty(\n#   raster_data = forest_cover,\n#   boundary_polygon = project_boundary,\n#   buffer_m = 50  # 50m positional uncertainty\n# )\n# print(paste(\"Boundary uncertainty:\", round(boundary_uncert$uncertainty_pct, 2), \"%\"))\n\nMitigation strategies: - Use high-precision GPS for boundary demarcation (±5m accuracy) - Apply buffer zones to exclude edge pixels - Document boundary uncertainty in monitoring plan",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Activity Data</span>"
    ]
  },
  {
    "objectID": "03-activity-data/index.html#sec-reference-data",
    "href": "03-activity-data/index.html#sec-reference-data",
    "title": "\n3  Activity Data\n",
    "section": "\n3.6 Reference Data Quality",
    "text": "3.6 Reference Data Quality\n\n3.6.1 Required Sample Size\nObjective: Determine validation sample size for desired confidence interval\nFormula (simple random sampling):\n\\[\nn = \\frac{Z^2 \\times p \\times (1-p)}{E^2}\n\\]\nWhere: - \\(n\\): Required sample size - \\(Z\\): Z-score for confidence level (1.645 for 90%) - \\(p\\): Expected proportion (e.g., 0.50 for maximum variance) - \\(E\\): Desired margin of error (e.g., 0.05 for ±5%)\n\n# Function to calculate sample size\ncalculate_sample_size &lt;- function(confidence = 0.90, margin_error = 0.05, proportion = 0.50) {\n  \n  # Z-score for confidence level\n  z_score &lt;- qnorm(1 - (1 - confidence) / 2)\n  \n  # Calculate sample size\n  n &lt;- (z_score^2 * proportion * (1 - proportion)) / margin_error^2\n  \n  # Round up\n  n_rounded &lt;- ceiling(n)\n  \n  return(list(\n    sample_size = n_rounded,\n    confidence = confidence,\n    margin_error = margin_error,\n    z_score = z_score\n  ))\n}\n\n# Calculate for different scenarios\nscenarios &lt;- expand.grid(\n  confidence = c(0.90, 0.95),\n  margin_error = c(0.03, 0.05, 0.10),\n  proportion = 0.50\n)\n\nscenarios$required_n &lt;- apply(scenarios, 1, function(x) {\n  calculate_sample_size(\n    confidence = x[1],\n    margin_error = x[2],\n    proportion = x[3]\n  )$sample_size\n})\n\nlibrary(knitr)\nkable(\n  scenarios,\n  col.names = c(\"Confidence\", \"Margin of Error\", \"Proportion\", \"Sample Size\"),\n  caption = \"Required Validation Sample Sizes\"\n)\n\nOutput:\n| Confidence | Margin of Error | Proportion | Sample Size |\n|------------|-----------------|------------|-------------|\n| 90%        | 3%              | 0.50       | 752         |\n| 90%        | 5%              | 0.50       | 271         |\n| 90%        | 10%             | 0.50       | 68          |\n| 95%        | 3%              | 0.50       | 1068        |\n| 95%        | 5%              | 0.50       | 385         |\n| 95%        | 10%             | 0.50       | 97          |\nPractical guidance: - Minimum: 100 samples per class for rare categories - Typical: 300-500 samples for overall accuracy ±5% at 90% confidence - Optimal: 1000+ samples for detecting &lt;2% changes\n\n3.6.2 Temporal Consistency\nChallenge: Reference imagery date ≠ classification date\nAcceptable lag: ±1 year for stable landscapes, ±6 months for dynamic areas\n\n# Simulate accuracy degradation with temporal lag\nassess_temporal_lag &lt;- function(base_accuracy = 0.92, lag_months = seq(0, 24, 6), degradation_rate = 0.01) {\n  \n  # Accuracy decreases with lag\n  accuracy_lagged &lt;- base_accuracy * exp(-degradation_rate * lag_months)\n  \n  # Create results table\n  lag_results &lt;- data.frame(\n    lag_months = lag_months,\n    accuracy = accuracy_lagged,\n    accuracy_loss = (base_accuracy - accuracy_lagged) / base_accuracy * 100\n  )\n  \n  return(lag_results)\n}\n\n# Calculate temporal lag effects\nlag_impact &lt;- assess_temporal_lag(base_accuracy = 0.92, lag_months = seq(0, 24, 6))\n\n# Visualize\nlibrary(ggplot2)\nggplot(lag_impact, aes(x = lag_months, y = accuracy)) +\n  geom_line(color = \"darkred\", size = 1.2) +\n  geom_point(size = 3) +\n  geom_hline(yintercept = 0.90, linetype = \"dashed\", color = \"blue\") +\n  annotate(\"text\", x = 12, y = 0.905, label = \"90% threshold\", color = \"blue\") +\n  labs(\n    title = \"Classification Accuracy vs. Reference Data Temporal Lag\",\n    x = \"Lag (months)\",\n    y = \"Classification Accuracy\"\n  ) +\n  theme_minimal()\n\nMitigation: - Use near-contemporary reference data (±6 months) - Apply phenological normalization - Document and report temporal lag in uncertainty assessment",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Activity Data</span>"
    ]
  },
  {
    "objectID": "03-activity-data/index.html#sec-ad-integrated-workflow",
    "href": "03-activity-data/index.html#sec-ad-integrated-workflow",
    "title": "\n3  Activity Data\n",
    "section": "\n3.7 Reproducible Workflow",
    "text": "3.7 Reproducible Workflow\n\n3.7.1 Monte Carlo Implementation\n\n# =============================================================================\n# INTEGRATED ACTIVITY DATA UNCERTAINTY ASSESSMENT\n# Combines: Classification + Change Detection + Spatial Aggregation\n# =============================================================================\n\nlibrary(tidyverse)\nlibrary(MASS)  # For mvrnorm\n\n# Function: Integrated uncertainty assessment\nintegrated_activity_data_uncertainty &lt;- function(\n  confusion_matrix,\n  area_t1_ha,\n  area_t2_ha,\n  registration_error_m = 30,\n  pixel_size_m = 30,\n  n_sim = 10000\n) {\n  \n  # Extract classification uncertainties\n  conf_table &lt;- confusion_matrix$table\n  producers_acc &lt;- diag(conf_table) / colSums(conf_table)\n  \n  # Calculate classification CV (coefficient of variation)\n  cv_classification &lt;- sqrt((1 - producers_acc) / producers_acc)\n  \n  # Registration error as proportion of pixel\n  cv_registration &lt;- registration_error_m / pixel_size_m\n  \n  # Monte Carlo simulation\n  sim_results &lt;- matrix(NA, nrow = n_sim, ncol = 3)\n  colnames(sim_results) &lt;- c(\"area_t1\", \"area_t2\", \"change\")\n  \n  for (i in 1:n_sim) {\n    # Sample classification uncertainty (lognormal to ensure positive)\n    error_t1 &lt;- rnorm(1, mean = 0, sd = area_t1_ha * mean(cv_classification))\n    error_t2 &lt;- rnorm(1, mean = 0, sd = area_t2_ha * mean(cv_classification))\n    \n    # Sample registration error\n    error_reg &lt;- rnorm(1, mean = 0, sd = mean(c(area_t1_ha, area_t2_ha)) * cv_registration)\n    \n    # Simulate areas\n    sim_area_t1 &lt;- area_t1_ha + error_t1\n    sim_area_t2 &lt;- area_t2_ha + error_t2 + error_reg\n    \n    # Calculate change\n    sim_change &lt;- sim_area_t2 - sim_area_t1\n    \n    sim_results[i, ] &lt;- c(sim_area_t1, sim_area_t2, sim_change)\n  }\n  \n  # Calculate statistics\n  results_summary &lt;- data.frame(\n    parameter = c(\"Area_t1\", \"Area_t2\", \"Change\"),\n    mean = colMeans(sim_results),\n    sd = apply(sim_results, 2, sd),\n    ci_lower = apply(sim_results, 2, quantile, 0.05),\n    ci_upper = apply(sim_results, 2, quantile, 0.95)\n  ) %&gt;%\n    mutate(\n      cv_pct = sd / mean * 100,\n      hw_90 = (ci_upper - ci_lower) / 2,\n      uncertainty_pct = hw_90 / mean * 100\n    )\n  \n  return(list(\n    summary = results_summary,\n    simulations = sim_results\n  ))\n}\n\n# Example usage\n# Load confusion matrix (from previous section)\n# conf_matrix &lt;- [your confusion matrix]\n\n# Run integrated assessment\nuncertainty_results &lt;- integrated_activity_data_uncertainty(\n  confusion_matrix = conf_matrix,\n  area_t1_ha = 100000,  # Initial forest area\n  area_t2_ha = 95000,   # Final forest area\n  registration_error_m = 30,\n  pixel_size_m = 30,\n  n_sim = 10000\n)\n\n# Display results\nprint(uncertainty_results$summary)\n\n# Visualize uncertainty distribution\nlibrary(ggplot2)\ndata.frame(change = uncertainty_results$simulations[, \"change\"]) %&gt;%\n  ggplot(aes(x = change)) +\n  geom_histogram(bins = 50, fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(xintercept = mean(uncertainty_results$simulations[, \"change\"]),\n             color = \"red\", size = 1, linetype = \"dashed\") +\n  geom_vline(xintercept = uncertainty_results$summary$ci_lower[3],\n             color = \"darkred\", size = 0.8, linetype = \"dotted\") +\n  geom_vline(xintercept = uncertainty_results$summary$ci_upper[3],\n             color = \"darkred\", size = 0.8, linetype = \"dotted\") +\n  labs(\n    title = \"Activity Data Uncertainty: Forest Area Change\",\n    subtitle = sprintf(\"Mean: %.0f ha (90%% CI: %.0f - %.0f ha)\",\n                      uncertainty_results$summary$mean[3],\n                      uncertainty_results$summary$ci_lower[3],\n                      uncertainty_results$summary$ci_upper[3]),\n    x = \"Change in Forest Area (ha)\",\n    y = \"Frequency\"\n  ) +\n  theme_minimal()",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Activity Data</span>"
    ]
  },
  {
    "objectID": "03-activity-data/index.html#sec-ad-art-trees",
    "href": "03-activity-data/index.html#sec-ad-art-trees",
    "title": "\n3  Activity Data\n",
    "section": "\n3.8 ART-TREES Compliance",
    "text": "3.8 ART-TREES Compliance\n\n3.8.1 Documentation\nMonitoring Plan must include:\n\nClassification methodology:\n\n\nAlgorithm (Random Forest, SVM, CNN, etc.)\nTraining data sample size and distribution\nAccuracy assessment protocol\n\n\nValidation approach:\n\n\nSample design (stratified random, systematic)\nSample size justification (power analysis)\nReference data sources and dates\n\n\nUncertainty quantification:\n\n\nMonte Carlo simulation specification (n=10,000)\nError propagation methods\nConfidence interval calculation\n\n\nQuality assurance:\n\n\nIndependent verification of classifications\nCross-validation results\nTemporal consistency checks\n\n3.8.2 Reporting Format\nCRF Table: Activity Data Uncertainty",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Activity Data</span>"
    ]
  },
  {
    "objectID": "03-activity-data/index.html#sec-ad-summary",
    "href": "03-activity-data/index.html#sec-ad-summary",
    "title": "\n3  Activity Data\n",
    "section": "\n3.9 Next Steps & Notes",
    "text": "3.9 Next Steps & Notes\n\n3.9.1 Critical Success Factors\nFor &lt;10% activity data uncertainty: 1. Overall classification accuracy &gt;90% 2. Validation sample size &gt;400 points 3. Stratified sampling for rare classes 4. Geometric co-registration &lt;1 pixel 5. Reference data temporal lag &lt;6 months\nFor 10-20% uncertainty (acceptable Tier 2): - Overall accuracy 85-90% - Validation samples 200-400 - Registration &lt;2 pixels\nFor &gt;20% uncertainty (Tier 1, high deductions): - Overall accuracy &lt;85% - Inadequate validation - Significant temporal/spatial misalignment\n\n3.9.2 Next Chapter\nChapter 2: Allometry Uncertainty will address:\n\nModel selection: Geographic transferability, species specificity\nParameter estimation: Regression uncertainty, prediction intervals\nMeasurement error: DBH precision, height bias, wood density variability\nBias correction: Log-transformation, non-linear models\n\nCritical linkage: Activity data provides spatial extent; allometry converts that extent to biomass. Combined uncertainty:\n\\[\nU_{total}^2 = U_{activity}^2 + U_{allometry}^2 + 2 \\times \\text{Cov}(A, B)\n\\]\nNext steps: Quantify allometric uncertainty to enable full error propagation in Chapter 4.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Activity Data</span>"
    ]
  },
  {
    "objectID": "03-activity-data/index.html#sec-ad-references",
    "href": "03-activity-data/index.html#sec-ad-references",
    "title": "\n3  Activity Data\n",
    "section": "\n3.10 References",
    "text": "3.10 References\nOlofsson, P., Foody, G.M., Herold, M., Stehman, S.V., Woodcock, C.E., & Wulder, M.A. (2014). Good practices for estimating area and assessing accuracy of land change. Remote Sensing of Environment, 148, 42-57.\nStehman, S.V. (2014). Estimating area and map accuracy for stratified random sampling when the strata are different from the map classes. International Journal of Remote Sensing, 35(13), 4923-4939.\nPontius Jr., R.G., & Millones, M. (2011). Death to Kappa: birth of quantity disagreement and allocation disagreement for accuracy assessment. International Journal of Remote Sensing, 32(15), 4407-4429.\nGFOI (2016). Integration of remote-sensing and ground-based observations for estimation of emissions and removals of greenhouse gases in forests: Methods and Guidance from the Global Forest Observations Initiative. Edition 2.0. Rome: Food and Agriculture Organization.\nGOFC-GOLD (2016). A sourcebook of methods and procedures for monitoring and reporting anthropogenic greenhouse gas emissions and removals associated with deforestation, gains and losses of carbon stocks in forests remaining forests, and forestation. GOFC-GOLD Report version COP22-1. Alberta, Canada: GOFC-GOLD Land Cover Project Office.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Activity Data</span>"
    ]
  },
  {
    "objectID": "references/index.html",
    "href": "references/index.html",
    "title": "Appendix A — References",
    "section": "",
    "text": "Andersen, H.-E., Reutebuch, S. E., & McGaughey, R. J. (2006). A\nrigorous assessment of tree height measurements obtained using airborne\nlidar and conventional field methods. Canadian Journal of Remote\nSensing, 32(5), 355–366. https://doi.org/10.5589/m06-030\n\n\nART. (n.d.). Architecture for REDD+ transactions program: The REDD+\nenvironmental excellence standard.\n\n\nART. (2021). The REDD+ environmental excellence standard (2.0\ned.). https://www.artredd.org/wp-content/uploads/2021/12/TREES-2.0-August-2021-Clean.pdf\n\n\nBaskerville, G. (1972). Use of logarithmic regression in the estimation\nof plant biomass. Canadian Journal of Forest Research,\n2(1), 49–53.\n\n\nButler, B. J., Sass, E. M., Gamarra, J. G., Campbell, J. L., Wayson, C.,\nOlguıń, M., Carrillo, O., & Yanai, R. D. (2024). Uncertainty in\nREDD+ carbon accounting: A survey of experts involved in REDD+\nreporting. Carbon Balance and Management, 19(1), 22.\n\n\nCamara, G., Simoes, R., Souza, F., Menino, F., Pelletier, C., Andrade,\nP. R., Ferreira, K., & Queiroz, G. (2024). Uncertainty and active\nlearning analysis. In Satellite time series on earth observation\ndata cubes. https://e-sensing.github.io/sitsbook/uncertainty-and-active-learning.html#uncertainty-and-active-learning\n\n\nChen, Q., Laurin, G. V., & Valentini, R. (2015). Uncertainty of\nremotely sensed aboveground biomass over an african tropical forest:\nPropagating errors from trees to plots to pixels. Remote Sensing of\nEnvironment, 160, 134–143. https://doi.org/10.1016/j.rse.2015.01.009\n\n\nClifford, D., Cressie, N., England, J. R., Roxburgh, S. H., & Paul,\nK. I. (2013). Correction factors for unbiased, efficient estimation and\nprediction of biomass from log–log allometric models. Forest Ecology\nand Management, 310, 375–381. https://doi.org/10.1016/j.foreco.2013.08.041\n\n\nDuncanson, L., Disney, M., Armston, J., Nickeson, J., Minor, D., &\nCamacho, F. (2021). Aboveground woody biomass product validation\ngood practices protocol. https://doi.org/10.5067/DOC/CEOSWGCV/LPV/AGB.001\n\n\nDuncanson, L., Rourke, O., & Dubayah, R. (2015). Small sample sizes\nyield biased allometric equations in temperate forests. Scientific\nReports, 5(1), 17153.\n\n\nIPCC. (2019a). 2019 refinement to the 2006 IPCC guidelines for\nnational greenhouse gas inventories (Agriculture, Forestry and\nOther Land Use, Vol. 4). Intergovernmental Panel on Climate Change. https://www.ipcc-nggip.iges.or.jp/public/2019rf/vol4.html\n\n\nIPCC. (2019b). Chapter 2: Generic methodologies applicable to multiple\nland-use categories. In 2019 refinement to the 2006 IPCC guidelines\nfor national greenhouse gas inventories (Agriculture, Forestry and\nOther Land Use, Vol. 4). Intergovernmental Panel on Climate Change. https://www.ipcc-nggip.iges.or.jp/public/2019rf/pdf/4_Volume4/19R_V4_Ch02_Generic%20Methods.pdf\n\n\nKöhler, P., & Huth, A. (2010). Towards ground-truthing of spaceborne\nestimates of above-ground life biomass and leaf area index in tropical\nrain forests. Biogeosciences (Online), 7(8),\n2531–2543.\n\n\nMcRoberts, R. E., & Westfall, J. A. (2016). Propagating uncertainty\nthrough individual tree volume model predictions to large-area volume\nestimates. Annals of Forest Science, 73(ue 3),\n625–633. https://doi.org/10.1007/s13595-015-0473-x\n\n\nPelletier, J., Martin, D., & Potvin, C. (2013). REDD+ emissions\nestimation and reporting: Dealing with uncertainty. Environmental\nResearch Letters, 8(3), 034009.\n\n\nPelletier, N., THIAGARAJAN, A., Durnin-Vermette, F., Liang, C., Choo,\nD., Cerkowniak, D., Elkhoury, A., MacDonald, D., Smith, W., &\nVandenBygaart, B. (2024). Bayesian calibration of the ipcc tier-2\nsteady-state organic carbon model for canadian croplands using long-term\nexperimental data. Available at SSRN 4877052.\n\n\nPloton, P., Mortier, F., Réjou-Méchain, M., Barbier, N., Picard, N.,\nRossi, V., Dormann, C., Cornu, G., Viennois, G., Bayol, N., & al.,\net. (2020). Spatial validation reveals poor predictive performance of\nlarge-scale ecological mapping models. Nature Communications,\n11(1), 4540.\n\n\nRoxburgh, S., Paul, K., Clifford, D., England, J., & Raison, R.\n(2015). Guidelines for constructing allometric models for the prediction\nof woody biomass: How many individuals to harvest? Ecosphere\n(Washington, D.C), 6(3), 1–27.\n\n\nSheng, J., Zhou, W., & De Sherbinin, A. (2018). Uncertainty in\nestimates, incentives, and emission reductions in REDD+ projects.\nInternational Journal of Environmental Research and Public\nHealth, 15(7), 1544.\n\n\nSimoes, R., Camara, G., Queiroz, G., Souza, F., Andrade, P. R., Santos,\nL., Carvalho, A., & Ferreira, K. (2021). Satellite image time series\nanalysis for big earth observation data. Remote Sensing,\n13(13), 2428.\n\n\nSt-Onge, B., Treitz, P., Wulder, M., Kurz, W., & Gillis, M. (2004).\nRetrospective mapping of structural and biomass changes in forest\necosystems using photogrammetry and laser altimetry. AGU Spring\nMeeting Abstracts, 2004, B21B–04.\n\n\nYanai, R. D., Battles, J. J., Richardson, A. D., Blodgett, C. A., Wood,\nD. M., & Rastetter, E. B. (2010). Estimating uncertainty in\necosystem budget calculations. Ecosystems (New York, N.Y.),\n13(ue 2), 239–248. https://doi.org/10.1007/s10021-010-9315-8",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>References</span>"
    ]
  },
  {
    "objectID": "references/glossary.html",
    "href": "references/glossary.html",
    "title": "Appendix B — Glossary & Addendum",
    "section": "",
    "text": "Modelling vs. Recurring Sources\nFramework from Pelletier et al. (2024) distinguishes temporal behavior:\nSource Type\nDefinition\nExamples\nTypical Magnitude\nModelling sources\nModel parameters & assumptions\nFallow classification, growth rates\n4-262% (highest)\nRecurring sources\nMeasurement errors\nActivity data, emission factors\n30-50%\nModelling sources vs. recurring sources of uncertainty\n“The highest error propagated using Monte Carlo simulations was caused by modelling sources of uncertainty, which calls for special attention to ensure consistency in REDD+ reporting which is essential for securing environmental integrity.” (Pelletier et al., 2024)\nStrategic implication: Modelling sources can be standardized across jurisdictions (one-time investment), while recurring sources require continuous monitoring (ongoing costs).\nSensitivity Analysis Framework\nSobol indices identify variance contributions:\nFirst-order effects (Si): Direct contribution\nTotal effects (STi): Direct + interactions\nTypical results: Activity data (Si = 0.42) &gt;&gt; Biomass (0.31) &gt;&gt; Combustion factor (0.18) &gt;&gt; Emission factor (0.03)\nComplementary methods:\nPartial correlation coefficients\nTornado diagrams for parameter ranking\nPanama case study (Pelletier et al., 2024): Fallow classification and carbon accumulation = highest sensitivity\nOptimization Strategies\nInvestment hierarchy (based on Sobol indices + cost):\nIntervention\nVariance Reduced\nCost\nROI Tier\nPriority\nActivity data QA/QC\n42% → 30% (12 pp)\n$30-50k\nVery High\n1\nEnhanced plot sampling\n31% → 20% (11 pp)\n$50-100k\nHigh\n2\nTier 2 allometry\n31% → 22% (9 pp)\n$15-30k\nVery High\n3\nGround Cf measurement\n18% → 12% (6 pp)\n$20-40k\nModerate\n4\nFTIR emission factors\n3% → 2% (1 pp)\n$50-100k\nVery Low\n5\nCost-benefit ranking for uncertainty reduction (Chapter 4 detail)\nTemporal aggregation provision:\n5-year recalculation: Aggregate uncertainty across crediting period\nRecovery mechanism: Over-deducted credits issued if cumulative uncertainty decreases\nTypical benefit: 5-10 percentage point reduction from temporal averaging\nExample: Individual-year deductions = 492,500 t CO2; Aggregated = 406,700 t CO2 → Recovery: 85,800 t CO2\nSoftware Systems\nAll analyses in this book use R (≥4.2.0) with the following packages:\nCore packages:\n\nC Statistical analysis\nlibrary(MASS) # Multivariate normal sampling library(boot) # Bootstrap resampling library(caret) # Cross-validation\n\n\nD Monte Carlo simulation\nlibrary(mc2d) # Two-dimensional Monte Carlo library(sensitivity) # Sobol sensitivity analysis\n\n\nE Visualization\nlibrary(ggplot2) # Publication-quality graphics library(plotly) # Interactive plots\nSpecialized packages:\n\n\nF Allometry\nlibrary(BIOMASS) # Pantropical allometric equations library(allodb) # Global allometry database\n\n\nG Spatial analysis\nlibrary(terra) # Raster processing library(sf) # Vector spatial data library(exactextractr) # Zonal statistics\n\n\nH Reporting\nlibrary(knitr) # Dynamic documents library(rmarkdown) # Report generation\nKey Terminology\nPrecision vs. Accuracy:\nPrecision: Reproducibility of measurements (random error)\nAccuracy: Closeness to true value (systematic bias)\nConfidence intervals:\n90% CI: Range containing true value with 90% probability\nHalf-width: Distance from mean to CI bound = (Upper - Lower) / 2\nError types:\nType 1: False rejection of null hypothesis (α error)\nType 2: False acceptance of null hypothesis (β error)\nType 3: Solving the wrong problem (asking the wrong question)\nType 4: Applying results outside valid domain (extrapolation)\nIPCC Tiers:\nTier 1: IPCC default methods and parameters\nTier 2: Country-specific methods or parameters\nTier 3: Higher-order methods (models, repeated measurements)\nLULC Approaches:\nApproach 1: Total area change (no spatial data)\nApproach 2: Tracking of land-use conversions (transition matrices)\nApproach 3: Spatially explicit tracking (wall-to-wall maps)\n\n\n\n\n\n\nPelletier, N., THIAGARAJAN, A., Durnin-Vermette, F., Liang, C., Choo, D., Cerkowniak, D., Elkhoury, A., MacDonald, D., Smith, W., & VandenBygaart, B. (2024). Bayesian calibration of the ipcc tier-2 steady-state organic carbon model for canadian croplands using long-term experimental data. Available at SSRN 4877052.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Glossary & Addendum</span>"
    ]
  }
]