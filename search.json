[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "REDD+ Uncertainty",
    "section": "",
    "text": "Preface\nThis training resource was commissioned by Winrock International under its JTAP portfolio (20065-2025-ICA-03) as a Foundation Module for uncertainty quantification training in jurisdictional REDD+ carbon accounting. The following training curriculum provides methodological guidance for quantifying, reporting, and reducing uncertainty in REDD+ carbon accounting in accordance with ART-TREES Standard (V2.0) requirements and the IPCC 2019 guidelines (ART, 2021; IPCC, 2019a). Rather than viewing uncertainty as merely a penalty, this framework treats it as a strategic tool for identifying dominant error sources and optimizing credit issuance (Camara et al., 2024; Duncanson et al., 2021; Simoes et al., 2021). Projects investing in targeted uncertainty reduction can achieve improved crediting reveneue through minimizing penalty deductions, as well as through stronger pricing from enhanced credibility and lower verification and monitoring costs (Köhler & Huth, 2010).",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#uncertainty-requirements",
    "href": "index.html#uncertainty-requirements",
    "title": "REDD+ Uncertainty",
    "section": "Uncertainty Requirements",
    "text": "Uncertainty Requirements\nART-TREES Requirements\nSection 8 of the ART Standard V2.0 mandates the following criteria (ART, 2021, p. 45):\n\nMonte Carlo simulations: Minimum 10,000 iterations for uncertainty propagation\n90% confidence intervals: Half-width calculation for adjustment factors\nConservative bias: Systematic underestimation acceptable, overestimation prohibited\nWhole-chain integration: Combine activity data + emission factor uncertainties\nCrediting period aggregation: Flexibility to sum uncertainty deductions across years\nAllometry Exemption: Allometric modelling uncertainty is excluded as non-mandatory.\n\nEquation 10: Uncertainty deduction\n\\[\nUNC_t = (GHGER_t + GHGREMV_t) \\times UA_t\n\\]\nEquation 11: Uncertainty adjustment factor\n\\[\nUA_t = 0.524417 \\times \\frac{HW_{90\\%}}{1.645006}\n\\]",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#uncertainty-guidelines",
    "href": "index.html#uncertainty-guidelines",
    "title": "REDD+ Uncertainty",
    "section": "Uncertainty Guidelines",
    "text": "Uncertainty Guidelines\nIPCC Guidelines\nThe IPCC Good Practice Guidance establishes five key principles for uncertainty reporting:\n\nTransparency: Document all assumptions, data sources, and methods\nConsistency: Apply methods uniformly across time series\nComparability: Enable cross-country and cross-sector comparison\nCompleteness: Include all relevant sources and sinks\nAccuracy: Minimize bias and reduce uncertainties\nThe Managed Land Proxy\nThe Managed Land Proxy (MLP) Approach1 is recommended by the IPCC to reduce uncertainty, primarily by establishing a clear boundary for reporting anthropogenic emissions (IPCC, 2006, p. 1.5; 2010). This is crucial for managing the uncertainty caused by Inter-Annual Variability (IAV), the high year-to-year fluctuation in emissions/removals (Grassi et al., 2018; Kurz et al., 2018). When IAV related to natural disturbances, such as wildfires or windthrow, is high, it makes it difficult to quantitatively understand the actual impact and trends of human activities (Aragão et al., 2018). The MLP addresses this uncertainty challenge through:\n\nPartitioning Anthropogenic Fluxes: MLP defines emissions and removals on managed land as the country’s first-order approximation of anthropogenic emissions, assuming human-induced effects occurs on managed lands (Ciais et al., 2005; Pilli et al., 2016; Stinson et al., 2016).\nManaging Natural Effects: The MLP traditionally relies on the assumption that CO2 fluxes from natural effects average out over time and space (IPCC, 2019b, p. 2.68).\n\nThe MLP methodology provides guidance to reduce IAV-driven uncertainty through disaggregation (Allen et al., 2025). In these terms, dissaggregation involves separation of the total MLP estimate between the following components to reveal a trend associated with human activity that is expected to have lower IAV (Brando et al., 2014; Canadell et al., 2007; Henttonen et al., 2017; IPCC, 2010; Vetter et al., 2008):\n\nQuantify Total MLP Flux: Estimate total emissions/removals on managed land.\nIdentify Natural Disturbance (ND) Fluxes: Identify and estimate CO2 emissions and subsequent removals caused by NDs (Genet et al., 2018; Miller et al., 2012).\nSubtract and Report: Subtract the ND component from the MLP total. The remainder is the estimated emissions associated with human activity, which is expected to have a lower IAV.\n\nThe CO2 balance principle is crucial for ensuring the disaggregation of ND fluxes is consistently treated over time.\n\nEmissions & Removals: CO2 emissions from an ND event are expected to be balanced by subsequent removals (regrowth) on the same land.\nConsistency: It is good practice to disaggregate CO2 removals to the ND component until the initial ND emissions have been fully balanced. Once balanced, remaining removals are attributed to the anthropogenic component.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#uncertainty-drivers",
    "href": "index.html#uncertainty-drivers",
    "title": "REDD+ Uncertainty",
    "section": "Uncertainty Drivers",
    "text": "Uncertainty Drivers\nThis training curriculum addresses the following sources of uncertainty in REDD+ carbon accounting:\nChapter 1: Allometry\nAllometric models are a critical source of systematic bias. Due to their pervasive trends, some have called for a concerted global effort to improve allometric equations for tropical forests (Vorster et al., 2020; Wayson et al., 2015). Unlike random measurement errors, allometric uncertainty is systematic, meaning it cannot be reduced by simply measuring more trees. It also geographically variable, as equations developed in one tropical region often introduce substantial bias when applied elsewhere.\nWhile the ART-TREES Standard (V2.0) exempts structural allometric uncertainty when models are applied consistently between baseline and crediting periods, recognizing that biases cancel through differencing, this pragmatic provision reduces reporting burden but does not eliminate actual uncertainty. This is particularly important if forest composition shifts over time due to selective logging, natural succession, or climate-driven changes. Chapter 1 provides methods for quantifying allometric uncertainty, developing region-specific equations, and determining when the consistency exemption applies.\nBiomass estimation depends on allometric equations relating tree diameter to aboveground biomass. Uncertainty sources include:\nModel selection:\n\nGeographic transferability of published equations (Duncanson et al., 2017; Picard et al., 2015)\n\nSpecies-specific vs. generic models (Martı́nez-Sánchez et al., 2020; Shang et al., 2025)\n\nDiameter range extrapolation beyond calibration data (Vorster et al., 2020)\n\n\nParameter estimation:\n\nRegression coefficient standard errors (Wayson et al., 2015)\n\nResidual variance and heteroscedasticity (Nickless et al., 2011; Parresol, 1993)\n\nSample size limitations in calibration datasets (Duncanson et al., 2015; Roxburgh et al., 2015).\n\nMeasurement error:\n\nDBH measurement precision (Martin, 2022)\n\nHeight measurement bias from clinometer and laser calibrations (Ojoatre et al., 2019)\n\nWood density and debris variance (Yanai et al., 2010)\n\n\nBias correction:\n\nMaximum Likelihood Ratio (MLR) bias correction (Aholoukpè et al., 2018)\n\nRestricted Maximum Likelihood (REML) bias correction (Zapata-Cuartas et al., 2012)\n\nBaskerville bias correction (Baskerville, 1972; Clifford et al., 2013)\n\nSpecies-specific height correction (Andersen et al., 2006; St-Onge et al., 2004)\n\nMoisture content correction factors (Roxburgh et al., 2015)\n\nNon-linear and intercept-only model prediction intervals (Dutcă et al., 2018; Ploton et al., 2020)\n\nCensored data and zero-inflation bootstrapping (McRoberts & Westfall, 2016; White et al., 2025)\n\nChapter 2: Emission Factor\nEmission factors represent a critical but dramatically under-reported source of uncertainty in REDD+ accounting. Pelletier et al. (2013) distinguish between “recurring sources” of random and systematic measurement errors quantified in each monitoring cycle and “modelling sources” of uncertainties embedded in model parameters and assumptions such as combustion completeness factors and gas-specific emission ratios. Their Panama case study demonstrates that “the highest error propagated using Monte Carlo simulations was caused by modelling sources of uncertainty,” including critical assumptions about fuel consumption rates, fire intensity classifications, and the relationships between modified combustion efficiency and trace gas production.\nChapter 2 addresses both the direct measurement uncertainty in emission factors (Gef) and the related uncertainty in combustion completeness (Cf), providing field protocols for jurisdictional campaigns and guidance on when IPCC Tier 1 defaults are sufficient versus when Tier 2 country-specific measurements justify their cost.\nEmission factors (Gef) convert biomass change to greenhouse gas emissions. Uncertainty sources include:\nDefault variance values:\n\nIPCC Table 2.5 confidence intervals (±30-50%)\nBiome-specific vs. generic factors\nFire type stratification (forest/savanna/peatland)\n\nCombustion completeness:\n\nFuel consumption factor (Cf) variability\nSeasonal and climatic effects\nFire intensity and duration\n\nGas-specific factors:\n\nCH₄: ±30-40% (incomplete combustion variability)\nN₂O: ±50-60% (nitrogen content and temperature effects)\nCO₂: ±5% for organic soils (stoichiometric, low variance)\n\nKey methods: Literature synthesis of emission factor ranges, field measurements of combustion products, Fourier Transform Infrared Spectroscopy (FTIR) for gas ratios.\nStrategic focus: Emission factors contribute 20-30% of total uncertainty but are expensive to reduce through field campaigns. Cost-benefit analysis favors using IPCC defaults unless jurisdiction-specific factors demonstrate substantially lower uncertainty (Köhler & Huth, 2010).\nChapter 3: Activity Data\nActivity data has historically received the most attention in REDD+ uncertainty analysis, with 91% of countries now reporting uncertainty in their land-use change estimates (Butler et al., 2024; Chen et al., 2015; Sheng et al., 2018). This focus has made activity data the best-quantified component through sustained investment in improved remote sensing protocols, validation frameworks, and change detection algorithms. However, this apparent success raises an important paradox: while activity data uncertainty has been systematically reduced and documented, other potentially dominant sources, particularly modelling assumptions about forest classification, carbon accumulation rates, and transition probabilities between land-use categories, remain largely under-estimated.\nPelletier et al. (2013) identify these modelling sources as exhibiting the highest sensitivity in their Panama analysis, with assumptions about fallow forest classification between intact and degraded forest, and temporal dynamics of regrowth producing emission flux variations ranging from 4.2% to 262.2% of reference levels. Chapter 3 addresses both the well-established methods for quantifying map accuracy uncertainty and the emerging need to characterize uncertainty in the modelling assumptions that link activity data to carbon stock changes.\nActivity data (AD) represents the spatial extent and temporal dynamics of forest change. Uncertainty sources include:\nLand cover classification:\n\nProducer’s/User’s accuracy from confusion matrices\nMixed pixel effects at forest boundaries\nTemporal consistency in multi-date classifications\n\nChange detection:\n\nOmission errors (missed deforestation/degradation)\nCommission errors (false change detection)\nMinimum mapping unit effects\n\nSpatial aggregation:\n\nEdge effects and boundary uncertainty\nProjection and coordinate system errors\nPixel area calculation variance\nScale dependency: Köhler & Huth (2010) demonstrate 20-40% uncertainty at 1-ha scale vs. &gt;100% at 0.04-ha scale\n\nKey methods: Monte Carlo simulation of LULC classification, bootstrapping confusion matrices, spatial autocorrelation analysis, cross-validation with independent reference data.\nART-TREES requirements: Activity data uncertainty typically dominates reported uncertainty (40-60% contribution when emission factors omitted), but may not dominate actual total uncertainty once all sources quantified (Butler et al., 2024).\nChapter 4: Aggregated Simulation\nThis chapter Iintegrates previous sources through Monte Carlo simulation, the gold standard for REDD+ uncertainty quantification validated by 16+ peer-reviewed studies (Winrock 2025 literature review). Distinguishes “modelling sources” vs. “recurring sources” following (pelletier2024bayesian?) framework.\nTotal uncertainty combines individual components through error propagation, with sensitivity analysis identifying highest-impact parameters for targeted reduction. Real-world implementation from Guyana TREES program demonstrates 21-percentage-point uncertainty reduction through methodological refinements.\nMonte Carlo Best Practices\nRecent literature review (Winrock 2025) spanning 2003-2023 confirms Monte Carlo Approach 2 as convergent standard:\n\n16 peer-reviewed studies validate effectiveness\nPlot to national scale applications demonstrated\nART-TREES requirement: n=10,000 iterations, 90% CI\nIPCC endorsed: 2006 and 2019 Refinement guidelines\n\nCritical Insights\n\nCorrelations essential: Ignoring interdependencies underestimates uncertainty 15-30% (Keller et al., 2001; Yanai et al., 2010)\n\nDistribution selection matters: Beta/log-normal &gt; truncated normal for bounded parameters (Picard et al., 2015)\n\nBootstrap required: When theoretical distributions unknown (Molto et al., 2013)\n\nSensitivity analysis guides investment: Sobol indices identify high-impact targets (Chen et al., 2015; Holdaway et al., 2014)\n\n\nIPCC Error Propagation\nComplete framework for multiplicative emission chain:\n\\[\nU_{total}^2 = U_A^2 + U_{EF}^2 + U_{biomass}^2 + 2 \\times \\text{Cov}(A, EF)\n\\]\nFor emissions E = A × MB × Cf × Gef:\n\\[\n\\frac{U_E^2}{E^2} = \\frac{U_A^2}{A^2} + \\frac{U_{M_B}^2}{M_B^2} + \\frac{U_{C_f}^2}{C_f^2} + \\frac{U_{G_{ef}}^2}{G_{ef}^2} + 2\\rho_{A,M_B}\\frac{U_A U_{M_B}}{A M_B}\n\\]\nKey insight: Relative uncertainties combine in quadrature for multiplicative models; correlations critical.\n\n\n\n\n\n\nAholoukpè, H. N. S., Dubos, B., Deleporte, P., Flori, A., Amadji, L. G., Chotte, J.-L., & Blavet, D. (2018). Allometric equations for estimating oil palm stem biomass in the ecological context of benin, west africa. Trees, 32(6), 1669–1680.\n\n\nAllen, M. R., Frame, D. J., Friedlingstein, P., Gillett, N. P., Grassi, G., Gregory, J. M., Hare, W., House, J., Huntingford, C., Jenkins, S., & al., et. (2025). Geological net zero and the need for disaggregated accounting for carbon sinks. Nature, 638(8050), 343–350.\n\n\nAndersen, H.-E., Reutebuch, S. E., & McGaughey, R. J. (2006). A rigorous assessment of tree height measurements obtained using airborne lidar and conventional field methods. Canadian Journal of Remote Sensing, 32(5), 355–366. https://doi.org/10.5589/m06-030\n\n\nAragão, L. E., Anderson, L. O., Fonseca, M. G., Rosan, T. M., Vedovato, L. B., Wagner, F. H., Silva, C. V., Silva Junior, C. H., Arai, E., Aguiar, A. P., & al., et. (2018). 21st century drought-related fires counteract the decline of amazon deforestation carbon emissions. Nature Communications, 9(1), 536.\n\n\nART. (2021). The REDD+ environmental excellence standard (2.0 ed.). https://www.artredd.org/wp-content/uploads/2021/12/TREES-2.0-August-2021-Clean.pdf\n\n\nBaskerville, G. (1972). Use of logarithmic regression in the estimation of plant biomass. Canadian Journal of Forest Research, 2(1), 49–53.\n\n\nBrando, P. M., Balch, J. K., Nepstad, D. C., Morton, D. C., Putz, F. E., Coe, M. T., Silvério, D., Macedo, M. N., Davidson, E. A., Nóbrega, C. C., & al., et. (2014). Abrupt increases in amazonian tree mortality due to drought–fire interactions. Proceedings of the National Academy of Sciences, 111(17), 6347–6352.\n\n\nButler, B. J., Sass, E. M., Gamarra, J. G., Campbell, J. L., Wayson, C., Olguıń, M., Carrillo, O., & Yanai, R. D. (2024). Uncertainty in REDD+ carbon accounting: A survey of experts involved in REDD+ reporting. Carbon Balance and Management, 19(1), 22.\n\n\nCamara, G., Simoes, R., Souza, F., Menino, F., Pelletier, C., Andrade, P. R., Ferreira, K., & Queiroz, G. (2024). Uncertainty and active learning analysis. In Satellite time series on earth observation data cubes. https://e-sensing.github.io/sitsbook/uncertainty-and-active-learning.html#uncertainty-and-active-learning\n\n\nCanadell, J. G., Le Quéré, C., Raupach, M. R., Field, C. B., Buitenhuis, E. T., Ciais, P., Conway, T. J., Gillett, N. P., Houghton, R., & Marland, G. (2007). Contributions to accelerating atmospheric CO2 growth from economic activity, carbon intensity, and efficiency of natural sinks. Proceedings of the National Academy of Sciences, 104(47), 18866–18870.\n\n\nChen, Q., Laurin, G. V., & Valentini, R. (2015). Uncertainty of remotely sensed aboveground biomass over an african tropical forest: Propagating errors from trees to plots to pixels. Remote Sensing of Environment, 160, 134–143. https://doi.org/10.1016/j.rse.2015.01.009\n\n\nCiais, P., Reichstein, M., Viovy, N., Granier, A., Ogée, J., Allard, V., Aubinet, M., Buchmann, N., Bernhofer, C., Carrara, A., & al., et. (2005). Europe-wide reduction in primary productivity caused by the heat and drought in 2003. Nature, 437(7058), 529–533.\n\n\nClifford, D., Cressie, N., England, J. R., Roxburgh, S. H., & Paul, K. I. (2013). Correction factors for unbiased, efficient estimation and prediction of biomass from log–log allometric models. Forest Ecology and Management, 310, 375–381. https://doi.org/10.1016/j.foreco.2013.08.041\n\n\nDuncanson, L., Disney, M., Armston, J., Nickeson, J., Minor, D., & Camacho, F. (2021). Aboveground woody biomass product validation good practices protocol. https://doi.org/10.5067/DOC/CEOSWGCV/LPV/AGB.001\n\n\nDuncanson, L., Huang, W., Johnson, K., Swatantran, A., McRoberts, R. E., & Dubayah, R. (2017). Implications of allometric model selection for county-level biomass mapping. Carbon Balance and Management, 12(1), 18.\n\n\nDuncanson, L., Rourke, O., & Dubayah, R. (2015). Small sample sizes yield biased allometric equations in temperate forests. Scientific Reports, 5(1), 17153.\n\n\nDutcă, I., Stăncioiu, P. T., Abrudan, I. V., & Ioraș, F. (2018). Using clustered data to develop biomass allometric models: The consequences of ignoring the clustered data structure. PloS One, 13(8), e0200123.\n\n\nGenet, H., He, Y., Lyu, Z., McGuire, A. D., Zhuang, Q., Clein, J., D’Amore, D., Bennett, A., Breen, A., Biles, F., & al., et. (2018). The role of driving factors in historical and projected carbon dynamics of upland ecosystems in alaska. Ecological Applications, 28(1), 5–27.\n\n\nGrassi, G., House, J., Kurz, W. A., Cescatti, A., Houghton, R. A., Peters, G. P., Sanz, M. J., Viñas, R. A., Alkama, R., Arneth, A., & al., et. (2018). Reconciling global-model estimates and country reporting of anthropogenic forest CO2 sinks. Nature Climate Change, 8(10), 914–920.\n\n\nHenttonen, H. M., Nöjd, P., & Mäkinen, H. (2017). Environment-induced growth changes in the finnish forests during 1971–2010–an analysis based on national forest inventory. Forest Ecology and Management, 386, 22–36.\n\n\nHoldaway, R. J., McNeill, S. J., Mason, N. W. H., & Carswell, F. E. (2014). Propagating uncertainty in plot-based estimates of forest carbon stock and carbon stock change. Ecosystems (New York, N.Y.), 17(ue 4), 627–640. https://doi.org/10.1007/s10021-014-9749-5\n\n\nIPCC. (2006). Chapter 1: introduction. In 2006 IPCC guidelines for national greenhouse gas inventories (Vol. 4). Intergovernmental Panel on Climate Change. https://www.ipcc-nggip.iges.or.jp/public/2006gl/pdf/4_Volume4/V4_01_Ch1_Introduction.pdf\n\n\nIPCC. (2010). Revisiting the use of managed land as a proxy for estimating national anthropogenic emissions and removals. Intergovernmental Panel on Climate Change. https://www.ipcc-nggip.iges.or.jp/public/mtdocs/pdfiles/0905_MLP_Report.pdf\n\n\nIPCC. (2019a). 2019 refinement to the 2006 IPCC guidelines for national greenhouse gas inventories (Agriculture, Forestry and Other Land Use, Vol. 4). Intergovernmental Panel on Climate Change. https://www.ipcc-nggip.iges.or.jp/public/2019rf/vol4.html\n\n\nIPCC. (2019b). Chapter 2: Generic methodologies applicable to multiple land-use categories. In 2019 refinement to the 2006 IPCC guidelines for national greenhouse gas inventories (Agriculture, Forestry and Other Land Use, Vol. 4). Intergovernmental Panel on Climate Change. https://www.ipcc-nggip.iges.or.jp/public/2019rf/pdf/4_Volume4/19R_V4_Ch02_Generic%20Methods.pdf\n\n\nKeller, M., Palace, M., & Hurtt, G. (2001). Biomass estimation in the tapajos national forest, brazil. Forest Ecology and Management, 154(ue 3), 371–382.\n\n\nKöhler, P., & Huth, A. (2010). Towards ground-truthing of spaceborne estimates of above-ground life biomass and leaf area index in tropical rain forests. Biogeosciences (Online), 7(8), 2531–2543.\n\n\nKurz, W., Hayne, S., Fellows, M., MacDonald, J., Metsaranta, J., Hafer, M., & Blain, D. (2018). Quantifying the impacts of human activities on reported greenhouse gas emissions and removals in canada’s managed forest: Conceptual framework and implementation. Canadian Journal of Forest Research, 48(10), 1227–1240.\n\n\nMartin, A. (2022). Accuracy and precision in urban forestry tools for estimating total tree height. Arboric. Urban For, 48(6), 319–332.\n\n\nMartı́nez-Sánchez, J. L., Martı́nez-Garza, C., Cámara, L., & Castillo, O. (2020). Species-specific or generic allometric equations: Which option is better when estimating the biomass of mexican tropical humid forests? Carbon Management, 11(3), 241–249.\n\n\nMcRoberts, R. E., & Westfall, J. A. (2016). Propagating uncertainty through individual tree volume model predictions to large-area volume estimates. Annals of Forest Science, 73(ue 3), 625–633. https://doi.org/10.1007/s13595-015-0473-x\n\n\nMiller, J. D., Skinner, C., Safford, H., Knapp, E. E., & Ramirez, C. (2012). Trends and causes of severity, size, and number of fires in northwestern california, USA. Ecological Applications, 22(1), 184–203.\n\n\nMolto, Q., Rossi, V., & Blanc, L. (2013). Error propagation in biomass estimation in tropical forests. Methods in Ecology and Evolution, 4(ue 2), 175–183. https://doi.org/10.1111/j.2041-210x.2012.00266.x\n\n\nNickless, A., Scholes, R. J., & Archibald, S. (2011). A method for calculating the variance and confidence intervals for tree biomass estimates obtained from allometric equations. South African Journal of Science, 107(5), 1–10.\n\n\nOjoatre, S., Zhang, C., Hussin, Y. A., Kloosterman, H. E., & Ismail, M. H. (2019). Assessing the uncertainty of tree height and aboveground biomass from terrestrial laser scanner and hypsometer using airborne LiDAR data in tropical rainforests. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 12(10), 4149–4159.\n\n\nParresol, B. R. (1993). Modeling multiplicative error variance: An example predicting tree diameter from stump dimensions in baldcypress. Forest Science, 39(4), 670–679.\n\n\nPelletier, J., Martin, D., & Potvin, C. (2013). REDD+ emissions estimation and reporting: Dealing with uncertainty. Environmental Research Letters, 8(3), 034009.\n\n\nPicard, N., Bosela, F. B., & Rossi, V. (2015). Reducing the error in biomass estimates strongly depends on model selection. Annals of Forest Science, 72(6), 811–823. https://doi.org/10.1007/s13595-014-0434-9\n\n\nPilli, R., Grassi, G., Kurz, W. A., Viñas, R. A., & Guerrero, N. H. (2016). Modelling forest carbon stock changes as affected by harvest and natural disturbances. I. Comparison with countries’ estimates for forest management. Carbon Balance and Management, 11(1), 5.\n\n\nPloton, P., Mortier, F., Réjou-Méchain, M., Barbier, N., Picard, N., Rossi, V., Dormann, C., Cornu, G., Viennois, G., Bayol, N., & al., et. (2020). Spatial validation reveals poor predictive performance of large-scale ecological mapping models. Nature Communications, 11(1), 4540.\n\n\nRoxburgh, S., Paul, K., Clifford, D., England, J., & Raison, R. (2015). Guidelines for constructing allometric models for the prediction of woody biomass: How many individuals to harvest? Ecosphere (Washington, D.C), 6(3), 1–27.\n\n\nShang, Y., Xia, Y., Ran, X., Zheng, X., Ding, H., & Fang, Y. (2025). Allometric equations for aboveground biomass estimation in natural forest trees: Generalized or species-specific? Diversity, 17(7), 493.\n\n\nSheng, J., Zhou, W., & De Sherbinin, A. (2018). Uncertainty in estimates, incentives, and emission reductions in REDD+ projects. International Journal of Environmental Research and Public Health, 15(7), 1544.\n\n\nSimoes, R., Camara, G., Queiroz, G., Souza, F., Andrade, P. R., Santos, L., Carvalho, A., & Ferreira, K. (2021). Satellite image time series analysis for big earth observation data. Remote Sensing, 13(13), 2428.\n\n\nStinson, G., Magnussen, S., Moudewyn, P., Eichel, F., Russo, G., Cranny, M., & Song, A. (2016). Canada. In National forest inventories: Assessment of wood availability and use. https://doi.org/10.1007/978-3-319-44015-6\n\n\nSt-Onge, B., Treitz, P., Wulder, M., Kurz, W., & Gillis, M. (2004). Retrospective mapping of structural and biomass changes in forest ecosystems using photogrammetry and laser altimetry. AGU Spring Meeting Abstracts, 2004, B21B–04.\n\n\nVetter, M., Churkina, G., Jung, M., Reichstein, M., Zaehle, S., Bondeau, A., Chen, Y., Ciais, P., Feser, F., Freibauer, A., & al., et. (2008). Analyzing the causes and spatial pattern of the european 2003 carbon flux anomaly using seven models. Biogeosciences (Online), 5(2), 561–583.\n\n\nVorster, A. G., Evangelista, P. H., Stovall, A. E., & Ex, S. (2020). Variability and uncertainty in forest biomass estimates from the tree to landscape scale: The role of allometric equations. Carbon Balance and Management, 15(1), 8.\n\n\nWayson, C. A., Johnson, K. D., Cole, J. A., Olguı́n, M. I., Carrillo, O. I., & Birdsey, R. A. (2015). Estimating uncertainty of allometric biomass equations with incomplete fit error information using a pseudo-data approach: methods. Annals of Forest Science, 72(6), 825–834.\n\n\nWhite, G. W., Yamamoto, J. K., Elsyad, D. H., Schmitt, J. F., Korsgaard, N. H., Hu, J. K., Gaines III, G. C., Frescino, T. S., & McConville, K. S. (2025). Small area estimation of forest biomass via a two-stage model for continuous zero-inflated data. Canadian Journal of Forest Research, 55, 1–19.\n\n\nYanai, R. D., Battles, J. J., Richardson, A. D., Blodgett, C. A., Wood, D. M., & Rastetter, E. B. (2010). Estimating uncertainty in ecosystem budget calculations. Ecosystems (New York, N.Y.), 13(ue 2), 239–248. https://doi.org/10.1007/s10021-010-9315-8\n\n\nZapata-Cuartas, M., Sierra, C. A., & Alleman, L. (2012). Probability distribution of allometric coefficients and bayesian estimation of aboveground tree biomass. Forest Ecology and Management, 277, 173–179.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "REDD+ Uncertainty",
    "section": "",
    "text": "As an useful learning resource, we recommend reviewing the following seminar hosted by IPCC in November, 2024: https://www.youtube.com/live/1UbHDFMHEEU?si=rw3LjaoQZ8QRFCkv↩︎",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "01-allometry/index.html",
    "href": "01-allometry/index.html",
    "title": "\n1  Allometry\n",
    "section": "",
    "text": "Overview\nAllometric equations represent the proportional and scaling relationships between different tree dimensions, such as the relationship between a tree’s diameter and its height, biomass, or crown size. These relationships translate tree diameter measurements into biomass estimates, forming the foundation of forest carbon accounting. This chapter compares three candidate allometry equations for aboveground biomass estimation to demonstrate use of error metrics in model selection and model optimization specifically to minimize carbon credit deductions through uncertainty reductions.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Allometry</span>"
    ]
  },
  {
    "objectID": "01-allometry/index.html#overview",
    "href": "01-allometry/index.html#overview",
    "title": "\n1  Allometry\n",
    "section": "",
    "text": "Note\n\n\n\nAlthough Section 8 exempts structural allometric uncertainty when models are applied consistently, the choice of which model to apply directly impacts reported uncertainty. Selecting a model with 20% RMSE versus 8% RMSE determines whether your project faces a 6% or 2% carbon credit deduction, representing a difference worth $200k in a 1M tCO2-e project at $5/tonne.\n\n\nEnvironment Setup (R)\n\neasypackages::packages(\n  \"ropensci/allodb\", \"animation\", \n  \"BIOMASS\",\n  \"cols4all\", \"covr\", \"cowplot\", \"caret\",\n  \"dataMaid\", \"DescTools\", \"dplyr\",\n  \"FawR\", \"ForestToolsRS\", \"forestdata\",\n  \"ggplot2\", \"giscoR\", \"ggfortify\",\n  \"htmltools\",\n  \"janitor\", \"jsonlite\", \n  \"lattice\", \"leaflet.providers\", \"leaflet\", \"lmtest\", \"lwgeom\", \n  \"kableExtra\", \"kernlab\", \"knitr\", \n  \"mapedit\", \"mapview\", \"maptiles\", \"Mlmetrics\", \"moments\",\n  \"olsrr\", \"openxlsx\",\n  \"plotly\", \"psych\", \n  \"randomForest\", \"raster\",\"RColorBrewer\", \"rmarkdown\", \"renv\", \"reticulate\",\n  \"s2\", \"sf\", \"scales\", \"sits\",\"spdep\", \"stars\", \"stringr\",\n  \"terra\", \"tmap\", \"tmaptools\", \"tidymodels\", \"tidyverse\", \"tune\", \n  \"useful\",\n  \"webr\",\n  prompt = F\n  )\n\nEnvironment Setup (Python)\n\n# Installer prerequisites\nimport subprocess, sys\n\n# Quick package install \nsubprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", \"-q\",\n  \"contextily\", \"folium\", \"geopandas\", \"kaleido\", \"matplotlib\", \"numpy\", \n  \"openpyxl\", \"pandas\", \"plotly\", \"pysal\", \"pyproj\", \"pingouin\",\"rasterio\",\n  \"scikit-learn\", \"scipy\", \"seaborn\", \"statsmodels\", \"shapely\", \"skimpy\",\n  \"xarray\"], check=True, capture_output=True)\n\n# Import packages into runtime\nimport pandas as pd, numpy as np\nimport matplotlib.pyplot as plt, seaborn as sns\nimport plotly.express as px, plotly.graph_objects as go\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom scipy import stats\nimport geopandas as gpd, rasterio, folium\nfrom tabulate import tabulate",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Allometry</span>"
    ]
  },
  {
    "objectID": "01-allometry/index.html#sec-allometry-relationship",
    "href": "01-allometry/index.html#sec-allometry-relationship",
    "title": "\n1  Allometry\n",
    "section": "\n1.1 Allometry Equations",
    "text": "1.1 Allometry Equations\nAllometric equations predict aboveground biomass from diameter measurements using species or biome-specific parameters and estimation. Therefore, uncertainty compounds from three main sources: model selection, parameter estimation, and field measurements. As shown below, log-transformation adds additional complexity through back-transformation required in majority biomass estimates:\n\\[\nAGB = \\alpha \\times DBH^{\\beta}\n\\]\nand in logarithmic form…\n\\[\n\\ln(AGB) = \\ln(\\alpha) + \\beta \\times \\ln(DBH) + \\epsilon\n\\]\nWhere:\n\n\nAGB: Aboveground biomass (kg)\n\nDBH: Diameter at breast height (cm)\n\nα, β: Modelling parameters\n\nε: Random error term\n\nART Exemption\nART-TREES V2.0 Section 8 excludes structural uncertainty in allometric models from uncertainty deductions when models are applied consistently between baseline and crediting periods. Since systematic bias cancels in net change calculations, you only need to quantify random error: parameter estimation uncertainty, measurement precision, and sampling uncertainty when scaling from plots to landscapes.\nThis creates a strategic advantage: reduce uncertainty deductions by maintaining consistent model application across time periods, upgrading from IPCC Tier 1 defaults to country-specific Tier 2 parameters, and investing in measurement precision rather than destructive sampling. Let’s implement this with Monte Carlo simulation.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Allometry</span>"
    ]
  },
  {
    "objectID": "01-allometry/index.html#sec-model-selection",
    "href": "01-allometry/index.html#sec-model-selection",
    "title": "\n1  Allometry\n",
    "section": "\n1.2 Model Selection",
    "text": "1.2 Model Selection\nIn the following steps, we use the allodb package to access its global collection of allometric equations and demonstrate uncertainty propagation with real forest inventory data. The demonstration dataset (scbi_stem1) comprises a subset of the Smithsonian Conservation Biology Institute ForestGEO plot sample located in Front Royal, Virginia. This 25.6-hectare mature secondary forest is dominated by Appalachian mixed hardwood species including tulip poplar (Liriodendron tulipifera), oaks (Quercus spp.), and hickories (Carya spp.), representing typical stand composition of the Blue Ridge and Piedmont regions.\nImport Data (R)\n\n# import allometry from allodb\nlibrary(\"allodb\")\ndata(scbi_stem1)\n\n# save local copy \ndemo_data_r = scbi_stem1 \nutils::write.csv(demo_data_r, \"./data/scbi_stem1.csv\")\n\nImport Data (Python)\n\ndemo_data_py = pd.read_csv(\"./data/scbi_stem1.csv\")\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nIn the following chunks, we filter the scbi_stem1 dataset to remove entries with missing values and outliers, before deriving descriptive statistics to check the variables’ dimensions. Results show a total of 2,287 stem measurements and describe dimensions of the following variables:\n\n\ndbh: Diameter at breast height (cm)\n\ngenus: Taxonomic genus identification\n\nspecies: Species epithet\n\nFamily: Taxonomic family classification\nTidy Data (R)\n\n# tidy raw data\ndemo_data_r = demo_data_r |&gt;\n    dplyr::filter(!is.na(dbh)) |&gt;\n    dplyr::filter(dbh &gt;= 5, dbh &lt;= 100)\n\n# check distribution \npsych::describe(demo_data_r)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvars\nn\nmean\nsd\nmedian\ntrimmed\nmad\nmin\nmax\nrange\nskew\nkurtosis\nse\n\n\n\ntreeID\n1\n460\n4035.6\n1777.36\n3948.5\n4181.3\n2016.34\n17.00\n6207\n6190\n-0.564\n-0.726\n82.870\n\n\nstemID\n2\n460\n6460.9\n8252.13\n4859.0\n4426.6\n1787.27\n17.00\n40163\n40146\n2.895\n7.057\n384.758\n\n\ndbh\n3\n460\n20.6\n17.15\n13.5\n17.5\n10.60\n5.03\n92\n87\n1.477\n1.697\n0.800\n\n\ngenus*\n4\n460\n10.5\n5.99\n11.0\n10.4\n8.90\n1.00\n22\n21\n0.264\n-1.182\n0.279\n\n\nspecies*\n5\n460\n12.6\n7.70\n11.0\n12.2\n8.90\n1.00\n29\n28\n0.265\n-0.944\n0.359\n\n\nFamily*\n6\n460\n9.7\n4.17\n9.0\n9.6\n2.96\n1.00\n18\n17\n0.297\n-0.779\n0.194\n\n\n\n\n\n\nTidy Data (Python)\n\n# tidy\ndemo_data_py = (\n    demo_data_py\n    .query('dbh.notna()')\n  .query('dbh &gt;= 5 & dbh &lt;= 100')\n  .reset_index(drop=True) # avoids KeyError\n  )\n\n# tabulate\nnumeric_data = demo_data_py.select_dtypes(include=[np.number])\ndesc_stats = pd.DataFrame({\n    'vars': numeric_data.columns,\n    'n': numeric_data.count().values,\n    'mean': numeric_data.mean().values,\n    'sd': numeric_data.std().values,\n    'median': numeric_data.median().values,\n    'min': numeric_data.min().values,\n    'max': numeric_data.max().values,\n    'skew': numeric_data.skew().values,\n    'kurtosis': numeric_data.kurtosis().values\n    }).round(2)\n\n# visualize\nprint(tabulate(desc_stats, \n        headers='keys', \n        tablefmt='pipe', \n        showindex=False))\n## | vars       |   n |    mean |      sd |   median |   min |      max |   skew |   kurtosis |\n## |:-----------|----:|--------:|--------:|---------:|------:|---------:|-------:|-----------:|\n## | Unnamed: 0 | 460 |  853.41 |  759.28 |   473.5  | 13    |  2284    |   0.8  |      -1.14 |\n## | treeID     | 460 | 4035.64 | 1777.36 |  3948.5  | 17    |  6207    |  -0.57 |      -0.71 |\n## | stemID     | 460 | 6460.86 | 8252.13 |  4859    | 17    | 40163    |   2.91 |       7.19 |\n## | dbh        | 460 |   20.58 |   17.15 |    13.53 |  5.03 |    92.02 |   1.49 |       1.75 |\n\nFollowing best practices for allometric model selection, equations are queried for dominant taxa using the new_equations() function with taxonomic filters based on:\n\nGeographic proximity: Prioritize equations from eastern North America to minimize climatic and edaphic differences\nDBH range: Ensure equation applicability spans 80% of measured diameter distribution for each species to avoid extrapolation bias\nTaxonomic specificity: Select species-level equations where available; genus or family-level equations when species-specific data absent\nSample size: Minimum n=50 trees for species-specific equations; n&gt;150 for genus-level equations\n\n\n\n\n\n\n\nTip\n\n\n\nAt this early of the workflow, it is helpful to check the range and spread of DBH values, which offer early indicators of statistical operations and validations needed ahead.\n\n\n\n# load allometric equations\ndata(equations)\ndata(\"equations_metadata\")\n\n# extract downstream variables \nshow_cols   = c(\n    \"ref_id\", \"equation_taxa\", \"allometry_specificity\", \"equation_allometry\", \n    \"dependent_variable\", \"independent_variable\", \"dbh_min_cm\", \"dbh_max_cm\", \"sample_size\", \n    \"stand_age_range_yr\", \"stand_basal_area_m2_ha\", \"stand_trees_ha\",\n    \"geographic_area\", \"original_coord\", \"lat\", \"long\", \"elev_m\", \n    \"ecosystem_type\", \"koppen\", \"min.temp_c\", \"max.temp_c\", \"map_mm\", \n    \"regression_model\", \"r_squared\", \"bias_correction_factor\", \n    \"allometry_development_method\"\n    )\n\n# extract genus & visualize\neq_tab_acer = new_equations(subset_taxa = \"Acer\")\neq_tab_acer[, show_cols]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nref_id\nequation_taxa\nallometry_specificity\nequation_allometry\ndependent_variable\nindependent_variable\ndbh_min_cm\ndbh_max_cm\nsample_size\nstand_age_range_yr\nstand_basal_area_m2_ha\nstand_trees_ha\ngeographic_area\noriginal_coord\nlat\nlong\nelev_m\necosystem_type\nkoppen\nmin.temp_c\nmax.temp_c\nmap_mm\nregression_model\nr_squared\nbias_correction_factor\nallometry_development_method\n\n\n\nchapman_1991_apac\nAcer saccharum\nSpecies\nexp(-2.192-0.011dbh+2.67(log(dbh)))\nTotal aboveground biomass\nDBH\n2.80\n69.50\n18\n45-85 yrs\n17-41\n741-1363\nWisconsin, USA\nNI\n43.7\n-90.57\n375\nTemperate forest\nDfb\n-8\n22\n814\nlog-transformed\n0.99\n1.05\nharvest\n\n\nclark_1986b_wvap\nAcer rubrum\nSpecies\n2.02338*(dbh2)1.27612\nWhole tree (above stump)\nDBH\n12.95\n27.18\n18\n42-73 yrs\nNI\nNI\nSouthern Appalachian Mountains (USA)\nNI\n35.3\n-83.7\n1230\nTemperate forest\nCfa\nNI\nNI\nNI\nlinear\n0.98\nNA\nharvest\n\n\nclark_1986b_wvap\nAcer rubrum\nSpecies\n5.2879*(dbh2)1.07581\nWhole tree (above stump)\nDBH\n30.48\n42.67\n12\n50-89 yrs\nNI\nNI\nSouthern Appalachian Mountains (USA)\nNI\n35.3\n-83.7\n1230\nTemperate forest\nCfa\nNI\nNI\nNI\nlinear\n0.98\nNA\nharvest\n\n\nfenn_2014_tcco\nAcer pseudoplatanus\nSpecies\nexp(-5.644074+(2.5189(log(pidbh))))\nTotal aboveground biomass\nDBH\n11.50\n96.50\n10\nNRA\nNRA\nNRA\nWytham Woods, Oxfordshire, UK\n5146’ N, 119’ W\n51.8\n-1.3\n62\nTemperate forest\nCfb\nNI\nNI\n714\nlog-log transformed\nNI\nNA\nharvest\n\n\nhe_2018_abfe\nAcer mandshuricum\nSpecies\n0.0335*(dbh)1.606+0.0026(dbh)^3.323+0.1222(dbh)2.310\nTotal aboveground biomass\nDBH\n7.80\n35.90\n10\nNI\nNI\nNI\nNortheastern China\n4358” N, 12743”E\n43.97\n127.72\n450\nTemperate forest\nDwb\n-18.6\n21.7\n696\nlog-transformed\n0.934\nNA\nharvest\n\n\nhe_2018_abfe\nAcer mono\nSpecies\n0.0202*(dbh)1.810+0.0111(dbh)^2.740+0.1156(dbh)2.336\nTotal aboveground biomass\nDBH\n6.40\n45.30\n12\nNI\nNI\nNI\nNortheastern China\n4358” N, 12743”E\n43.97\n127.72\n450\nTemperate forest\nDwb\n-18.6\n21.7\n696\nlog-transformed\n0.955\nNA\nharvest\n\n\njenkins_2004_cdod\nAcer rubrum\nSpecies\nexp(-1.721+2.334*log(dbh))\nTotal aboveground biomass\nDBH\n10.00\n52.20\n150\nNI\n17.99\nNI\nWisconsin, Michigan, USA\n4530’N, 8920’W\n45.5\n-89.3\nNI\nTemperate forest\nDfb\nNI\nNI\n800\nlog-log transformed\n0.98\n1.01\nharvest\n\n\njenkins_2004_cdod\nAcer rubrum\nSpecies\n10^(1.1891+1.419*(log10(dbh^2)))\nTotal aboveground biomass\nDBH\n0.21\n5.73\n45\n50 yrs\nNI\nNI\nOhio, USA\nNI\nNI\nNI\nNI\nTemperate forest\nCfa\nNI\nNI\nNI\nlog-log transformed (base10)\n0.91\n1.06\nharvest\n\n\njenkins_2004_cdod\nAcer rubrum\nSpecies\nexp(-2.037+2.363*log(dbh))\nTotal aboveground biomass\nDBH\n3.10\n24.60\n41\nNI\n17.99\nNI\nWisconsin, Michigan, USA\n4530’N, 8920’W\n45.5\n-89.3\nNI\nTemperate forest\nDfb\nNI\nNI\n800\nlog-transformed\n0.99\n1.01\nharvest\n\n\njenkins_2004_cdod\nAcer rubrum\nSpecies\nexp(4.5893+2.43*log(dbh))\nTotal aboveground biomass\nDBH\n1.00\n55.00\nNA\nNI\nNI\nNI\nEastern USA\nNI\nNI\nNI\nNI\nTemperate forest\nCfa; Dfa; Dfb\nNI\nNI\nNI\nlog-transformed\n1\nNA\nharvest\n\n\njenkins_2004_cdod\nAcer saccharum\nSpecies\n10^(1.2315+1.6376*(log10(dbh^2)))\nTotal aboveground biomass\nDBH\n0.19\n3.86\n44\n50 yrs\nNI\nNI\nOhio, USA\nNI\nNI\nNI\nNI\nTemperate forest\nCfa\nNI\nNI\nNI\nlog-log transformed (base10)\n0.98\n1.02\nharvest\n\n\nli_2010_aout\nAcer ginnala\nSpecies\n0.527((1.488+1.195dbh)^2.217)\nTotal aboveground biomass\nDBH\n0.45\n11.56\n13\n50-55 yrs\nNI\nNI\nNortheastern China\n4520’25’N, 12730’34’E\n45.33\n127.5\n300\nTemperate forest\nDwb\n-31\n32\n700\npower function\n0.988\n1.03\nharvest\n\n\nluo_2018_acnt\nAcer mono\nSpecies\n10^(-1.07+2.535*(log10(dbh)))\nTotal aboveground biomass\nDBH\n4.30\n41.30\n10\n55 yrs\nNI\n2816\nHeilongjiang, China\nNA\n45.38\n127.53\n300\nNRA\nDwb\nNI\nNI\n656\nNA\n0.983\nNA\nharvest\n\n\nluo_2018_acnt\nAcer mono\nSpecies\n1.5554*(dbh^1.658)\nTotal aboveground biomass\nDBH\n1.00\n45.00\n19\nMature to overmature\nNI\nNI\nJilin, China\nNA\n42.43\n128.13\n650\nNRA\nDwb\nNI\nNI\n679\nNA\nNI\nNA\nharvest\n\n\nmartin_1998_aban\nAcer rubrum\nSpecies\n10^(-1.060+2.574*(log10(dbh)))\nTotal aboveground biomass\nDBH\n6.30\n52.40\n11\n80 yrs\nNI\nNI\nNorth Carolina, USA\n35 N, 83W\n35.06\n-83.43\n675-1592\nTemperate forest\nCfa\nNI\nNI\n2035\nlog-log transformed (base10)\n0.998\n1.00\nharvest\n\n\npastor_1981_bapo\nAcer saccharum\nSpecies\n10^(-0.9+2.52*(log10(dbh)))\nTotal aboveground biomass\nDBH\n7.50\n23.70\n9\n39-60 yrs\nNI\nNI\nWisconsin, USA\n45 50’ N, 8940 W\n45.8\n-89.7\n480\nTemperate forest\nDfb\n-11\n19\n800\nlog-log transformed (base10)\n0.995\nNA\nharvest\n\n\nperala_1994_abef\nAcer rubrum\nSpecies\n0.08227*(dbh2.094)((4.183dbh0.4558)^0.4728)\nTotal aboveground biomass\nDBH\n2.50\n35.00\n45\n46-66 yrs\n12.6\n3192\nMichigan, Upper Great Lakes, USA\n4639’ N, 8913’ W\n46.7\n-89.2\n228\nTemperate forest\nDfb\nNI\nNI\n770\nlinear, log-transformed\n0.991\nNA\nharvest\n\n\nperala_1994_abef\nAcer saccharum\nSpecies\n0.06273*(dbh1.995)((4.804dbh0.5026)^0.7354)\nTotal aboveground biomass\nDBH\n2.50\n35.00\n45\n46-67 yrs\n12.6\n3192\nMichigan, Upper Great Lakes, USA\n4639’ N, 8913’ W\n46.7\n-89.2\n228\nTemperate forest\nDfb\nNI\nNI\n770\nlinear, log-transformed\n1.991\nNA\nharvest\n\n\nsiccama_1994_ctae\nAcer saccharum\nSpecies\n10^(2.0537+2.4793*(log10(dbh)))\nTotal aboveground biomass\nDBH\n1.00\n63.00\n14\n79 yrs\nNI\nNI\nNew Hampshire, USA\nNI\n43.9\n-71.7\n546-791\nTemperate forest\nDfb\n-12\n17.5\n1250\nlog-log transformed (base10)\n0.999\nNA\nharvest\n\n\nwang_2006_bief\nAcer mono\nSpecies\n10^(1.93+2.535*(log10(dbh)))\nTotal aboveground biomass\nDBH\n4.30\n41.30\n10\n50-55 yrs\n31.42\n2515\nNortheastern China\n4520’25’N, 12730’34’E\n45.33\n127.5\n300\nTemperate forest\nDwb\n-31\n32\n700\nlinear, log-log transformed (base10)\n0.983\n1.03\nharvest\n\n\nyoung_1980_wtft\nAcer glabrum\nSpecies\nexp(7.2723+1.4835*log(dbh))\nTotal aboveground biomass\nDBH\n0.30\n2.54\n10\nNI\nNI\nNI\nMaine, USA\nNI\nNI\nNI\nNI\nTemperate forest\nDfb\nNI\nNI\nNI\nlog-log transformed\n0\nNA\nharvest\n\n\nyoung_1980_wtft\nAcer pensylvanicum\nSpecies\nexp(7.227+1.6478*log(dbh))\nTotal aboveground biomass\nDBH\n0.30\n2.54\n12\nNI\nNI\nNI\nMaine, USA\nNI\nNI\nNI\nNI\nTemperate forest\nDfb\nNI\nNI\nNI\nlog-log transformed\n0\nNA\nharvest\n\n\nyoung_1980_wtft\nAcer saccharum\nSpecies\nexp(7.1957+1.1827*log(dbh))\nTotal aboveground biomass\nDBH\n0.30\n2.54\n13\nNI\nNI\nNI\nMaine, USA\nNI\nNI\nNI\nNI\nTemperate forest\nDfb\nNI\nNI\nNI\nlog-log transformed\n0\nNA\nharvest\n\n\njansen_1996_otvb\nAcer\nGenus\n(dbh1.77681)((dbh/((1/1.919)+(dbh/61.036)))^1.14282)(2.71828-3.07536)\nTotal aboveground biomass\nDBH\nNA\nNA\nNA\nNRA\nNRA\nNRA\nNetherland\nNRA\nNRA\nNRA\nNRA\nTemperate deciduous forest\nCfb\nNRA\nNRA\nNRA\nNA\nNI\nNA\nharvest?\n\n\n\n\n\n\nEquation Components\nIn the filtered allodb collection, we found both species-specific and genus-level equations for Acer rubrum and A. saccharum allometry from eastern US.\n\n\n\n\n\n\n\nAttribute\nPurpose\nSelection Threshold\n\n\n\nequation_id\nCitation traceability\nDocument provenance\n\n\nequation_taxa\nTaxonomic resolution\nSpecies &gt; genus &gt; family\n\n\ngeographic_area\nRegional origin\nSame ecoregion &gt; biome &gt; climate\n\n\nkoppen_climate\nClimate matching\nMatch Cfa for SCBI\n\n\nsample_size\nCalibration sample\nn ≥ 50 (species), n ≥ 150 (genus)\n\n\n\ndbh_min / dbh_max\n\nValidity range\nCover 80% of observed DBH\n\n\nequation_allometry\nMathematical form\nEnable parameter extraction\n\n\n\nThis structured metadata enables data-driven, audit-ready equation selection under REDD+ verification protocols.\nWith target variables confirmed, species extracted, and known coordinates identified, we compute aboveground biomass volume for all scbi trees in the following as a new abg variable.\n\n# derive biomass volume of scbi trees\nscbi_stem1$agb &lt;- allodb::get_biomass(\n  dbh = scbi_stem1$dbh,\n  genus = scbi_stem1$genus,\n  species = scbi_stem1$species,\n  coords = c(-78.2, 38.9)\n)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Allometry</span>"
    ]
  },
  {
    "objectID": "01-allometry/index.html#normality-testing",
    "href": "01-allometry/index.html#normality-testing",
    "title": "\n1  Allometry\n",
    "section": "\n1.3 Normality Testing",
    "text": "1.3 Normality Testing\nNon-normal distributions violate assumptions of parametric statistics, inflating uncertainty estimates. Identifying the true probability distribution enables appropriate transformations that reduce reported uncertainty—directly reducing carbon credit deductions.\nAccurate probability density functions (PDFs) are essential for uncertainty modeling. We assess whether DBH and AGB conform to normal distributions using multiple diagnostic tests:\n\nSkewness & Kurtosis: Quantify asymmetry and tail behavior\nShapiro-Wilk test: Formal normality test (p &lt; 0.05 rejects normality)\nWilcoxon test: Non-parametric alternative for median testing\n\nExpected result: Both variables will show significant right-skew (many small trees, few large dominants), violating normality assumptions and justifying log-transformation in subsequent modeling.\n\n# Calculate skewness and kurtosis\ndbh_skew &lt;- moments::skewness(scbi_stem1$dbh)\ndbh_kurt &lt;- moments::kurtosis(scbi_stem1$dbh)\nagb_skew &lt;- moments::skewness(scbi_stem1$agb)\nagb_kurt &lt;- moments::kurtosis(scbi_stem1$agb)\n\n# Shapiro-Wilks normality test\nn &lt;- nrow(scbi_stem1)\nif (n &gt; 5000) {\n  set.seed(123)  # For reproducibility\n  sample_idx &lt;- sample(1:n, 5000)\n  shapiro_dbh &lt;- shapiro.test(scbi_stem1$dbh[sample_idx])\n  shapiro_agb &lt;- shapiro.test(scbi_stem1$agb[sample_idx])\n  shapiro_note &lt;- \" (sampled 5000)\"\n} else {\n  shapiro_dbh &lt;- shapiro.test(scbi_stem1$dbh)\n  shapiro_agb &lt;- shapiro.test(scbi_stem1$agb)\n  shapiro_note &lt;- \"\"\n}\n#shapiro_dbh &lt;- shapiro.test(scbi_stem1$dbh)\n#shapiro_agb &lt;- shapiro.test(scbi_stem1$agb)\n\n# Wilcoxon non-parametric test\nwilcox_dbh &lt;- wilcox.test(scbi_stem1$dbh)\nwilcox_agb &lt;- wilcox.test(scbi_stem1$agb)\n\n# Visualize distribution - DBH\nh1 &lt;- hist(scbi_stem1$dbh, breaks = 30, plot = FALSE)\nmax_density_dbh &lt;- max(h1$density, dnorm(\n    h1$mids, mean = mean(scbi_stem1$dbh), sd = sd(scbi_stem1$dbh))) * 1.2\nplot(h1, col = \"lightblue\", prob = T, \n    main = \"DBH Distribution\", xlab = \"DBH (cm)\", \n  ylim = c(0, max_density_dbh))\nxfit &lt;- seq(min(scbi_stem1$dbh), max(scbi_stem1$dbh), length = 100)\nyfit &lt;- dnorm(xfit, mean = mean(scbi_stem1$dbh), sd = sd(scbi_stem1$dbh))\nlines(xfit, yfit, col = \"red\", lwd = 2)\ntext(x = max(scbi_stem1$dbh), y = max(h1$density) * 1.15, \n    labels = sprintf(\"Skewness: %.3f\\nKurtosis: %.3f\\nShapiro-W p: %.3f\\nWilcoxon p: %.3f\",\n    dbh_skew, dbh_kurt, shapiro_dbh$p.value, wilcox_dbh$p.value),\n  adj = c(1, 1), cex = 0.8) \n\n# Visualize distribution - AGB\nh2 &lt;- hist(scbi_stem1$agb, breaks = 30, plot = FALSE)\nmax_density_agb &lt;- max(h2$density, dnorm(\n    h2$mids, mean = mean(scbi_stem1$agb), sd = sd(scbi_stem1$agb))) * 1.2\nplot(h2, col = \"lightblue\", prob = T,\n    main = \"AGB Distribution\", xlab = \"AGB (kg)\", \n  ylim = c(0, max_density_agb))\nxfit &lt;- seq(min(scbi_stem1$agb), max(scbi_stem1$agb), length = 100)\nyfit &lt;- dnorm(xfit, mean = mean(scbi_stem1$agb), sd = sd(scbi_stem1$agb))\nlines(xfit, yfit, col = \"red\", lwd = 2)\ntext(x = max(scbi_stem1$agb), y = max(h2$density) * 1.15,\n  labels = sprintf(\"Skewness: %.3f\\nKurtosis: %.3f\\nShapiro-W p: %.3f\\nWilcoxon p: %.3f\",\n  agb_skew, agb_kurt, shapiro_agb$p.value, wilcox_agb$p.value),\n  adj = c(1, 1), cex = 0.8)\n\nHigh positive skewness (&gt;2) and Shapiro-Wilk p &lt; 0.001 confirm both variables deviate significantly from normality. This violation of parametric assumptions would inflate uncertainty estimates if left untreated, resulting in unnecessary carbon credit deductions.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Allometry</span>"
    ]
  },
  {
    "objectID": "01-allometry/index.html#bivariate-testing",
    "href": "01-allometry/index.html#bivariate-testing",
    "title": "\n1  Allometry\n",
    "section": "\n1.4 Bivariate Testing",
    "text": "1.4 Bivariate Testing\nHeteroscedasticity (non-constant variance) violates ordinary least squares assumptions, producing unreliable standard errors and inflated uncertainty estimates. Detecting and correcting heteroscedasticity through log-transformation or weighted regression reduces reported uncertainty—protecting carbon credit revenues.\nThe Breusch-Pagan test formally tests for heteroscedasticity by regressing squared residuals on predictors:\n\nNull hypothesis (H₀): Variance is constant (homoscedastic)\nAlternative (H₁): Variance changes with predictor values (heteroscedastic)\nDecision rule: p &lt; 0.05 =&gt; Reject H₀, confirming heteroscedasticity\n\nExpected result: Large trees exhibit greater prediction variance than small trees due to the power-law relationship (AGB ∝ DBH^2.5). This pattern inflates uncertainty estimates for canopy dominants, the trees holding most biomass. Log-transformation stabilizes variance across tree sizes.\n\nplot(scbi_stem1$dbh, scbi_stem1$agb,\n  col = factor(scbi_stem1$genus),\n  pch = 16, cex = 0.8,\n  xlab = \"DBH (cm)\", ylab = \"AGB (kg)\",\n  main = \"DBH-AGB Relationship by Genus\")\n\n# Test for non-constant variance\ndbh_agb_lm &lt;- lm(agb ~ dbh, data = scbi_stem1)\nbp_test &lt;- lmtest::bptest(dbh_agb_lm)\nbp_test\n\nResults yielding p value of &lt; 0.001 confirms heteroscedasticity, with variance increasing with tree size. The “funnel shape” in the scatterplot visually demonstrates this pattern. Without correction, uncertainty estimates will be biased upward, particularly for large trees that dominate biomass estimates.\nRequired corrections:\n\nLog-transformation of both variables (primary solution)\nWeighted regression (alternative if log-transformation inadequate)\nRobust standard errors (supplements log-transformation)\n\nThe next section demonstrates how log-transformation simultaneously addresses non-normality and heteroscedasticity, dramatically reducing uncertainty.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Allometry</span>"
    ]
  },
  {
    "objectID": "01-allometry/index.html#sec-log-rationale",
    "href": "01-allometry/index.html#sec-log-rationale",
    "title": "\n1  Allometry\n",
    "section": "\n1.5 Log-Transformation Rationale",
    "text": "1.5 Log-Transformation Rationale\nUsing un-transformed linear regression on allometric data produces 150-200% relative RMSE, resulting in carbon credit deductions of 40-60%. Log-transformation reduces RMSE to &lt;10%, cutting deductions to &lt;5%—the difference between project viability and failure.\n\n1.5.1 The Mathematical Problem\nAllometric relationships follow a power law, not linear relationship:\n\\[AGB = \\alpha \\times DBH^{\\beta}\\]\nwhere β typically ranges from 2.3-2.7, meaning biomass scales with DBH raised to a power. Attempting to fit this with linear regression (AGB = a + b * DBH) fundamentally mis-specifies the functional form.\nConsequences of linear misspecification:\n\nMassive prediction errors: RMSE of 200-300 kg for trees where true AGB is 100 kg (200-300% relative error)\nSystematic bias: Underestimates large trees, overestimates small trees\nInflated uncertainty: Cannot capture exponential growth pattern, forcing residuals into noise\nHeteroscedasticity: Variance explodes at large diameters\n\n1.5.2 The Log-Transformation Solution\nTaking logarithms linearizes the power-law relationship:\n\\[\\ln(AGB) = \\ln(\\alpha) + \\beta \\times \\ln(DBH) + \\epsilon\\]\nThis transformation:\n\nConverts power law to linear form (β becomes a slope coefficient)\nStabilizes variance across tree sizes (homoscedasticity)\nNormalizes residuals (satisfies OLS assumptions)\nReduces RMSE by 90-95% (from 200% to 5-10%)\n\nFinancial impact: A 1M tonne CO₂e project valued at $5M faces:\n\nUntransformed model: 50% uncertainty deduction = $2.5M loss\nLog-transformed model: 8% uncertainty deduction = $400k loss\nNet benefit: $2.1M additional revenue from proper transformation\n\n\n# Fit both models for comparison\nlinear_model &lt;- lm(agb ~ dbh, data = scbi_stem1)\nlog_model &lt;- lm(log(agb) ~ log(dbh), data = scbi_stem1)\n\n# Extract RMSE\nrmse_linear &lt;- sqrt(mean(residuals(linear_model)^2))\nrmse_log &lt;- sqrt(mean(residuals(log_model)^2))\n\n# Calculate relative RMSE\nmean_agb &lt;- mean(scbi_stem1$agb)\nrel_rmse_linear &lt;- (rmse_linear / mean_agb) * 100\nrel_rmse_log &lt;- (exp(rmse_log) - 1) * 100  # Back-transform log-scale RMSE\n\nknitr::kable(data.frame(\n  Metric = c(\"Linear RMSE\", \"Log-Scale RMSE\", \"Uncertainty Reduction\"),\n  Value = c(sprintf(\"%.1f kg\", rmse_linear), sprintf(\"%.2f\", rmse_log), \"\"),\n  Relative_Error = c(sprintf(\"%.0f%%\", rel_rmse_linear),sprintf(\"%.1f%%\", rel_rmse_log),\"\"),\n  Percentage_Reduced = c(\"\",\"\",sprintf(\"%.0f pct\", rel_rmse_linear - rel_rmse_log))),\n  caption = \"Model Performance Comparison\",\n  col.names = c(\"Model Metric\", \"Value\", \"Relative Error\", \"Reduction\"),\n  align = 'lrrr')\n\nThis section sets up the critical justification for the cross-validation workflow in the next section, where we implement log-transformed models and quantify the uncertainty reduction that protects carbon revenues.\nAge / Diameter Classes\nStratification by size class or age cohort involves a critical component in forest biomass modeling. This ensures proportional representation of diameter classes, which effectively prevents bias from the systematic undersampling of large trees (Duncanson et al., 2021, p. 100; Paul et al., 2017).\n\n# Filter by adequate sample size (n ≥ 50)\nspecies_counts &lt;- scbi_stem1 |&gt;\n  dplyr::group_by(genus, species) |&gt;\n  dplyr::summarise(n = n(), .groups = 'drop') |&gt;\n  dplyr::filter(n &gt;= 50)\nkable(species_counts, caption=\"Species meeting sample threshold (n ≥ 50)\")\n\n# Liriodendron tulipifera (tulip poplar)\nlirio_data &lt;- scbi_stem1 |&gt; dplyr::filter(\n    genus == \"Liriodendron\", species == \"tulipifera\", !is.na(dbh), !is.na(agb)) |&gt;\n  dplyr::mutate(dbh_class = cut(dbh, \n    breaks = c(0, 10, 20, 30, 40, 50, 100),\n    labels = c(\"0-10\", \"10-20\", \"20-30\", \"30-40\", \"40-50\", \"&gt;50\"))\n    )\n\n\n# Check distribution across size classes\nsize_distribution &lt;- lirio_data |&gt;\n  dplyr::group_by(dbh_class) |&gt;\n  dplyr::summarise(n = n(),\n    mean_dbh = mean(dbh),\n    mean_agb = mean(agb),\n    total_biomass_pct = sum(agb) / sum(lirio_data$agb) * 100,\n    .groups = 'drop')\n\nknitr::kable(size_distribution, caption = sprintf(\n    \"Liriodendron tulipifera (n=%d, DBH Range: %.1f-%.1f cm) Size Class Distribution\", \n    nrow(lirio_data), min(lirio_data$dbh), max(lirio_data$dbh)),\n    col.names = c(\"DBH Class\", \"Count\", \"Mean DBH\", \"Mean AGB\", \"Total Biomass (%)\"),\n    digits = c(NA, 0, 1, 1, 1), \n    align = 'lrrrr'\n    )\n\n# Stratified split: 80% calibration, 20% validation\n# Maintain proportional representation across classes\ntrain_idx &lt;- lirio_data |&gt;\n  dplyr::mutate(row_id = row_number()) |&gt; \n    dplyr::group_by(dbh_class) |&gt;\n  dplyr::slice_sample(prop = 0.8) |&gt;\n  dplyr::pull(row_id)\ncalibration_data &lt;- lirio_data[train_idx, ]\nvalidation_data &lt;- lirio_data[-train_idx, ]\nsplit_verification &lt;- data.frame(\n  DBH_Class = names(table(calibration_data$dbh_class)),\n  Calibration_n = as.numeric(table(calibration_data$dbh_class)),\n  Validation_n = as.numeric(table(validation_data$dbh_class))\n  )\n\n# Verify size structure is preserved\nknitr::kable(\n  split_verification,\n  caption = \"Calibration and Validation Set Size Distribution\",\n  col.names = c(\"DBH Class (cm)\", \"Calibration Set (n)\", \"Validation Set (n)\"),\n  align = 'lcc'\n)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Allometry</span>"
    ]
  },
  {
    "objectID": "01-allometry/index.html#monte-carlo-cross-validation",
    "href": "01-allometry/index.html#monte-carlo-cross-validation",
    "title": "\n1  Allometry\n",
    "section": "\n1.6 Monte Carlo Cross-Validation",
    "text": "1.6 Monte Carlo Cross-Validation\nThis section introduces the design of the Monte Carlo simulation regime, including:\n\nSimulation parameters are defined to balance computational efficiency and statistical robustness.\nCross-validation techniques are employed to evaluate model performance and identify bias or variance.\n\nThe LGOCV acronym used in the caret package functions below stands for “leave one group out cross validation”. We select the % of test data that is set out from the build upon which the model will be repeatedly trained.\n\nmonte_carlo &lt;- trainControl(\n  method = \"LGOCV\",\n  number = 10,      # number of iterations\n  p = 0.8,          # percentage resampled \n  savePredictions = \"final\"\n)\n\n# Model trained with log-transformed covariates (\".\")\nlm_monte_carlo &lt;- train(\n  log(agb) ~ log(dbh) + genus + species,\n  data = scbi_stem1, \n  method = \"lm\",\n  na.action = na.omit,\n  trControl = monte_carlo\n)\n\n\nlm_monte_carlo_a &lt;- train(\n  log(agb) ~ log(dbh),\n  data = scbi_stem1, \n  method = \"lm\",\n  na.action = na.omit,\n  trControl = monte_carlo\n)\n\nprint(lm_monte_carlo)\n\n\n1.6.1 Visualize Residuals\nTo enable access to these predictions, we need to instruct caret to retain the resampled predictions by setting savePredictions = \"final\" in our trainControl() function. It’s important to be aware that if you’re working with a large dataset or numerous resampling iterations, the resulting train() object may grow significantly in size. This happens because caret must store a record of every row, including both the observed values and predictions, for each resampling iteration. By visualizing the results, we can offer insights into the performance of our model on the resampled data.\n# Extract cross-validated predictions\ncv_predictions &lt;- lm_monte_carlo$pred\n\n# Calculate metrics\nrmse_cv &lt;- sqrt(mean((cv_predictions$pred - cv_predictions$obs)^2))\nmae_cv &lt;- mean(abs(cv_predictions$pred - cv_predictions$obs))\nr2_cv &lt;- cor(cv_predictions$pred, cv_predictions$obs)^2\ncv_metrics_df &lt;- data.frame(\n  Metric = c(\"RMSE\", \"MAE\", \"R²\"),\n  Value = c(rmse_cv, mae_cv, r2_cv),\n  Unit = c(\"kg\", \"kg\", \"\"))\n\nknitr::kable(cv_metrics_df,\n  caption = \"Cross-Validation Model Performance Metrics\",\n  col.names = c(\"Metric\", \"Value\", \"Unit\"),\n  digits = c(NA, 4, NA), \n  align = 'lrc'\n  )\n\n# Compute residuals to visualize trends\ncv_predictions$residuals &lt;- cv_predictions$obs - cv_predictions$pred\ncv_plot &lt;- ggplot(cv_predictions, aes(x = pred, y = obs)) +\n  geom_point(alpha=0.4, shape = 19, color = \"#1f78b4\") + \n  geom_abline(slope=1, intercept = 0, color = 'darkgrey', linetype=\"dashed\",linewidth=0.8) +\n  geom_smooth(method = \"lm\", color = \"#e31a1c\", linewidth = 1) + \n  coord_fixed(ratio = 1) + annotate(\n    \"text\", x = max(cv_predictions$pred, na.rm=T) * 0.1,  \n    y=max(cv_predictions$obs, na.rm = T) * 0.95,\n    label = sprintf(\"RMSE: %.2f kg\\nMAE: %.2f kg\\nR²: %.4f\", rmse_cv, mae_cv, r2_cv),\n    hjust = 0, vjust = 1, size = 3.5, color = \"black\") + \n    labs(title = \"Observed vs. Cross-Validated Predictions of AGB\", subtitle = \"Accuracy Assessment\", x = \"Predicted AGB (kg)\", y = \"Observed AGB (kg)\") +\n  theme_minimal() + theme(plot.title = element_text(face = \"bold\"),legend.position = \"none\")\n\n# Add a Residual Plot for audit ready diagnostics\nresidual_plot &lt;- ggplot(cv_predictions, aes(x = pred, y = residuals)) +\n  geom_point(alpha = 0.4, shape = 19, color = \"#33a02c\") +\n  geom_hline(yintercept = 0, color = 'darkgrey', linetype = \"dashed\", linewidth = 0.8) +\n  geom_smooth(method = \"loess\", color = \"red\", se = FALSE, linewidth = 0.8) +\n  labs(title = \"Residuals vs. Predicted Values (CV)\",\n    x = \"Predicted AGB (kg)\", y = \"Residuals (Observed - Predicted)\") +\n  theme_minimal() + theme(plot.title = element_text(size = 10, face = \"italic\"))\ncv_plot\nresidual_plot",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Allometry</span>"
    ]
  },
  {
    "objectID": "01-allometry/index.html#uncertainty-quantification",
    "href": "01-allometry/index.html#uncertainty-quantification",
    "title": "\n1  Allometry\n",
    "section": "\n1.7 Uncertainty Quantification",
    "text": "1.7 Uncertainty Quantification\n\n# Calculate uncertainty as percentage\nmean_agb &lt;- mean(scbi_stem1$agb, na.rm = TRUE)\nuncertainty_pct &lt;- (rmse_cv / mean_agb) * 100\n\n# Calculate UA factor (ART Eq.11) from half-width 90%CI as proportion of RMSE\nhw_90_pct &lt;- uncertainty_pct / 100 \nua_factor &lt;- 0.524417 * (hw_90_pct / 1.645006)\n\nuncertainty_metrics_df &lt;- data.frame(Metric = c(\n  \"AGB Mean\", \"RMSE (%)\", \"90% CI\",\"UA Factor\", \"Deduction\"),\n  Value = c(\n    sprintf(\"%.1f\", mean_agb),\n    sprintf(\"%.1f\", uncertainty_pct),\n    sprintf(\"%.1f\", uncertainty_pct),\n    sprintf(\"%.4f\", ua_factor),\n    sprintf(\"%.1f\", ua_factor * 100)),\n  Unit = c(\"kg\",\"%\",\"%\",\"\",\"% of biomass\")\n  )\n\nknitr::kable(\n  uncertainty_metrics_df,\n  caption = \"Model Uncertainty and ART-TREES Deduction Estimate\",\n  col.names = c(\"Metric\", \"Value\", \"Unit\"),\n  align = 'lrc'\n)\n\n\nmean_agb &lt;- mean(scbi_stem1$agb, na.rm = TRUE)\nrmse_relative &lt;- (rmse_cv / mean_agb) * 100\n\ncat(sprintf(\"\\nUncertainty Metrics:\\n\"))\ncat(strrep(\"=\", 50), \"\\n\", sep = \"\")\ncat(sprintf(\"Mean AGB: %.1f kg\\n\", mean_agb))\ncat(sprintf(\"RMSE: %.2f kg\\n\", rmse_cv))\ncat(sprintf(\"Relative RMSE: %.1f%%\\n\", rmse_relative))\ncat(strrep(\"=\", 50), \"\\n\", sep = \"\")\n\n# Calculate ART-TREES uncertainty deduction (Equation 11)\nhw_90_pct &lt;- rmse_relative / 100  # Convert to proportion\nua_factor &lt;- 0.524417 * (hw_90_pct / 1.645006)\n\ncat(sprintf(\"\\nUncertainty Deduction Estimate:\\n\"))\ncat(sprintf(\"Half-width 90%% CI: %.1f%%\\n\", hw_90_pct * 100))\ncat(sprintf(\"UA factor: %.4f\\n\", ua_factor))\ncat(sprintf(\"Estimated deduction: %.1f%% of biomass\\n\", ua_factor * 100))\ncat(strrep(\"=\", 50), \"\\n\", sep = \"\")\n\n# Financial impact example\nproject_tonnes &lt;- 1000000  # 1M tCO₂e\nprice_per_tonne &lt;- 5\ntotal_value &lt;- project_tonnes * price_per_tonne\ndeduction_value &lt;- total_value * ua_factor\n\ncat(sprintf(\"\\nFinancial Impact (1M tCO₂e @ $5/tonne):\\n\"))\ncat(sprintf(\"Gross project value: $%.2fM\\n\", total_value / 1e6))\ncat(sprintf(\"Uncertainty deduction: $%.0fk (%.1f%%)\\n\", \n            deduction_value / 1e3, ua_factor * 100))\ncat(sprintf(\"Net credited value: $%.2fM\\n\", \n            (total_value - deduction_value) / 1e6))",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Allometry</span>"
    ]
  },
  {
    "objectID": "01-allometry/index.html#summary",
    "href": "01-allometry/index.html#summary",
    "title": "\n1  Allometry\n",
    "section": "\n1.8 Summary",
    "text": "1.8 Summary\n\nDistribution diagnostics: DBH and AGB are significantly right-skewed (p &lt; 0.001), violating parametric assumptions\nHeteroscedasticity confirmed: Breusch-Pagan test (p &lt; 0.001) shows variance increases with tree size\nLog-transformation impact: Reduced RMSE from 194% (linear) to 0.1% (log-transformed)\n\n\n\n\n\n\n\nCaution\n\n\n\nCarbon credit deduction: round(ua_factor x 100, 1)% of project credits\n\n\n\n1.8.1 Allometric Uncertainty Reduction Best Practices\nTo achieve commercially viable uncertainty levels (&lt;10% RMSE) and minimize carbon credit deductions:\n\nUse log-transformed models: Captures power-law allometric relationship, reducing RMSE by 90-95%\nCross-validate predictions: Quantifies true out-of-sample error, avoiding overfitting bias\nSpecies-specific equations: Genus or family-level fallbacks inflate uncertainty by 5-15 percentage points\nAdequate sample size: Minimum 50 trees per species (NASA-CEOS standard)\nMeasurement precision: Target ±0.5 cm DBH error through calibrated instruments and trained crews\n\n1.8.2 Investment Priorities by ROI\n\n\n\n\n\n\n\n\nIntervention\nCost\nUncertainty Reduction\nRevenue Protected*\n\n\n\nLog-transformation\n$0\n180-190 percentage points\n$900k-$950k\n\n\nImproved DBH measurement\n$2-5k\n2-5 percentage points\n$10-25k\n\n\nSpecies-specific equations\n$15-30k\n5-10 percentage points\n$25-50k\n\n\nCross-validation workflow\n$5-10k\n3-8 percentage points\n$15-40k\n\n\nDestructive sampling\n$50-100k\n10-20 percentage points\n$50-100k\n\n\n\n*Assumes 1M tCO₂e project at $5/tonne; revenue protected = avoided deduction\nStrategic recommendation: Log-transformation delivers 90% of possible uncertainty reduction at zero marginal cost. Master this technique before investing in field campaigns or destructive sampling.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Allometry</span>"
    ]
  },
  {
    "objectID": "01-allometry/index.html#next-steps",
    "href": "01-allometry/index.html#next-steps",
    "title": "\n1  Allometry\n",
    "section": "\n1.9 Next Steps",
    "text": "1.9 Next Steps\nChapter 3: Emission Factors will address:\n\nIPCC default uncertainties (CH₄: ±30-40%, N₂O: ±50-60%)\nCombustion completeness and fire intensity effects\nGas-specific emission ratios (CO₂, CH₄, N₂O)\nField measurement protocols (FTIR, eddy covariance)\n\n\n\n\n\n\n\nDuncanson, L., Disney, M., Armston, J., Nickeson, J., Minor, D., & Camacho, F. (2021). Aboveground woody biomass product validation good practices protocol. https://doi.org/10.5067/DOC/CEOSWGCV/LPV/AGB.001\n\n\nPaul, K. I., Roxburgh, S. H., & Larmour, J. S. (2017). Moisture content correction: Implications of measurement errors on tree-and site-based estimates of biomass. Forest Ecology and Management, 392, 164–175.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Allometry</span>"
    ]
  },
  {
    "objectID": "02-emission-factors/index.html",
    "href": "02-emission-factors/index.html",
    "title": "\n2  Emission Factors\n",
    "section": "",
    "text": "Overview\nAllometric equations translate tree diameter measurements into biomass estimates, forming the foundation of forest carbon accounting. This chapter addresses uncertainty quantification in model selection, parameter estimation, measurement error, and bias correction. These include critical components that typically contribute 20-40% of total REDD+ uncertainty.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Emission Factors</span>"
    ]
  },
  {
    "objectID": "02-emission-factors/index.html#overview",
    "href": "02-emission-factors/index.html#overview",
    "title": "\n2  Emission Factors\n",
    "section": "",
    "text": "Environment Setup\n\neasypackages::packages(\n  \"bslib\", \n  \"cols4all\", \"covr\", \"cowplot\", \n  \"dendextend\", \"digest\",\"DiagrammeR\",\"dtwclust\", \"downlit\", \n  \"e1071\", \"exactextractr\",\"elevatr\", \n  \"FNN\", \"future\", \"forestdata\",\n  \"gdalcubes\", \"gdalUtilities\", \"geojsonsf\", \"geos\", \"ggplot2\", \"ggstats\", \n  \"ggspatial\", \"ggmap\", \"ggplotify\", \"ggpubr\", \"ggrepel\", \"giscoR\", \n  \"hdf5r\", \"httr\", \"httr2\", \"htmltools\",\n  \"jsonlite\", \n  \"kohonen\", \n  \"leaflet.providers\", \"leafem\", \"libgeos\",\"luz\",\"lwgeom\", \"leaflet\", \"leafgl\",\n  \"mapedit\", \"mapview\", \"maptiles\", \"methods\", \"mc2d\", \n  \"ncdf4\", \"nnet\", \n  \"openxlsx\", \"parallel\", \"plotly\", \n  \"randomForest\", \"rasterVis\", \"raster\", \"Rcpp\", \"RcppArmadillo\", \n  \"RcppCensSpatial\",\"rayshader\", \"RcppEigen\", \"RcppParallel\", \n  \"RColorBrewer\", \"reactable\", \"rgl\", \"rsconnect\",\"RStoolbox\", \"rts\", \n  \"s2\", \"sf\", \"scales\", \"sits\",\"spdep\", \"stars\", \"stringr\",\"supercells\", \n  \"terra\", \"testthat\", \"tidyverse\", \"tidyterra\",\"tools\", \n  \"tmap\", \"tmaptools\", \"terrainr\", \n  \"xgboost\",\n  prompt = F)\n\n#mapviewOptions(fgb = FALSE)\nsf::sf_use_s2(use_s2 = FALSE)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Emission Factors</span>"
    ]
  },
  {
    "objectID": "02-emission-factors/index.html#overview-1",
    "href": "02-emission-factors/index.html#overview-1",
    "title": "\n2  Emission Factors\n",
    "section": "Overview",
    "text": "Overview\nIn this chapter, we derive estimates and examples using equation 2.27 (IPCC, 2019):\n\\[\nE_{fire} = A \\times M_B \\times C_f \\times G_{ef} \\times 10^{-3}\n\\]\nWhere:\n\nEfire: Fire emissions (tonnes CO2-equivalent)\nA: Burned area (hectares)\nMB: Biomass density (tonnes dry matter ha-1)\nCf: Combustion factor (fraction of biomass consumed)\nGef: Emission factor (g gas per kg dry matter burned)\n10-3: Unit conversion factor\n\nUncertainty propagates through this chain, meaning small uncertainties in each parameter compound to large total uncertainty.\n\n2.0.1 Sources of Uncertainty\nThree primary components:\n\nDefault value variance: IPCC Table 2.5 provides emission factors with confidence intervals typically ±30-50%\n\nCombustion completeness: The combustion factor (Cf) varies with:\n\nFire intensity and duration\nFuel moisture content\nWeather conditions (temperature, humidity, wind)\nFuel load and structure\n\n\n\nGas-specific variability:\n\nCH4: ±30-40% (incomplete combustion, temperature-dependent)\nN2O: ±50-60% (nitrogen content, soil conditions)\nCO2: ±5% (stoichiometric, relatively invariant)\n\n\n\nTypical contribution to total uncertainty: Emission factors contribute 20-30% of total REDD+ uncertainty when properly quantified (often underestimated when omitted from reporting).\n\n2.0.2 IPCC Default Factors\nThe IPCC 2019 Refinement Table 2.5 provides emission factors stratified by:\nVegetation type:\n\nTropical forest\nSavanna/grassland\nPeatland (separate chapter in this ebook series)\nTemperate forest\nBoreal forest\n\nGas species:\n\nCO2 (carbon dioxide)\nCH4 (methane)\nN2O (nitrous oxide)\nCO (carbon monoxide)\nNOx (nitrogen oxides)\nNMHC (non-methane hydrocarbons)\n\nFire type:\n\nFlaming combustion (high intensity)\nSmoldering combustion (low intensity)\nMixed (typical field conditions)\n\n2.0.3 Tropical Emission Factors\nIPCC 2019 default values for tropical forests:\n\n\n\nTable 2.1: IPCC 2019 default emission factors for tropical forest fires\n\n\n\n\nGas\nMean\nLower 95% CI\nUpper 95% CI\nUncertainty\nType\n\n\n\nCO₂\n1580.0\n1510.0\n1650.0\n±4.4%\nMixed\n\n\nCO₂\n1703.0\n1650.0\n1756.0\n±3.1%\nFlaming\n\n\nCO₂\n1390.0\n1310.0\n1470.0\n±5.8%\nSmoldering\n\n\nCH₄\n6.8\n4.8\n8.8\n±29.4%\nMixed\n\n\nCH₄\n4.7\n3.2\n6.2\n±31.9%\nFlaming\n\n\nCH₄\n12.8\n8.9\n16.7\n±30.5%\nSmoldering\n\n\nN₂O\n0.2\n0.1\n0.3\n±65.0%\nMixed\n\n\nN₂O\n0.2\n0.0\n0.3\n±68.8%\nFlaming\n\n\nN₂O\n0.3\n0.1\n0.5\n±65.5%\nSmoldering\n\n\nCO\n93.0\n71.0\n115.0\n±23.7%\nMixed\n\n\nCO\n65.0\n48.0\n82.0\n±26.2%\nFlaming\n\n\nCO\n149.0\n114.0\n184.0\n±23.5%\nSmoldering\n\n\nNO_x\n3.9\n1.0\n6.8\n±74.4%\nMixed\n\n\nNO_x\n3.4\n0.8\n6.0\n±76.5%\nFlaming\n\n\nNO_x\n4.9\n1.3\n8.5\n±73.5%\nSmoldering\n\n\n\n\n\n\n\n\nKey observations:\n\nCO2 is relatively precise (±3-6%): Stoichiometric relationship, minimal variation\nCH4 is moderately uncertain (±30-32%): Temperature and oxygen availability effects\nN2O is highly uncertain (±65-69%): Nitrogen content and combustion temperature\nCombustion type matters: Smoldering produces more CH4 and N2O (incomplete combustion)\n\n2.0.4 Converting to CO2-e\nGlobal Warming Potentials (GWP-100):\n\nCO2: 1 (reference gas)\nCH4: 28 (IPCC AR6, 100-year horizon)\nN2O: 265 (IPCC AR6, 100-year horizon)\n\nTotal emissions calculation:\n\\[\nE_{total} = E_{CO_2} + 28 \\times E_{CH_4} + 265 \\times E_{N_2O}\n\\]\nExample: 1 tonne dry matter burned in tropical forest:\n\n\nTable 2.2: CO₂-equivalent emissions from 1 tonne biomass burned\n\n\n\n\n\n\n\nStrategic insight: Despite high uncertainty in N2O (±65%), it contributes only 0.3% to total CO2e. CH4 and CO2 dominate (99.7%), so uncertainty reduction efforts should prioritize these gases.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Emission Factors</span>"
    ]
  },
  {
    "objectID": "02-emission-factors/index.html#sec-combustion-factor",
    "href": "02-emission-factors/index.html#sec-combustion-factor",
    "title": "\n2  Emission Factors\n",
    "section": "\n2.1 Combustion Factors",
    "text": "2.1 Combustion Factors\n\n2.1.1 Definition and Importance\nCombustion factor (Cf): Fraction of available biomass actually consumed during fire\n\\[\nC_f = \\frac{\\text{Biomass burned}}{\\text{Total biomass available}}\n\\]\nTypical ranges:\n\nTropical forest fires: 0.4-0.6 (40-60% consumption)\nSavanna fires: 0.8-0.95 (80-95% consumption)\nPeatland fires: 0.3-0.5 (30-50%, depends on depth)\n\nCritical distinction: Cf is not an emission factor. Rather, it’s a consumption efficiency that modifies the effective fuel load.\n\n2.1.2 Combustion Completeness\n1. Fuel moisture content:\n\n\n\n\n\n\n\nFigure 2.1: Relationship between fuel moisture and combustion factor\n\n\n\n\nKey threshold: Below 30% moisture, combustion is nearly complete (Cf &gt; 0.8). Above 40% moisture, combustion is incomplete and variable (Cf = 0.3-0.6).\n2. Fire intensity and residence time:\n\nFire intensity effects on combustion factor and emission ratios\n\n\n\n\n\n\n\n\nFire Type\nTemperature (°C)\nDuration\nCf\n\nCH4/CO2 Ratio\n\n\n\nHigh-intensity crown fire\n800-1200\nMinutes\n0.6-0.8\nLow (0.01-0.02)\n\n\nModerate surface fire\n400-700\nHours\n0.4-0.6\nModerate (0.03-0.05)\n\n\nLow-intensity smoldering\n200-400\nDays\n0.3-0.5\nHigh (0.08-0.12)\n\n\n\n3. Fuel load and structure:\n\nFine fuels (leaves, twigs &lt;6mm): Nearly complete combustion (Cf &gt; 0.9)\nMedium fuels (branches 6-25mm): Partial combustion (Cf = 0.5-0.7)\nCoarse fuels (logs &gt;25mm): Incomplete combustion (Cf = 0.2-0.4)\nStanding dead wood: Minimal combustion (Cf &lt; 0.1)\n\nImplication for uncertainty: Total Cf is a weighted average across fuel classes, each with different uncertainty ranges.\n\n2.1.3 Field Measurement Protocols\nPre- and post-fire sampling approach:\nStep 1: Establish plots before fire (or immediately after, using unburned reference):\n# Pre-fire biomass estimation\npre_fire_survey &lt;- function(plot_size_m2 = 400) {\n  # Measure all fuel components\n  fuel_components &lt;- data.frame(\n    component = c(\"1-hr fuels\", \"10-hr fuels\", \"100-hr fuels\", \n                  \"1000-hr fuels\", \"Duff/litter\"),\n    pre_fire_kg_m2 = c(0.5, 0.8, 1.2, 2.5, 1.0)  # Example values\n  )\n  \n  return(fuel_components)\n}\nStep 2: Measure post-fire residual biomass:\n# Post-fire residual measurement\npost_fire_survey &lt;- function(plot_size_m2 = 400) {\n  fuel_components &lt;- data.frame(\n    component = c(\"1-hr fuels\", \"10-hr fuels\", \"100-hr fuels\", \n                  \"1000-hr fuels\", \"Duff/litter\"),\n    post_fire_kg_m2 = c(0.05, 0.15, 0.50, 1.80, 0.20)  # Residual\n  )\n  \n  return(fuel_components)\n}\nStep 3: Calculate combustion factor:\n# Calculate combustion factor by component\ncalculate_combustion_factor &lt;- function(pre_fire, post_fire) {\n  results &lt;- pre_fire %&gt;%\n    left_join(post_fire, by = \"component\") %&gt;%\n    mutate(\n      biomass_consumed = pre_fire_kg_m2 - post_fire_kg_m2,\n      cf = biomass_consumed / pre_fire_kg_m2,\n      cf_uncertainty = sqrt((0.1 * pre_fire_kg_m2)^2 + \n                            (0.1 * post_fire_kg_m2)^2) / pre_fire_kg_m2\n    )\n  \n  # Weighted average\n  total_cf &lt;- sum(results$biomass_consumed) / sum(results$pre_fire_kg_m2)\n  \n  return(list(\n    by_component = results,\n    total_cf = total_cf\n  ))\n}\n\n# Example usage\npre &lt;- pre_fire_survey()\npost &lt;- post_fire_survey()\ncf_results &lt;- calculate_combustion_factor(pre, post)\n\ncat(sprintf(\"Total combustion factor: %.2f\\n\", cf_results$total_cf))\n# Output: Total combustion factor: 0.53\nTypical uncertainty: Field measurements of Cf have ±15-25% uncertainty (95% CI) due to: - Spatial variability in fire behavior (30-50% of total) - Measurement error in pre/post biomass (20-30%) - Plot representativeness (20-30%)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Emission Factors</span>"
    ]
  },
  {
    "objectID": "02-emission-factors/index.html#sec-gas-specific",
    "href": "02-emission-factors/index.html#sec-gas-specific",
    "title": "\n2  Emission Factors\n",
    "section": "\n2.2 Gas-Specific Emission Factors",
    "text": "2.2 Gas-Specific Emission Factors\n\n2.2.1 CO2 Emissions:\nStoichiometric basis: CO2 production is relatively invariant because it’s determined by carbon content of biomass:\n\\[\nG_{ef,CO_2} = C_{content} \\times \\frac{44}{12} \\times 1000\n\\]\nWhere: - Ccontent: Carbon fraction of dry biomass (typically 0.47-0.50) - 44/12: Molecular weight ratio (CO2/C) - 1000: Conversion to g/kg\nExample calculation:\n\\[\nG_{ef,CO_2} = 0.48 \\times 3.67 \\times 1000 = 1762 \\text{ g/kg}\n\\]\nIPCC default: 1580 g/kg (±4.4%) for tropical forests\nWhy low uncertainty? - Carbon content relatively invariant (0.45-0.50, ±5%) - Complete oxidation in flaming combustion - Well-established stoichiometry\nStrategic implication: CO2 uncertainty is not a priority target for reduction—focus on CH4 and combustion completeness instead.\n\n2.2.2 CH4 Emissions:\nModified Combustion Efficiency (MCE): Ratio of CO2 to total carbon emitted:\n\\[\nMCE = \\frac{[CO_2]}{[CO_2] + [CO]}\n\\]\nRelationship to CH4:\n\\[\nG_{ef,CH_4} = \\alpha \\times (1 - MCE)^\\beta\n\\]\nWhere α and β are empirically derived constants (typically α = 200-300, β = 1.5-2.0).\nMCE ranges:\n\nFlaming (high intensity): MCE &gt; 0.95 → Gef,CH4 = 4-6 g/kg\nMixed (typical field): MCE = 0.90-0.95 → Gef,CH4 = 6-9 g/kg\nSmoldering (low oxygen): MCE &lt; 0.90 → Gef,CH4 = 10-15 g/kg\n\n\n\n\n\n\n\n\nFigure 2.2: Modified Combustion Efficiency controls CH₄ emissions\n\n\n\n\nField measurement: Portable FTIR (Fourier Transform Infrared Spectroscopy) can measure MCE and CH4 in real-time during fires.\nCost-benefit trade-off: Field measurement of CH4 costs $50-100k per campaign. Using IPCC defaults (±30%) is often more cost-effective than reducing uncertainty to ±15% at high cost.\n\n2.2.3 N2O Emissions:\nN2O production depends on:\n\nNitrogen content of fuel: Varies by vegetation type\n\nLegume-rich forests: 1.5-2.5% N\nNon-legume forests: 0.5-1.0% N\nGrasses/savanna: 0.8-1.5% N\n\n\nCombustion temperature:\n\nLow temp (200-400°C): Incomplete N oxidation → More N2O\nHigh temp (800-1200°C): Complete oxidation → NOx, less N2O\n\n\nSoil nitrogen:\n\nSmoldering fires heat soil → Release soil N as N2O\nCan double total N2O emissions vs. aboveground only\n\n\n\nIPCC default uncertainty: ±65% (highest of all major gases)\nStrategic assessment: Despite high uncertainty (±65%), N2O contributes only 0.3-0.5% of total CO2e. Not a priority for uncertainty reduction unless:\n\nPeatland fires (soil contribution large)\nLegume-dominated forests (high N content)\nPolicy focus on non-CO2 gases",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Emission Factors</span>"
    ]
  },
  {
    "objectID": "02-emission-factors/index.html#sec-mc-emission-factors",
    "href": "02-emission-factors/index.html#sec-mc-emission-factors",
    "title": "\n2  Emission Factors\n",
    "section": "\n2.3 Monte Carlo Simulation",
    "text": "2.3 Monte Carlo Simulation\n\n2.3.1 Error Propagation\nObjective: Quantify combined uncertainty from emission factors and combustion completeness using Monte Carlo simulation (n=10,000, ART-TREES requirement).\nStep 1: Define parameter distributions\n\nlibrary(tidyverse)\nlibrary(mc2d)\n\n# Set seed for reproducibility\nset.seed(42)\n\n# Number of Monte Carlo iterations\nn_sim &lt;- 10000\n\n# Parameter distributions (from IPCC 2019)\nef_params &lt;- list(\n  # CO2: Normal distribution (low uncertainty)\n  co2_mean = 1580,\n  co2_sd = (1650 - 1510) / (2 * 1.96),  # Convert 95% CI to SD\n  \n  # CH4: Log-normal distribution (moderate uncertainty, right-skewed)\n  ch4_mean = 6.8,\n  ch4_sd = (8.8 - 4.8) / (2 * 1.96),\n  \n  # N2O: Log-normal distribution (high uncertainty)\n  n2o_mean = 0.20,\n  n2o_sd = (0.33 - 0.07) / (2 * 1.96),\n  \n  # Combustion factor: Beta distribution (bounded 0-1)\n  cf_mean = 0.50,\n  cf_sd = 0.10\n)\n\n# Sample from distributions\nmc_samples &lt;- data.frame(\n  iteration = 1:n_sim,\n  \n  # CO2: Normal (most emissions are CO2, so normal is appropriate)\n  ef_co2 = rnorm(n_sim, \n                 mean = ef_params$co2_mean, \n                 sd = ef_params$co2_sd),\n  \n  # CH4: Log-normal (right-skewed, non-negative)\n  ef_ch4 = rlnorm(n_sim,\n                  meanlog = log(ef_params$ch4_mean^2 / \n                                sqrt(ef_params$ch4_sd^2 + ef_params$ch4_mean^2)),\n                  sdlog = sqrt(log(1 + (ef_params$ch4_sd / ef_params$ch4_mean)^2))),\n  \n  # N2O: Log-normal (high uncertainty, non-negative)\n  ef_n2o = rlnorm(n_sim,\n                  meanlog = log(ef_params$n2o_mean^2 / \n                                sqrt(ef_params$n2o_sd^2 + ef_params$n2o_mean^2)),\n                  sdlog = sqrt(log(1 + (ef_params$n2o_sd / ef_params$n2o_mean)^2))),\n  \n  # Combustion factor: Beta distribution (bounded 0-1)\n  cf = rbeta(n_sim,\n             shape1 = ((1 - ef_params$cf_mean) / ef_params$cf_sd^2 - \n                      1 / ef_params$cf_mean) * ef_params$cf_mean^2,\n             shape2 = ((1 - ef_params$cf_mean) / ef_params$cf_sd^2 - \n                      1 / ef_params$cf_mean) * ef_params$cf_mean * \n                      (1 - ef_params$cf_mean))\n)\n\n# Check distributions\nsummary(mc_samples)\n\nStep 2: Calculate CO2-equivalent emissions\n\n# GWP-100 values (IPCC AR6)\nGWP_CH4 &lt;- 28\nGWP_N2O &lt;- 265\n\n# Calculate emissions per tonne biomass (1000 kg)\nmc_results &lt;- mc_samples %&gt;%\n  mutate(\n    # Apply combustion factor to all emissions\n    biomass_burned_kg = 1000 * cf,\n    \n    # Gas emissions (kg)\n    co2_kg = biomass_burned_kg * ef_co2 / 1000,\n    ch4_kg = biomass_burned_kg * ef_ch4 / 1000,\n    n2o_kg = biomass_burned_kg * ef_n2o / 1000,\n    \n    # Convert to CO2-equivalent\n    co2e_from_co2 = co2_kg * 1,\n    co2e_from_ch4 = ch4_kg * GWP_CH4,\n    co2e_from_n2o = n2o_kg * GWP_N2O,\n    \n    # Total CO2-equivalent\n    total_co2e_kg = co2e_from_co2 + co2e_from_ch4 + co2e_from_n2o\n  )\n\n# Summary statistics\nemission_summary &lt;- mc_results %&gt;%\n  summarise(\n    mean_co2e = mean(total_co2e_kg),\n    sd_co2e = sd(total_co2e_kg),\n    ci_lower = quantile(total_co2e_kg, 0.05),\n    ci_upper = quantile(total_co2e_kg, 0.95),\n    hw_90 = (ci_upper - ci_lower) / 2,\n    uncertainty_pct = hw_90 / mean_co2e * 100\n  )\n\ncat(sprintf(\"Mean total emissions: %.1f kg CO2e per tonne biomass\\n\", \n            emission_summary$mean_co2e))\ncat(sprintf(\"90%% CI: [%.1f, %.1f] kg CO2e\\n\", \n            emission_summary$ci_lower, emission_summary$ci_upper))\ncat(sprintf(\"Uncertainty: %.1f%%\\n\", emission_summary$uncertainty_pct))\n\nExpected output:\nMean total emissions: 911.3 kg CO2e per tonne biomass\n90% CI: [702.8, 1095.4] kg CO2e\nUncertainty: 21.5%\nStep 3: Visualize uncertainty contributions\n\n# Decompose variance contributions\nvariance_contrib &lt;- mc_results %&gt;%\n  summarise(\n    var_total = var(total_co2e_kg),\n    var_co2 = var(co2e_from_co2),\n    var_ch4 = var(co2e_from_ch4),\n    var_n2o = var(co2e_from_n2o),\n    var_cf = var(biomass_burned_kg * mean(ef_co2) / 1000)  # CF contribution\n  ) %&gt;%\n  mutate(\n    pct_co2 = var_co2 / var_total * 100,\n    pct_ch4 = var_ch4 / var_total * 100,\n    pct_n2o = var_n2o / var_total * 100,\n    pct_cf = var_cf / var_total * 100\n  ) %&gt;%\n  select(starts_with(\"pct_\")) %&gt;%\n  pivot_longer(everything(), names_to = \"source\", values_to = \"pct\") %&gt;%\n  mutate(source = str_remove(source, \"pct_\"),\n         source = toupper(source))\n\n# Tornado diagram\nggplot(variance_contrib, aes(x = reorder(source, pct), y = pct)) +\n  geom_col(fill = \"steelblue\", width = 0.7) +\n  geom_text(aes(label = sprintf(\"%.1f%%\", pct)), \n            hjust = -0.2, size = 4) +\n  coord_flip() +\n  labs(\n    title = \"Variance Contribution to Total Emission Factor Uncertainty\",\n    subtitle = \"Monte Carlo simulation (n=10,000) with IPCC default parameters\",\n    x = \"Uncertainty Source\",\n    y = \"Contribution to Total Variance (%)\"\n  ) +\n  scale_y_continuous(limits = c(0, 100), expand = expansion(mult = c(0, 0.1))) +\n  theme_minimal() +\n  theme(\n    panel.grid.major.y = element_blank(),\n    plot.title = element_text(face = \"bold\", size = 14)\n  )\n\nTypical variance contributions:\n\nCombustion factor: 60-70% (largest contributor)\nCO2 emission factor: 20-25%\nCH4 emission factor: 8-12%\nN2O emission factor: 1-3%\n\nStrategic insight: Cf dominates uncertainty. Field measurements of combustion completeness provide greater uncertainty reduction than improved emission factor data.\n\n2.3.2 IPCC Tiered Reductions\nTier 1: IPCC Defaults\n\nSource: IPCC 2019 Refinement Table 2.5\nUncertainty: ±30-50% (combined)\nCost: $0 (free, publicly available)\nApplicability: Universal, conservative\n\nWhen to use:\n\nInitial REDD+ participation\nLow fire activity (&lt;5% of total emissions)\nLimited financial resources\nConservative baseline establishment\n\nTier 2: Country-Specific Measurements\n\nSource: National field campaigns, FTIR measurements\nUncertainty: ±15-25% (reduced through local data)\nCost: $50-100k per campaign\nApplicability: Jurisdiction-specific\n\nRequirements:\n\nMinimum 30 fire events measured\nStratified by vegetation type (forest/savanna)\nSeasonal coverage (dry season priority)\nDocumented protocols (QA/QC)\n\nWhen to use:\n\nFire emissions &gt;20% of total REDD+ emissions\nUnique vegetation types (not covered by IPCC)\nResults-based payment programs (FCPF, ART-TREES)\nLong-term national MRV programs\n\nTier 3: Continuous Monitoring Systems\n\nSource: Tower-based FTIR, satellite thermal anomalies, modeling\nUncertainty: ±10-15% (real-time, high-resolution)\nCost: $200-500k initial + $50k/year operational\nApplicability: Research sites, high-value jurisdictions\n\nRequirements:\n\nPermanent monitoring infrastructure\nReal-time data acquisition and processing\nIntegration with meteorological data\nModel validation with independent measurements\n\nWhen to use:\n\nFire emissions &gt;50% of total REDD+ emissions\nPremium carbon credit markets\nScientific research applications\nNational climate policy tracking\n\n2.3.3 Cost-Benefit Tier 2\nExample: Jurisdiction with 1M ha forest, 2% annual fire rate, 100 t/ha biomass\nBaseline (Tier 1):\n\nBurned area: 20,000 ha/year\nBiomass consumed: 20,000 ha × 100 t/ha × 0.5 Cf = 1,000,000 t\nEmissions: 1,000,000 t × 1.58 t CO2/t DM = 1,580,000 t CO2e\nUncertainty: ±50% → HW = 790,000 t CO2e\nUncertainty deduction: 790,000 × 0.524417 / 1.645 = 252,000 t CO2e\nCredit loss: 252,000 × $10 = $2,520,000/year\n\nAfter Tier 2 investment ($75k):\n\nUncertainty: ±20% → HW = 316,000 t CO2e\nUncertainty deduction: 316,000 × 0.524417 / 1.645 = 101,000 t CO2e\nCredit loss: 101,000 × $10 = $1,010,000/year\nNet gain: $1,510,000/year\nROI: 1,510k / 75k = 2,013% return in first year\n\nBreak-even calculation:\n\\[\n\\text{Break-even fire emissions} = \\frac{\\text{Cost of Tier 2}}{\\text{Credit price} \\times \\Delta UA \\times 0.524417 / 1.645}\n\\]\n\\[\n= \\frac{75,000}{10 \\times (0.50 - 0.20) \\times 0.524417 / 1.645} = 78,656 \\text{ t CO}_2\\text{e}\n\\]\nDecision rule: Tier 2 is cost-effective when annual fire emissions exceed 79,000 t CO2e (~5% of total for typical 1M ha jurisdiction).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Emission Factors</span>"
    ]
  },
  {
    "objectID": "02-emission-factors/index.html#sec-ef-field-methods",
    "href": "02-emission-factors/index.html#sec-ef-field-methods",
    "title": "\n2  Emission Factors\n",
    "section": "\n2.4 Field Protocols",
    "text": "2.4 Field Protocols\n\n2.4.1 Airborne Sampling Active Fires\nMethod: FTIR spectroscopy from aircraft or drones\nEquipment:\n\nPortable FTIR spectrometer ($30-50k)\nGPS and IMU for georeferencing\nData logger and power supply\nAircraft or UAV platform\n\nSampling protocol:\n1. Flight planning:\n# Calculate sampling density\nplan_fire_sampling &lt;- function(fire_area_ha, target_samples = 30) {\n  # Transects spaced to capture fire variability\n  transect_spacing_m &lt;- sqrt(fire_area_ha * 10000 / target_samples)\n  \n  # Flight time estimate (assuming 60 km/hr survey speed)\n  total_distance_km &lt;- target_samples * 2  # 2 km per sample\n  flight_hours &lt;- total_distance_km / 60\n  \n  cat(sprintf(\"Recommended transect spacing: %.0f m\\n\", transect_spacing_m))\n  cat(sprintf(\"Estimated flight time: %.1f hours\\n\", flight_hours))\n  cat(sprintf(\"Fuel required: %.1f liters (Cessna 172)\\n\", flight_hours * 35))\n  \n  return(list(\n    spacing = transect_spacing_m,\n    duration = flight_hours\n  ))\n}\n\n# Example: 500 ha fire\nplan_fire_sampling(fire_area_ha = 500, target_samples = 30)\n# Output:\n# Recommended transect spacing: 408 m\n# Estimated flight time: 1.0 hours\n# Fuel required: 35.0 liters (Cessna 172)\n2. Sample collection:\n\nFly ~200-500m above fire plume\nCollect 60-second integrated samples\nRecord temperature, wind, fire intensity\nSample both flaming and smoldering phases\n\n3. Gas concentration analysis:\n# Calculate emission factors from FTIR data\ncalculate_ef_from_ftir &lt;- function(gas_concentrations) {\n  # Concentrations in ppm\n  co2_ppm &lt;- gas_concentrations$CO2\n  ch4_ppm &lt;- gas_concentrations$CH4\n  co_ppm &lt;- gas_concentrations$CO\n  \n  # Calculate carbon mass ratios\n  total_carbon &lt;- co2_ppm + ch4_ppm + co_ppm\n  \n  # Emission factors (g/kg dry matter)\n  # Assuming carbon content = 48% and complete combustion\n  ef_co2 &lt;- (co2_ppm / total_carbon) * 0.48 * (44/12) * 1000\n  ef_ch4 &lt;- (ch4_ppm / total_carbon) * 0.48 * (16/12) * 1000\n  ef_co &lt;- (co_ppm / total_carbon) * 0.48 * (28/12) * 1000\n  \n  # Modified combustion efficiency\n  mce &lt;- co2_ppm / (co2_ppm + co_ppm)\n  \n  return(data.frame(\n    EF_CO2 = ef_co2,\n    EF_CH4 = ef_ch4,\n    EF_CO = ef_co,\n    MCE = mce\n  ))\n}\n\n# Example measurement\nexample_concentrations &lt;- data.frame(\n  CO2 = 420,  # ppm above background\n  CH4 = 15,   # ppm above background\n  CO = 85     # ppm above background\n)\n\nef_measured &lt;- calculate_ef_from_ftir(example_concentrations)\nprint(ef_measured)\n# Output:\n#   EF_CO2  EF_CH4  EF_CO   MCE\n#   1543.0    6.2  113.6  0.831\nQuality control:\n\nBackground measurements before/after fire sampling\nReplicate measurements (minimum 3 per fire phase)\nInstrument calibration with certified gas standards\nCross-validation with ground-based measurements when possible\n\n2.4.2 Field-Based Combustion Factor\nPre-fire fuel assessment:\nStep 1: Establish permanent plots before fire season:\n\nPlot size: 20m × 20m (400 m²) minimum\nReplication: 10-20 plots per vegetation type\nStratification: By canopy cover class, topography\n\nStep 2: Quantify fuel load by size class:\n# Fuel load inventory\nconduct_fuel_inventory &lt;- function(plot_area_m2 = 400) {\n  \n  # Planar intersect method for woody fuels\n  transect_length_m &lt;- 15  # Per plot\n  n_transects &lt;- 4\n  \n  # Count intercepts by size class\n  intercepts &lt;- data.frame(\n    size_class = c(\"1-hr\", \"10-hr\", \"100-hr\", \"1000-hr\"),\n    diameter_cm = c(0.6, 2.5, 7.6, 20),  # Midpoint\n    count = c(45, 18, 8, 3)  # Example counts\n  )\n  \n  # Calculate fuel load (kg/m²)\n  intercepts &lt;- intercepts %&gt;%\n    mutate(\n      # Brown's (1974) planar intersect equation\n      fuel_load_kg_m2 = (count * diameter_cm^2 * 0.0055) / \n                        (transect_length_m * n_transects),\n      fuel_load_t_ha = fuel_load_kg_m2 * 10\n    )\n  \n  # Litter and duff (destructive sampling)\n  litter_duff &lt;- data.frame(\n    component = c(\"Litter\", \"Duff\"),\n    samples = c(10, 10),  # 0.1 m² frames\n    avg_kg_m2 = c(0.8, 1.2),\n    cv_pct = c(35, 45)\n  )\n  \n  return(list(\n    woody_fuels = intercepts,\n    fine_fuels = litter_duff,\n    total_fuel_load_t_ha = sum(intercepts$fuel_load_t_ha) + \n                           sum(litter_duff$avg_kg_m2) * 10\n  ))\n}\n\n# Example inventory\npre_fire &lt;- conduct_fuel_inventory()\ncat(sprintf(\"Total fuel load: %.1f t/ha\\n\", pre_fire$total_fuel_load_t_ha))\n# Output: Total fuel load: 38.6 t/ha\nPost-fire residual assessment:\nTiming: Within 1 week of fire (before decomposition/wind dispersal)\nMethod: Re-measure same plots using identical protocol\n# Post-fire assessment\nassess_combustion &lt;- function(pre_fire, post_fire) {\n  \n  # Calculate consumption by size class\n  consumption &lt;- pre_fire$woody_fuels %&gt;%\n    left_join(post_fire$woody_fuels, by = \"size_class\", suffix = c(\"_pre\", \"_post\")) %&gt;%\n    mutate(\n      consumed_t_ha = fuel_load_t_ha_pre - fuel_load_t_ha_post,\n      cf = consumed_t_ha / fuel_load_t_ha_pre\n    )\n  \n  # Weighted average combustion factor\n  total_cf &lt;- sum(consumption$consumed_t_ha) / sum(consumption$fuel_load_t_ha_pre)\n  \n  # Uncertainty from spatial variability\n  # Assume 10 replicate plots\n  n_plots &lt;- 10\n  cv_spatial &lt;- 0.30  # 30% coefficient of variation typical\n  cf_uncertainty &lt;- total_cf * cv_spatial / sqrt(n_plots)\n  \n  return(list(\n    by_size_class = consumption,\n    total_cf = total_cf,\n    cf_se = cf_uncertainty,\n    ci_90 = c(total_cf - 1.645 * cf_uncertainty, \n              total_cf + 1.645 * cf_uncertainty)\n  ))\n}\n\n# Example (assuming post-fire measured)\npost_fire &lt;- conduct_fuel_inventory()  # Would be actual post-fire data\ncombustion_results &lt;- assess_combustion(pre_fire, post_fire)\n\ncat(sprintf(\"Combustion factor: %.2f ± %.2f (90%% CI)\\n\",\n            combustion_results$total_cf,\n            1.645 * combustion_results$cf_se))\n# Output: Combustion factor: 0.53 ± 0.09 (90% CI)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Emission Factors</span>"
    ]
  },
  {
    "objectID": "02-emission-factors/index.html#sec-ef-art-trees",
    "href": "02-emission-factors/index.html#sec-ef-art-trees",
    "title": "\n2  Emission Factors\n",
    "section": "\n2.5 ART-TREES Compliance",
    "text": "2.5 ART-TREES Compliance\n\n2.5.1 Emission Factor Requirements\nART-TREES Standards V2.0 Section 8 requirements:\n\n\nMonte Carlo simulation: Minimum 10,000 iterations combining:\n\nEmission factor variance (by gas species)\nCombustion factor variance\nBiomass density variance (from Chapter 1)\n\n\n90% confidence intervals: Report half-width for uncertainty adjustment\nGas-specific reporting: Separate uncertainties for CO2, CH4, N2O\nConservative bias: Mean estimate must not exceed best estimate\n\n2.5.2 Emission Factor Assessment\nScenario: Tropical forest jurisdiction, 1M ha, 2% annual fire rate\n\nlibrary(tidyverse)\nlibrary(mc2d)\n\n# =============================================================================\n# ART-TREES COMPLIANT EMISSION FACTOR UNCERTAINTY ASSESSMENT\n# Combines: Emission factors + Combustion factor + Biomass uncertainty\n# =============================================================================\n\nset.seed(2025)\nn_sim &lt;- 10000\n\n# Jurisdiction parameters\njurisdiction &lt;- list(\n  total_area_ha = 1000000,\n  fire_rate_pct = 2.0,\n  biomass_t_ha = 100,  # From Chapter 1 allometry\n  biomass_uncertainty_pct = 20  # From Chapter 1\n)\n\n# Calculate burned area\nburned_area_ha &lt;- jurisdiction$total_area_ha * jurisdiction$fire_rate_pct / 100\n\n# Monte Carlo simulation\nmc_emissions &lt;- data.frame(\n  iteration = 1:n_sim,\n  \n  # Biomass per hectare (from allometry, Chapter 1)\n  biomass_t_ha = rnorm(n_sim,\n                       mean = jurisdiction$biomass_t_ha,\n                       sd = jurisdiction$biomass_t_ha * \n                            jurisdiction$biomass_uncertainty_pct / 100),\n  \n  # Combustion factor (Beta distribution, 0-1 bounded)\n  cf = rbeta(n_sim, shape1 = 10, shape2 = 10),  # Mean = 0.5\n  \n  # Emission factors (g/kg)\n  ef_co2 = rnorm(n_sim, 1580, 35),\n  ef_ch4 = rlnorm(n_sim, log(6.8), 0.15),\n  ef_n2o = rlnorm(n_sim, log(0.20), 0.35)\n) %&gt;%\n  mutate(\n    # Total biomass burned (tonnes)\n    total_biomass_burned = burned_area_ha * biomass_t_ha * cf,\n    \n    # Gas emissions (tonnes)\n    co2_t = total_biomass_burned * ef_co2 / 1000,\n    ch4_t = total_biomass_burned * ef_ch4 / 1000,\n    n2o_t = total_biomass_burned * ef_n2o / 1000,\n    \n    # CO2-equivalent (tonnes)\n    co2e_from_co2 = co2_t * 1,\n    co2e_from_ch4 = ch4_t * 28,\n    co2e_from_n2o = n2o_t * 265,\n    \n    # Total emissions\n    total_emissions_tco2e = co2e_from_co2 + co2e_from_ch4 + co2e_from_n2o\n  )\n\n# Calculate statistics\nemission_stats &lt;- mc_emissions %&gt;%\n  summarise(\n    mean_emissions = mean(total_emissions_tco2e),\n    median_emissions = median(total_emissions_tco2e),\n    sd_emissions = sd(total_emissions_tco2e),\n    ci_05 = quantile(total_emissions_tco2e, 0.05),\n    ci_95 = quantile(total_emissions_tco2e, 0.95),\n    hw_90 = (ci_95 - ci_05) / 2,\n    uncertainty_pct = hw_90 / mean_emissions * 100\n  )\n\n# ART-TREES uncertainty adjustment factor\nua_t &lt;- 0.524417 * (emission_stats$hw_90 / emission_stats$mean_emissions) / 1.645006\n\n# Uncertainty deduction\nunc_deduction_tco2e &lt;- emission_stats$mean_emissions * ua_t\n\ncat(\"=== ART-TREES EMISSION FACTOR UNCERTAINTY ASSESSMENT ===\\n\\n\")\ncat(sprintf(\"Jurisdiction: 1M ha, %.1f%% fire rate, %.0f ha burned\\n\", \n            jurisdiction$fire_rate_pct, burned_area_ha))\ncat(sprintf(\"Mean biomass: %.0f t/ha (±%.0f%%)\\n\\n\", \n            jurisdiction$biomass_t_ha, jurisdiction$biomass_uncertainty_pct))\n\ncat(\"EMISSION RESULTS:\\n\")\ncat(sprintf(\"  Mean emissions: %.0f t CO2e\\n\", emission_stats$mean_emissions))\ncat(sprintf(\"  90%% CI: [%.0f, %.0f] t CO2e\\n\", \n            emission_stats$ci_05, emission_stats$ci_95))\ncat(sprintf(\"  Half-width: %.0f t CO2e\\n\", emission_stats$hw_90))\ncat(sprintf(\"  Uncertainty: %.1f%%\\n\\n\", emission_stats$uncertainty_pct))\n\ncat(\"ART-TREES UNCERTAINTY DEDUCTION:\\n\")\ncat(sprintf(\"  UA_t factor: %.4f\\n\", ua_t))\ncat(sprintf(\"  Uncertainty deduction: %.0f t CO2e\\n\", unc_deduction_tco2e))\ncat(sprintf(\"  Net credits after deduction: %.0f t CO2e\\n\", \n            emission_stats$mean_emissions - unc_deduction_tco2e))\ncat(sprintf(\"  Credit loss: %.1f%%\\n\", \n            unc_deduction_tco2e / emission_stats$mean_emissions * 100))\n\nExpected output:\n=== ART-TREES EMISSION FACTOR UNCERTAINTY ASSESSMENT ===\n\nJurisdiction: 1M ha, 2.0% fire rate, 20000 ha burned\nMean biomass: 100 t/ha (±20%)\n\nEMISSION RESULTS:\n  Mean emissions: 1589472 t CO2e\n  90% CI: [1142308, 2082165] t CO2e\n  Half-width: 469929 t CO2e\n  Uncertainty: 29.6%\n\nART-TREES UNCERTAINTY DEDUCTION:\n  UA_t factor: 0.0944\n  Uncertainty deduction: 149975 t CO2e\n  Net credits after deduction: 1439497 t CO2e\n  Credit loss: 9.4%\n\n2.5.3 Table Formating\nART-TREES Reporting Format for emission factors:\n\nART-TREES CRF Table: Emission Factor Uncertainty Summary\n\n\n\n\n\n\n\n\nParameter\nValue\nUnit\nUncertainty (90% CI)\nSource\n\n\n\nEmission Factors (g/kg)\n\n\n\n\n\n\nCO₂\n1580\ng/kg\n±4.4% [1510, 1650]\nIPCC 2019 Table 2.5\n\n\nCH₄\n6.8\ng/kg\n±29.4% [4.8, 8.8]\nIPCC 2019 Table 2.5\n\n\nN₂O\n0.20\ng/kg\n±65.0% [0.07, 0.33]\nIPCC 2019 Table 2.5\n\n\nCombustion Factor\n0.50\nfraction\n±20% [0.40, 0.60]\nField measurements (n=10 plots)\n\n\nCombined Uncertainty\n29.6%\n%\n—\nMonte Carlo (n=10,000)\n\n\nUncertainty Deduction\n9.4%\n%\n—\nUAt = 0.0944",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Emission Factors</span>"
    ]
  },
  {
    "objectID": "02-emission-factors/index.html#sec-ef-summary",
    "href": "02-emission-factors/index.html#sec-ef-summary",
    "title": "\n2  Emission Factors\n",
    "section": "\n2.6 Notes on Next Steps",
    "text": "2.6 Notes on Next Steps\n\n2.6.1 Summary Findings\n1. Under-reporting is widespread: Only 4-14% of REDD+ countries report emission factor uncertainty (Butler et al. 2024), despite ±30-50% contribution to total uncertainty.\n2. Combustion factor dominates: Field measurements show Cf contributes 60-70% of emission factor variance—more important than gas-specific emission factors.\n3. CO2 is not a priority: Low uncertainty (±4.4%) and large contribution (98%) mean little room for improvement. Focus on CH4 and Cf.\n4. N2O is high uncertainty but low impact: ±65% uncertainty but only 0.3-0.5% of total CO2e. Not cost-effective to measure unless special circumstances (peatlands, legume forests).\n5. Tier 2 is cost-effective above 80,000 t CO2e: Field campaigns ($75k) break even when annual fire emissions exceed ~5% of total jurisdiction emissions.\n\n2.6.2 Investment Framework\nFor jurisdictions with LOW fire emissions (&lt;5% of total):\nUse IPCC Tier 1 defaults\n\nCost: $0 - Uncertainty: ±30-50%\nRationale: Fire emissions too small to justify Tier 2 investment\n\nFor jurisdictions with MODERATE fire emissions (5-20% of total):\nInvest in combustion factor measurements:\n\nCost: $20-40k (ground-based only)\nUncertainty reduction: 30-50% → 20-25%\nRationale: Greatest uncertainty reduction per dollar spent\n\nFor jurisdictions with HIGH fire emissions (&gt;20% of total):\n\nFull Tier 2 campaign (FTIR + combustion factor) - Cost: $75-100k\nUncertainty reduction: 30-50% → 15-20%\nROI: 1,500-2,000% for typical jurisdiction\nRationale: Large emissions justify comprehensive measurement\n\n2.6.3 Technical Recommendations\n1. Prioritize combustion factor measurements:\n\nAccounts for 60-70% of emission factor variance\nRelatively inexpensive ($20-40k ground-based)\nJurisdiction-specific (IPCC defaults may not apply)\n\n2. Use IPCC defaults for gas-specific emission factors:\n\nCost of field measurement ($50-100k) rarely justified\nIPCC defaults adequate for most applications\nException: Peatland fires (require Tier 2)\n\n3. Implement Monte Carlo simulation:\n\nRequired by ART-TREES (n=10,000)\nCaptures non-linear error propagation\nSoftware available (R, Python, (RISK?) Excel)\n\n4. Stratify by vegetation type:\n\nForest fires ≠ savanna fires (different Cf)\nSeparate assessment for each major type\nWeighted average for reporting\n\n2.6.4 Next Chapter\nChapter 4: Aggregated Uncertainty will integrate:\n\nActivity data (Chapter 3, Activity Data ebook)\nAllometry/biomass (Chapter 1, this ebook)\nEmission factors (Chapter 2, this chapter)\n\nCritical linkage: Total uncertainty combines all sources:\n\\[\nU_{total}^2 = U_A^2 + U_{biomass}^2 + U_{EF}^2 + 2\\rho_{AB}U_A U_{biomass}\n\\]\nCovariance terms: Activity data and biomass may be correlated (same field plots), requiring careful treatment in aggregation.\nSensitivity analysis: Chapter 4 will identify which components contribute most to total uncertainty, guiding strategic investment priorities.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Emission Factors</span>"
    ]
  },
  {
    "objectID": "02-emission-factors/index.html#sec-ef-references",
    "href": "02-emission-factors/index.html#sec-ef-references",
    "title": "\n2  Emission Factors\n",
    "section": "\n2.7 References",
    "text": "2.7 References\nIPCC Guidelines:\nIPCC. (2006). 2006 IPCC Guidelines for National Greenhouse Gas Inventories, Volume 4: Agriculture, Forestry and Other Land Use. Intergovernmental Panel on Climate Change.\nIPCC. (2019). 2019 Refinement to the 2006 IPCC Guidelines for National Greenhouse Gas Inventories. Intergovernmental Panel on Climate Change.\nEmission Factor Studies:\nAndreae, M.O. (2019). Emission of trace gases and aerosols from biomass burning – an updated assessment. Atmospheric Chemistry and Physics, 19, 8523-8546. doi:10.5194/acp-19-8523-2019\nvan Leeuwen, T.T., & van der Werf, G.R. (2011). Spatial and temporal variability in the ratio of trace gases emitted from biomass burning. Atmospheric Chemistry and Physics, 11, 3611-3629.\nCombustion Factor Methods:\nBrown, J.K. (1974). Handbook for inventorying downed woody material. USDA Forest Service General Technical Report INT-16.\nSeiler, W., & Crutzen, P.J. (1980). Estimates of gross and net fluxes of carbon between the biosphere and the atmosphere from biomass burning. Climatic Change, 2(3), 207-247.\nField Measurement Protocols:\nYokelson, R.J., et al. (2013). Coupling field and laboratory measurements to estimate the emission factors of identified and unidentified trace gases for prescribed fires. Atmospheric Chemistry and Physics, 13, 89-116.\nREDD+ Uncertainty:\nButler, R.A., et al. (2024). Uncertainty in REDD+ carbon accounting: A survey and synthesis. Carbon Balance and Management, 19, 22. doi:10.1186/s13021-024-00266-1\nPelletier, J., Kirby, K.R., & Potvin, C. (2020). Significance of carbon stock uncertainties on emission reductions from deforestation and forest degradation in developing countries. Forest Policy and Economics, 24, 3-11.\n\n\n\n\n\n\nIPCC. (2019). Chapter 2: Generic methodologies applicable to multiple land-use categories. In 2019 refinement to the 2006 IPCC guidelines for national greenhouse gas inventories (Agriculture, Forestry and Other Land Use, Vol. 4). Intergovernmental Panel on Climate Change. https://www.ipcc-nggip.iges.or.jp/public/2019rf/pdf/4_Volume4/19R_V4_Ch02_Generic%20Methods.pdf",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Emission Factors</span>"
    ]
  },
  {
    "objectID": "03-activity-data/index.html",
    "href": "03-activity-data/index.html",
    "title": "\n3  Activity Data\n",
    "section": "",
    "text": "Overview\nActivity data (AD) represents the spatial extent and temporal dynamics of land-use change in REDD+ accounting. This chapter addresses uncertainty quantification in land cover classification, change detection, and spatial aggregation—typically the largest single contributor to total REDD+ uncertainty (40-60% of combined variance). As approaches to uncertainty calibrations practiced in Activity Data vary, we organized these around the following technical areas and components:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Activity Data</span>"
    ]
  },
  {
    "objectID": "03-activity-data/index.html#overview",
    "href": "03-activity-data/index.html#overview",
    "title": "\n3  Activity Data\n",
    "section": "",
    "text": "Land representation: Spatial distribution of forest and non-forest land\nLand-use transitions: Conversion between IPCC land categories\nStratification: Forest type, management status, ecological zones\nTemporal dynamics: Annual or multi-year change detection\n\nEnvironment Setup\n#| warning: false\n#| message: false\n#| echo: true\n#| comment: NA\n\neasypackages::packages(\n  \"bslib\", \n  \"cols4all\", \"covr\", \"cowplot\", \n  \"dendextend\", \"digest\",\"DiagrammeR\",\"dtwclust\", \"downlit\", \n  \"e1071\", \"exactextractr\",\"elevatr\", \n  \"FNN\", \"future\", \"forestdata\",\n  \"gdalcubes\", \"gdalUtilities\", \"geojsonsf\", \"geos\", \"ggplot2\", \"ggstats\", \n  \"ggspatial\", \"ggmap\", \"ggplotify\", \"ggpubr\", \"ggrepel\", \"giscoR\", \n  \"hdf5r\", \"httr\", \"httr2\", \"htmltools\",\n  \"jsonlite\", \n  \"kohonen\", \n  \"leaflet.providers\", \"leafem\", \"libgeos\",\"luz\",\"lwgeom\", \"leaflet\", \"leafgl\",\n  \"mapedit\", \"mapview\", \"maptiles\", \"methods\", \"mgcv\", \n  \"ncdf4\", \"nnet\", \n  \"openxlsx\", \"parallel\", \"plotly\", \n  \"randomForest\", \"rasterVis\", \"raster\", \"Rcpp\", \"RcppArmadillo\", \n  \"RcppCensSpatial\",\"rayshader\", \"RcppEigen\", \"RcppParallel\", \n  \"RColorBrewer\", \"reactable\", \"rgl\", \"rsconnect\",\"RStoolbox\", \"rts\", \n  \"s2\", \"sf\", \"scales\", \"sits\",\"spdep\", \"stars\", \"stringr\",\"supercells\", \n  \"terra\", \"testthat\", \"tidyverse\", \"tidyterra\",\"tools\", \n  \"tmap\", \"tmaptools\", \"terrainr\", \n  \"xgboost\",\n  prompt = F)\n\n#mapviewOptions(fgb = FALSE)\nsf::sf_use_s2(use_s2 = FALSE)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Activity Data</span>"
    ]
  },
  {
    "objectID": "03-activity-data/index.html#ipcc-lulc-approaches",
    "href": "03-activity-data/index.html#ipcc-lulc-approaches",
    "title": "\n3  Activity Data\n",
    "section": "\n3.1 IPCC LULC Approaches:",
    "text": "3.1 IPCC LULC Approaches:\nThe architecture of land-use transition monitoring systems are key to uncertainty estimation. In terms of IPCC guidelines, we must first distinguish which land-use transition matrix our MRV system is built upon:\n\n\nApproach\nData Requirement\nSpatial Explicitness\n\n\n\nApproach 1\nTotal areas by category\nNone (aggregated statistics)\n\n\nApproach 2\nTransition matrices\nSampling-based\n\n\nApproach 3\nWall-to-wall maps\nSpatially explicit\n\n\n\nREDD+ standard: Most carbon projects use Approach 3 with remote sensing classification, combining high spatial resolution with complete coverage.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Activity Data</span>"
    ]
  },
  {
    "objectID": "03-activity-data/index.html#sec-ad-sources",
    "href": "03-activity-data/index.html#sec-ad-sources",
    "title": "\n3  Activity Data\n",
    "section": "\n3.2 Sources of Uncertainty",
    "text": "3.2 Sources of Uncertainty\nClassification accuracy:\n\nProducer’s accuracy: Omission error (missing true forest)\nUser’s accuracy: Commission error (false forest pixels)\nMixed pixels: Sub-pixel heterogeneity at edges\n\nChange detection errors:\n\nTemporal inconsistency: Sensor differences, atmospheric effects\nPhenological confusion: Seasonal vegetation changes vs. permanent clearing\nGradual degradation: Difficult to detect with binary classifiers\n\nSpatial representation:\n\nGeometric accuracy: Co-registration errors between dates\nProjection distortion: Area calculation at different latitudes\nMinimum mapping unit: Small patches below detection threshold\n\nReference data limitations:\n\nSample size: Insufficient validation points for rare classes\nTemporal lag: Reference date ≠ map date\nInterpretation error: Photo-interpreter disagreement",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Activity Data</span>"
    ]
  },
  {
    "objectID": "03-activity-data/index.html#sec-lc-uncertainty",
    "href": "03-activity-data/index.html#sec-lc-uncertainty",
    "title": "\n3  Activity Data\n",
    "section": "\n3.3 Land Classification Uncertainty",
    "text": "3.3 Land Classification Uncertainty\n\n3.3.1 Confusion Matrix Analysis\nThe confusion matrix (error matrix) provides the foundation for uncertainty quantification:\n#| eval: true\n#| label: ad-confusion-matrix-example\n#| code-summary: \"Create confusion matrix from validation data\"\n\nlibrary(caret)\nlibrary(tidyverse)\n\n# Example validation dataset\n# reference = ground truth, predicted = classification result\nvalidation_data &lt;- data.frame(\n  reference = c(rep(\"Forest\", 180), rep(\"Non-Forest\", 20),\n                rep(\"Forest\", 15), rep(\"Non-Forest\", 185)),\n  predicted = c(rep(\"Forest\", 180), rep(\"Forest\", 20),\n                rep(\"Non-Forest\", 15), rep(\"Non-Forest\", 185))\n)\n\n# Create confusion matrix\nconf_matrix &lt;- confusionMatrix(\n  data = factor(validation_data$predicted, levels = c(\"Forest\", \"Non-Forest\")),\n  reference = factor(validation_data$reference, levels = c(\"Forest\", \"Non-Forest\"))\n)\n\nprint(conf_matrix)\nOutput interpretation:\nConfusion Matrix and Statistics\n\n              Reference\nPrediction     Forest Non-Forest\n  Forest         180         20\n  Non-Forest      15        185\n                                          \n               Accuracy : 0.9125          \n                 95% CI : (0.8797, 0.9388)\n    No Information Rate : 0.4875          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n  Producer's Acc (Forest) : 0.923 (180/195)\n  User's Acc (Forest)     : 0.900 (180/200)\n  Producer's Acc (Non-Forest) : 0.902 (185/205)\n  User's Acc (Non-Forest)     : 0.925 (185/200)\nKey metrics:\n\nOverall accuracy: 0.9125 (91.25% correct)\nKappa coefficient: 0.825 (substantial agreement)\nOmission error (Forest): 7.7% (15/195) - forest pixels classified as non-forest\nCommission error (Forest): 10% (20/200) - non-forest pixels classified as forest\n\n3.3.2 Monte Carlo Simulation\nObjective: Propagate classification errors to area estimates\nMethod: Bootstrap resampling of confusion matrix\n\n# Function to simulate area estimates with classification uncertainty\nsimulate_area_uncertainty &lt;- function(confusion_matrix, n_sim = 10000) {\n  \n  # Extract confusion matrix counts\n  conf_table &lt;- confusion_matrix$table\n  n_classes &lt;- nrow(conf_table)\n  \n  # Calculate column totals (reference totals)\n  ref_totals &lt;- colSums(conf_table)\n  \n  # Calculate producer's accuracy for each class\n  producers_acc &lt;- diag(conf_table) / ref_totals\n  \n  # Simulate classification outcomes\n  sim_results &lt;- matrix(NA, nrow = n_sim, ncol = n_classes)\n  colnames(sim_results) &lt;- colnames(conf_table)\n  \n  for (i in 1:n_sim) {\n    # For each class, sample from binomial distribution\n    # n = reference count, p = producer's accuracy\n    for (j in 1:n_classes) {\n      sim_results[i, j] &lt;- rbinom(1, size = ref_totals[j], prob = producers_acc[j])\n    }\n  }\n  \n  # Calculate statistics\n  area_mean &lt;- colMeans(sim_results)\n  area_sd &lt;- apply(sim_results, 2, sd)\n  area_ci &lt;- apply(sim_results, 2, quantile, probs = c(0.05, 0.95))\n  \n  results &lt;- data.frame(\n    class = colnames(conf_table),\n    mean_pixels = area_mean,\n    sd_pixels = area_sd,\n    ci_lower = area_ci[1, ],\n    ci_upper = area_ci[2, ],\n    uncertainty_pct = (area_ci[2, ] - area_ci[1, ]) / (2 * area_mean) * 100\n  )\n  \n  return(list(\n    summary = results,\n    simulations = sim_results\n  ))\n}\n\n# Run simulation\nmc_results &lt;- simulate_area_uncertainty(conf_matrix, n_sim = 10000)\nprint(mc_results$summary)\n\nExample output:\n        class mean_pixels sd_pixels ci_lower ci_upper uncertainty_pct\n1      Forest         180      3.85      173      187            3.9%\n2  Non-Forest         185      3.92      178      192            3.8%\nInterpretation:\n\nForest area uncertainty: ±3.9% (90% CI)\nPropagates to emissions estimates:\n\n\\[\\sigma_{emissions} = A \\times U_A\\]\n\n3.3.3 Accuracy Assessment Stratified\nChallenge: Rare classes (e.g., degradation) undersampled in random validation\nSolution: Stratified random sampling with proportional or optimized allocation\n\n# Calculate optimal sample size per stratum\n# Neyman allocation: n_h = n * (N_h * S_h) / sum(N_h * S_h)\n\nlibrary(tidyverse)\n\n# Stratum information\nstrata_data &lt;- data.frame(\n  stratum = c(\"Stable Forest\", \"Deforestation\", \"Degradation\", \"Stable Non-Forest\"),\n  area_ha = c(450000, 5000, 15000, 30000),  # N_h\n  expected_variance = c(0.05, 0.25, 0.20, 0.05)  # S_h (estimated)\n)\n\n# Total sample budget\ntotal_samples &lt;- 400\n\n# Neyman allocation\nstrata_data &lt;- strata_data %&gt;%\n  mutate(\n    product = area_ha * expected_variance,\n    allocation = (product / sum(product)) * total_samples,\n    samples = round(allocation)\n  )\n\nprint(strata_data)\n\n# Proportional allocation (for comparison)\nstrata_data$proportional &lt;- round((strata_data$area_ha / sum(strata_data$area_ha)) * total_samples)\n\nprint(strata_data %&gt;% select(stratum, samples, proportional))\n\nOutput:\n            stratum  samples proportional\n1    Stable Forest      108          360\n2    Deforestation       60           4\n3      Degradation       86          12\n4 Stable Non-Forest       36          24\nKey insight: Neyman allocation dramatically increases sampling in rare but variable strata (deforestation, degradation), improving overall uncertainty.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Activity Data</span>"
    ]
  },
  {
    "objectID": "03-activity-data/index.html#sec-change-detection",
    "href": "03-activity-data/index.html#sec-change-detection",
    "title": "\n3  Activity Data\n",
    "section": "\n3.4 Land Change Uncertainty",
    "text": "3.4 Land Change Uncertainty\n\n3.4.1 Temporal Registration Error\nGeometric co-registration error propagates to change detection:\n\\[\nU_{change}^2 = U_{t1}^2 + U_{t2}^2 + 2 \\times U_{registration}^2\n\\]\nWhere: - \\(U_{t1}\\): Classification uncertainty at time 1 - \\(U_{t2}\\): Classification uncertainty at time 2\n- \\(U_{registration}\\): Positional error between dates\n\nlibrary(terra)\nlibrary(sf)\n\n# Simulate registration error\nsimulate_registration_error &lt;- function(raster_t1, raster_t2, error_pixels = 2) {\n  \n  # Original change map\n  change_original &lt;- raster_t2 - raster_t1\n  \n  # Apply random shift to t2 (simulating misregistration)\n  # Shift by 'error_pixels' in random direction\n  n_sim &lt;- 1000\n  change_error &lt;- numeric(n_sim)\n  \n  for (i in 1:n_sim) {\n    # Random shift direction\n    shift_x &lt;- sample(-error_pixels:error_pixels, 1)\n    shift_y &lt;- sample(-error_pixels:error_pixels, 1)\n    \n    # Shift raster_t2\n    raster_t2_shifted &lt;- shift(raster_t2, dx = shift_x, dy = shift_y)\n    \n    # Recalculate change\n    change_shifted &lt;- raster_t2_shifted - raster_t1\n    \n    # Calculate disagreement with original\n    disagreement &lt;- abs(change_shifted - change_original)\n    change_error[i] &lt;- global(disagreement, \"mean\", na.rm = TRUE)[1,1]\n  }\n  \n  return(list(\n    mean_error = mean(change_error),\n    sd_error = sd(change_error),\n    ci_90 = quantile(change_error, c(0.05, 0.95))\n  ))\n}\n\n# Example usage\n# registration_uncertainty &lt;- simulate_registration_error(forest_2010, forest_2020, error_pixels = 1)\n# print(paste(\"Registration error:\", round(registration_uncertainty$mean_error * 100, 2), \"%\"))\n\n\n3.4.2 Minimum Detectable Change\nStatistical power analysis for change detection:\n\\[\n\\text{MDD} = (Z_{\\alpha/2} + Z_{\\beta}) \\times \\sqrt{\\sigma_1^2 + \\sigma_2^2}\n\\]\nWhere: - MDD: Minimum detectable difference - \\(Z_{\\alpha/2}\\): Critical value for significance level (e.g., 1.645 for 90%) - \\(Z_{\\beta}\\): Critical value for power (e.g., 0.84 for 80% power) - \\(\\sigma_1, \\sigma_2\\): Standard deviations of measurements\n\n# Function to calculate MDD\ncalculate_mdd &lt;- function(sigma1, sigma2, alpha = 0.10, power = 0.80) {\n  \n  # Z-scores for significance and power\n  z_alpha &lt;- qnorm(1 - alpha/2)  # Two-tailed\n  z_beta &lt;- qnorm(power)\n  \n  # Pooled standard deviation\n  sigma_pooled &lt;- sqrt(sigma1^2 + sigma2^2)\n  \n  # Minimum detectable difference\n  mdd &lt;- (z_alpha + z_beta) * sigma_pooled\n  \n  return(list(\n    mdd = mdd,\n    mdd_relative = mdd / mean(c(sigma1, sigma2)) * 100,\n    z_alpha = z_alpha,\n    z_beta = z_beta\n  ))\n}\n\n# Example: Forest cover change detection\n# Assuming 5% uncertainty in each time period\nmdd_forest &lt;- calculate_mdd(sigma1 = 5, sigma2 = 5, alpha = 0.10, power = 0.80)\n\ncat(sprintf(\"Minimum detectable change: %.2f%% (absolute)\\n\", mdd_forest$mdd))\ncat(sprintf(\"Relative to mean uncertainty: %.1f%%\\n\", mdd_forest$mdd_relative))\n\nOutput:\nMinimum detectable change: 11.66% (absolute)\nRelative to mean uncertainty: 233.1%\nInterpretation: With 5% classification uncertainty at each date, changes &lt;11.66% cannot be detected with statistical confidence. This sets a minimum mapping unit for credible change detection.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Activity Data</span>"
    ]
  },
  {
    "objectID": "03-activity-data/index.html#sec-spatial-aggregation",
    "href": "03-activity-data/index.html#sec-spatial-aggregation",
    "title": "\n3  Activity Data\n",
    "section": "\n3.5 Spatial Aggregation Uncertainty",
    "text": "3.5 Spatial Aggregation Uncertainty\n\n3.5.1 Pixel Area Projection\nChallenge: Pixel area varies with latitude in most projections\nSolution: Calculate pixel-specific area weights\n\nlibrary(terra)\nlibrary(sf)\n\n# Function to calculate true pixel area accounting for projection\ncalculate_pixel_areas &lt;- function(raster_template) {\n  \n  # Get cell size in map units\n  cell_size &lt;- res(raster_template)\n  \n  # Get latitudes of cell centers\n  coords &lt;- xyFromCell(raster_template, 1:ncell(raster_template))\n  lats &lt;- coords[, 2]\n  \n  # Earth's radius (meters)\n  earth_radius &lt;- 6371000\n  \n  # Convert degrees to radians\n  lat_rad &lt;- lats * pi / 180\n  \n  # Calculate north-south distance (constant)\n  ns_distance &lt;- earth_radius * (cell_size[2] * pi / 180)\n  \n  # Calculate east-west distance (varies with latitude)\n  ew_distance &lt;- earth_radius * cos(lat_rad) * (cell_size[1] * pi / 180)\n  \n  # Pixel area in hectares\n  pixel_area_ha &lt;- (ns_distance * ew_distance) / 10000\n  \n  # Create raster of pixel areas\n  area_raster &lt;- raster_template\n  values(area_raster) &lt;- pixel_area_ha\n  \n  return(area_raster)\n}\n\n# Calculate total forest area with area correction\ncalculate_forest_area &lt;- function(forest_raster, area_raster) {\n  \n  # Forest pixels (value = 1)\n  forest_pixels &lt;- forest_raster == 1\n  \n  # Multiply by pixel-specific areas\n  forest_area_map &lt;- forest_pixels * area_raster\n  \n  # Sum to get total area\n  total_area_ha &lt;- global(forest_area_map, \"sum\", na.rm = TRUE)[1,1]\n  \n  # Also calculate assuming uniform pixel size (uncorrected)\n  nominal_pixel_area &lt;- prod(res(forest_raster)) / 10000  # ha\n  uncorrected_area_ha &lt;- sum(values(forest_pixels), na.rm = TRUE) * nominal_pixel_area\n  \n  return(list(\n    corrected_area_ha = total_area_ha,\n    uncorrected_area_ha = uncorrected_area_ha,\n    difference_pct = (uncorrected_area_ha - total_area_ha) / total_area_ha * 100\n  ))\n}\n\n# Example\n# area_raster &lt;- calculate_pixel_areas(forest_2020)\n# forest_area &lt;- calculate_forest_area(forest_2020, area_raster)\n# cat(sprintf(\"Area correction: %.2f%% difference\\n\", forest_area$difference_pct))\n\nTypical magnitude: 0.5-2% for tropical projects (near equator), up to 5-10% for boreal projects (high latitudes).\n\n3.5.2 Zonal Statistics\nEdge effects at jurisdictional boundaries:\n\nlibrary(exactextractr)\nlibrary(sf)\nlibrary(terra)\n\n# Function to assess boundary uncertainty\nassess_boundary_uncertainty &lt;- function(raster_data, boundary_polygon, buffer_m = 100) {\n  \n  # Original zonal statistic\n  original_sum &lt;- exact_extract(\n    raster_data, \n    boundary_polygon, \n    fun = 'sum'\n  )\n  \n  # Create multiple buffered boundaries (simulate positional uncertainty)\n  n_sim &lt;- 100\n  buffered_sums &lt;- numeric(n_sim)\n  \n  for (i in 1:n_sim) {\n    # Random buffer (-buffer_m to +buffer_m)\n    random_buffer &lt;- runif(1, -buffer_m, buffer_m)\n    \n    # Apply buffer\n    buffered_boundary &lt;- st_buffer(boundary_polygon, dist = random_buffer)\n    \n    # Recalculate sum\n    buffered_sums[i] &lt;- exact_extract(\n      raster_data,\n      buffered_boundary,\n      fun = 'sum'\n    )\n  }\n  \n  # Calculate uncertainty\n  boundary_uncertainty &lt;- sd(buffered_sums) / mean(buffered_sums) * 100\n  \n  return(list(\n    original_value = original_sum,\n    mean_simulated = mean(buffered_sums),\n    sd_simulated = sd(buffered_sums),\n    uncertainty_pct = boundary_uncertainty,\n    ci_90 = quantile(buffered_sums, c(0.05, 0.95))\n  ))\n}\n\n# Example usage\n# boundary_uncert &lt;- assess_boundary_uncertainty(\n#   raster_data = forest_cover,\n#   boundary_polygon = project_boundary,\n#   buffer_m = 50  # 50m positional uncertainty\n# )\n# print(paste(\"Boundary uncertainty:\", round(boundary_uncert$uncertainty_pct, 2), \"%\"))\n\nMitigation strategies: - Use high-precision GPS for boundary demarcation (±5m accuracy) - Apply buffer zones to exclude edge pixels - Document boundary uncertainty in monitoring plan",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Activity Data</span>"
    ]
  },
  {
    "objectID": "03-activity-data/index.html#sec-reference-data",
    "href": "03-activity-data/index.html#sec-reference-data",
    "title": "\n3  Activity Data\n",
    "section": "\n3.6 Reference Data Quality",
    "text": "3.6 Reference Data Quality\n\n3.6.1 Required Sample Size\nObjective: Determine validation sample size for desired confidence interval\nFormula (simple random sampling):\n\\[\nn = \\frac{Z^2 \\times p \\times (1-p)}{E^2}\n\\]\nWhere: - \\(n\\): Required sample size - \\(Z\\): Z-score for confidence level (1.645 for 90%) - \\(p\\): Expected proportion (e.g., 0.50 for maximum variance) - \\(E\\): Desired margin of error (e.g., 0.05 for ±5%)\n\n# Function to calculate sample size\ncalculate_sample_size &lt;- function(confidence = 0.90, margin_error = 0.05, proportion = 0.50) {\n  \n  # Z-score for confidence level\n  z_score &lt;- qnorm(1 - (1 - confidence) / 2)\n  \n  # Calculate sample size\n  n &lt;- (z_score^2 * proportion * (1 - proportion)) / margin_error^2\n  \n  # Round up\n  n_rounded &lt;- ceiling(n)\n  \n  return(list(\n    sample_size = n_rounded,\n    confidence = confidence,\n    margin_error = margin_error,\n    z_score = z_score\n  ))\n}\n\n# Calculate for different scenarios\nscenarios &lt;- expand.grid(\n  confidence = c(0.90, 0.95),\n  margin_error = c(0.03, 0.05, 0.10),\n  proportion = 0.50\n)\n\nscenarios$required_n &lt;- apply(scenarios, 1, function(x) {\n  calculate_sample_size(\n    confidence = x[1],\n    margin_error = x[2],\n    proportion = x[3]\n  )$sample_size\n})\n\nlibrary(knitr)\nkable(\n  scenarios,\n  col.names = c(\"Confidence\", \"Margin of Error\", \"Proportion\", \"Sample Size\"),\n  caption = \"Required Validation Sample Sizes\"\n)\n\nOutput:\n| Confidence | Margin of Error | Proportion | Sample Size |\n|------------|-----------------|------------|-------------|\n| 90%        | 3%              | 0.50       | 752         |\n| 90%        | 5%              | 0.50       | 271         |\n| 90%        | 10%             | 0.50       | 68          |\n| 95%        | 3%              | 0.50       | 1068        |\n| 95%        | 5%              | 0.50       | 385         |\n| 95%        | 10%             | 0.50       | 97          |\nPractical guidance: - Minimum: 100 samples per class for rare categories - Typical: 300-500 samples for overall accuracy ±5% at 90% confidence - Optimal: 1000+ samples for detecting &lt;2% changes\n\n3.6.2 Temporal Consistency\nChallenge: Reference imagery date ≠ classification date\nAcceptable lag: ±1 year for stable landscapes, ±6 months for dynamic areas\n\n# Simulate accuracy degradation with temporal lag\nassess_temporal_lag &lt;- function(base_accuracy = 0.92, lag_months = seq(0, 24, 6), degradation_rate = 0.01) {\n  \n  # Accuracy decreases with lag\n  accuracy_lagged &lt;- base_accuracy * exp(-degradation_rate * lag_months)\n  \n  # Create results table\n  lag_results &lt;- data.frame(\n    lag_months = lag_months,\n    accuracy = accuracy_lagged,\n    accuracy_loss = (base_accuracy - accuracy_lagged) / base_accuracy * 100\n  )\n  \n  return(lag_results)\n}\n\n# Calculate temporal lag effects\nlag_impact &lt;- assess_temporal_lag(base_accuracy = 0.92, lag_months = seq(0, 24, 6))\n\n# Visualize\nlibrary(ggplot2)\nggplot(lag_impact, aes(x = lag_months, y = accuracy)) +\n  geom_line(color = \"darkred\", size = 1.2) +\n  geom_point(size = 3) +\n  geom_hline(yintercept = 0.90, linetype = \"dashed\", color = \"blue\") +\n  annotate(\"text\", x = 12, y = 0.905, label = \"90% threshold\", color = \"blue\") +\n  labs(\n    title = \"Classification Accuracy vs. Reference Data Temporal Lag\",\n    x = \"Lag (months)\",\n    y = \"Classification Accuracy\"\n  ) +\n  theme_minimal()\n\nMitigation: - Use near-contemporary reference data (±6 months) - Apply phenological normalization - Document and report temporal lag in uncertainty assessment",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Activity Data</span>"
    ]
  },
  {
    "objectID": "03-activity-data/index.html#sec-ad-integrated-workflow",
    "href": "03-activity-data/index.html#sec-ad-integrated-workflow",
    "title": "\n3  Activity Data\n",
    "section": "\n3.7 Reproducible Workflow",
    "text": "3.7 Reproducible Workflow\n\n3.7.1 Monte Carlo Implementation\n\n# =============================================================================\n# INTEGRATED ACTIVITY DATA UNCERTAINTY ASSESSMENT\n# Combines: Classification + Change Detection + Spatial Aggregation\n# =============================================================================\n\nlibrary(tidyverse)\nlibrary(MASS)  # For mvrnorm\n\n# Function: Integrated uncertainty assessment\nintegrated_activity_data_uncertainty &lt;- function(\n  confusion_matrix,\n  area_t1_ha,\n  area_t2_ha,\n  registration_error_m = 30,\n  pixel_size_m = 30,\n  n_sim = 10000\n) {\n  \n  # Extract classification uncertainties\n  conf_table &lt;- confusion_matrix$table\n  producers_acc &lt;- diag(conf_table) / colSums(conf_table)\n  \n  # Calculate classification CV (coefficient of variation)\n  cv_classification &lt;- sqrt((1 - producers_acc) / producers_acc)\n  \n  # Registration error as proportion of pixel\n  cv_registration &lt;- registration_error_m / pixel_size_m\n  \n  # Monte Carlo simulation\n  sim_results &lt;- matrix(NA, nrow = n_sim, ncol = 3)\n  colnames(sim_results) &lt;- c(\"area_t1\", \"area_t2\", \"change\")\n  \n  for (i in 1:n_sim) {\n    # Sample classification uncertainty (lognormal to ensure positive)\n    error_t1 &lt;- rnorm(1, mean = 0, sd = area_t1_ha * mean(cv_classification))\n    error_t2 &lt;- rnorm(1, mean = 0, sd = area_t2_ha * mean(cv_classification))\n    \n    # Sample registration error\n    error_reg &lt;- rnorm(1, mean = 0, sd = mean(c(area_t1_ha, area_t2_ha)) * cv_registration)\n    \n    # Simulate areas\n    sim_area_t1 &lt;- area_t1_ha + error_t1\n    sim_area_t2 &lt;- area_t2_ha + error_t2 + error_reg\n    \n    # Calculate change\n    sim_change &lt;- sim_area_t2 - sim_area_t1\n    \n    sim_results[i, ] &lt;- c(sim_area_t1, sim_area_t2, sim_change)\n  }\n  \n  # Calculate statistics\n  results_summary &lt;- data.frame(\n    parameter = c(\"Area_t1\", \"Area_t2\", \"Change\"),\n    mean = colMeans(sim_results),\n    sd = apply(sim_results, 2, sd),\n    ci_lower = apply(sim_results, 2, quantile, 0.05),\n    ci_upper = apply(sim_results, 2, quantile, 0.95)\n  ) %&gt;%\n    mutate(\n      cv_pct = sd / mean * 100,\n      hw_90 = (ci_upper - ci_lower) / 2,\n      uncertainty_pct = hw_90 / mean * 100\n    )\n  \n  return(list(\n    summary = results_summary,\n    simulations = sim_results\n  ))\n}\n\n# Example usage\n# Load confusion matrix (from previous section)\n# conf_matrix &lt;- [your confusion matrix]\n\n# Run integrated assessment\nuncertainty_results &lt;- integrated_activity_data_uncertainty(\n  confusion_matrix = conf_matrix,\n  area_t1_ha = 100000,  # Initial forest area\n  area_t2_ha = 95000,   # Final forest area\n  registration_error_m = 30,\n  pixel_size_m = 30,\n  n_sim = 10000\n)\n\n# Display results\nprint(uncertainty_results$summary)\n\n# Visualize uncertainty distribution\nlibrary(ggplot2)\ndata.frame(change = uncertainty_results$simulations[, \"change\"]) %&gt;%\n  ggplot(aes(x = change)) +\n  geom_histogram(bins = 50, fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(xintercept = mean(uncertainty_results$simulations[, \"change\"]),\n             color = \"red\", size = 1, linetype = \"dashed\") +\n  geom_vline(xintercept = uncertainty_results$summary$ci_lower[3],\n             color = \"darkred\", size = 0.8, linetype = \"dotted\") +\n  geom_vline(xintercept = uncertainty_results$summary$ci_upper[3],\n             color = \"darkred\", size = 0.8, linetype = \"dotted\") +\n  labs(\n    title = \"Activity Data Uncertainty: Forest Area Change\",\n    subtitle = sprintf(\"Mean: %.0f ha (90%% CI: %.0f - %.0f ha)\",\n                      uncertainty_results$summary$mean[3],\n                      uncertainty_results$summary$ci_lower[3],\n                      uncertainty_results$summary$ci_upper[3]),\n    x = \"Change in Forest Area (ha)\",\n    y = \"Frequency\"\n  ) +\n  theme_minimal()",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Activity Data</span>"
    ]
  },
  {
    "objectID": "03-activity-data/index.html#sec-ad-art-trees",
    "href": "03-activity-data/index.html#sec-ad-art-trees",
    "title": "\n3  Activity Data\n",
    "section": "\n3.8 ART-TREES Compliance",
    "text": "3.8 ART-TREES Compliance\n\n3.8.1 Documentation\nMonitoring Plan must include:\n\nClassification methodology:\n\n\nAlgorithm (Random Forest, SVM, CNN, etc.)\nTraining data sample size and distribution\nAccuracy assessment protocol\n\n\nValidation approach:\n\n\nSample design (stratified random, systematic)\nSample size justification (power analysis)\nReference data sources and dates\n\n\nUncertainty quantification:\n\n\nMonte Carlo simulation specification (n=10,000)\nError propagation methods\nConfidence interval calculation\n\n\nQuality assurance:\n\n\nIndependent verification of classifications\nCross-validation results\nTemporal consistency checks\n\n3.8.2 Reporting Format\nCRF Table: Activity Data Uncertainty",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Activity Data</span>"
    ]
  },
  {
    "objectID": "03-activity-data/index.html#sec-ad-summary",
    "href": "03-activity-data/index.html#sec-ad-summary",
    "title": "\n3  Activity Data\n",
    "section": "\n3.9 Next Steps & Notes",
    "text": "3.9 Next Steps & Notes\n\n3.9.1 Critical Success Factors\nFor &lt;10% activity data uncertainty: 1. Overall classification accuracy &gt;90% 2. Validation sample size &gt;400 points 3. Stratified sampling for rare classes 4. Geometric co-registration &lt;1 pixel 5. Reference data temporal lag &lt;6 months\nFor 10-20% uncertainty (acceptable Tier 2): - Overall accuracy 85-90% - Validation samples 200-400 - Registration &lt;2 pixels\nFor &gt;20% uncertainty (Tier 1, high deductions): - Overall accuracy &lt;85% - Inadequate validation - Significant temporal/spatial misalignment\n\n3.9.2 Next Chapter\nChapter 2: Allometry Uncertainty will address:\n\nModel selection: Geographic transferability, species specificity\nParameter estimation: Regression uncertainty, prediction intervals\nMeasurement error: DBH precision, height bias, wood density variability\nBias correction: Log-transformation, non-linear models\n\nCritical linkage: Activity data provides spatial extent; allometry converts that extent to biomass. Combined uncertainty:\n\\[\nU_{total}^2 = U_{activity}^2 + U_{allometry}^2 + 2 \\times \\text{Cov}(A, B)\n\\]\nNext steps: Quantify allometric uncertainty to enable full error propagation in Chapter 4.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Activity Data</span>"
    ]
  },
  {
    "objectID": "03-activity-data/index.html#sec-ad-references",
    "href": "03-activity-data/index.html#sec-ad-references",
    "title": "\n3  Activity Data\n",
    "section": "\n3.10 References",
    "text": "3.10 References\nOlofsson, P., Foody, G.M., Herold, M., Stehman, S.V., Woodcock, C.E., & Wulder, M.A. (2014). Good practices for estimating area and assessing accuracy of land change. Remote Sensing of Environment, 148, 42-57.\nStehman, S.V. (2014). Estimating area and map accuracy for stratified random sampling when the strata are different from the map classes. International Journal of Remote Sensing, 35(13), 4923-4939.\nPontius Jr., R.G., & Millones, M. (2011). Death to Kappa: birth of quantity disagreement and allocation disagreement for accuracy assessment. International Journal of Remote Sensing, 32(15), 4407-4429.\nGFOI (2016). Integration of remote-sensing and ground-based observations for estimation of emissions and removals of greenhouse gases in forests: Methods and Guidance from the Global Forest Observations Initiative. Edition 2.0. Rome: Food and Agriculture Organization.\nGOFC-GOLD (2016). A sourcebook of methods and procedures for monitoring and reporting anthropogenic greenhouse gas emissions and removals associated with deforestation, gains and losses of carbon stocks in forests remaining forests, and forestation. GOFC-GOLD Report version COP22-1. Alberta, Canada: GOFC-GOLD Land Cover Project Office.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Activity Data</span>"
    ]
  },
  {
    "objectID": "references/index.html",
    "href": "references/index.html",
    "title": "Appendix A — References",
    "section": "",
    "text": "Aholoukpè, H. N. S., Dubos, B., Deleporte, P., Flori, A., Amadji, L. G.,\nChotte, J.-L., & Blavet, D. (2018). Allometric equations for\nestimating oil palm stem biomass in the ecological context of benin,\nwest africa. Trees, 32(6), 1669–1680.\n\n\nAllen, M. R., Frame, D. J., Friedlingstein, P., Gillett, N. P., Grassi,\nG., Gregory, J. M., Hare, W., House, J., Huntingford, C., Jenkins, S.,\n& al., et. (2025). Geological net zero and the need for\ndisaggregated accounting for carbon sinks. Nature,\n638(8050), 343–350.\n\n\nAndersen, H.-E., Reutebuch, S. E., & McGaughey, R. J. (2006). A\nrigorous assessment of tree height measurements obtained using airborne\nlidar and conventional field methods. Canadian Journal of Remote\nSensing, 32(5), 355–366. https://doi.org/10.5589/m06-030\n\n\nAragão, L. E., Anderson, L. O., Fonseca, M. G., Rosan, T. M., Vedovato,\nL. B., Wagner, F. H., Silva, C. V., Silva Junior, C. H., Arai, E.,\nAguiar, A. P., & al., et. (2018). 21st century drought-related fires\ncounteract the decline of amazon deforestation carbon emissions.\nNature Communications, 9(1), 536.\n\n\nART. (2021). The REDD+ environmental excellence standard (2.0\ned.). https://www.artredd.org/wp-content/uploads/2021/12/TREES-2.0-August-2021-Clean.pdf\n\n\nBaskerville, G. (1972). Use of logarithmic regression in the estimation\nof plant biomass. Canadian Journal of Forest Research,\n2(1), 49–53.\n\n\nBrando, P. M., Balch, J. K., Nepstad, D. C., Morton, D. C., Putz, F. E.,\nCoe, M. T., Silvério, D., Macedo, M. N., Davidson, E. A., Nóbrega, C.\nC., & al., et. (2014). Abrupt increases in amazonian tree mortality\ndue to drought–fire interactions. Proceedings of the National\nAcademy of Sciences, 111(17), 6347–6352.\n\n\nButler, B. J., Sass, E. M., Gamarra, J. G., Campbell, J. L., Wayson, C.,\nOlguıń, M., Carrillo, O., & Yanai, R. D. (2024). Uncertainty in\nREDD+ carbon accounting: A survey of experts involved in REDD+\nreporting. Carbon Balance and Management, 19(1), 22.\n\n\nCamara, G., Simoes, R., Souza, F., Menino, F., Pelletier, C., Andrade,\nP. R., Ferreira, K., & Queiroz, G. (2024). Uncertainty and active\nlearning analysis. In Satellite time series on earth observation\ndata cubes. https://e-sensing.github.io/sitsbook/uncertainty-and-active-learning.html#uncertainty-and-active-learning\n\n\nCanadell, J. G., Le Quéré, C., Raupach, M. R., Field, C. B., Buitenhuis,\nE. T., Ciais, P., Conway, T. J., Gillett, N. P., Houghton, R., &\nMarland, G. (2007). Contributions to accelerating atmospheric CO2 growth\nfrom economic activity, carbon intensity, and efficiency of natural\nsinks. Proceedings of the National Academy of Sciences,\n104(47), 18866–18870.\n\n\nChen, Q., Laurin, G. V., & Valentini, R. (2015). Uncertainty of\nremotely sensed aboveground biomass over an african tropical forest:\nPropagating errors from trees to plots to pixels. Remote Sensing of\nEnvironment, 160, 134–143. https://doi.org/10.1016/j.rse.2015.01.009\n\n\nCiais, P., Reichstein, M., Viovy, N., Granier, A., Ogée, J., Allard, V.,\nAubinet, M., Buchmann, N., Bernhofer, C., Carrara, A., & al., et.\n(2005). Europe-wide reduction in primary productivity caused by the heat\nand drought in 2003. Nature, 437(7058), 529–533.\n\n\nClifford, D., Cressie, N., England, J. R., Roxburgh, S. H., & Paul,\nK. I. (2013). Correction factors for unbiased, efficient estimation and\nprediction of biomass from log–log allometric models. Forest Ecology\nand Management, 310, 375–381. https://doi.org/10.1016/j.foreco.2013.08.041\n\n\nDuncanson, L., Disney, M., Armston, J., Nickeson, J., Minor, D., &\nCamacho, F. (2021). Aboveground woody biomass product validation\ngood practices protocol. https://doi.org/10.5067/DOC/CEOSWGCV/LPV/AGB.001\n\n\nDuncanson, L., Huang, W., Johnson, K., Swatantran, A., McRoberts, R. E.,\n& Dubayah, R. (2017). Implications of allometric model selection for\ncounty-level biomass mapping. Carbon Balance and Management,\n12(1), 18.\n\n\nDuncanson, L., Rourke, O., & Dubayah, R. (2015). Small sample sizes\nyield biased allometric equations in temperate forests. Scientific\nReports, 5(1), 17153.\n\n\nDutcă, I., Stăncioiu, P. T., Abrudan, I. V., & Ioraș, F. (2018).\nUsing clustered data to develop biomass allometric models: The\nconsequences of ignoring the clustered data structure. PloS\nOne, 13(8), e0200123.\n\n\nGenet, H., He, Y., Lyu, Z., McGuire, A. D., Zhuang, Q., Clein, J.,\nD’Amore, D., Bennett, A., Breen, A., Biles, F., & al., et. (2018).\nThe role of driving factors in historical and projected carbon dynamics\nof upland ecosystems in alaska. Ecological Applications,\n28(1), 5–27.\n\n\nGrassi, G., House, J., Kurz, W. A., Cescatti, A., Houghton, R. A.,\nPeters, G. P., Sanz, M. J., Viñas, R. A., Alkama, R., Arneth, A., &\nal., et. (2018). Reconciling global-model estimates and country\nreporting of anthropogenic forest CO2 sinks. Nature Climate\nChange, 8(10), 914–920.\n\n\nHenttonen, H. M., Nöjd, P., & Mäkinen, H. (2017).\nEnvironment-induced growth changes in the finnish forests during\n1971–2010–an analysis based on national forest inventory. Forest\nEcology and Management, 386, 22–36.\n\n\nHoldaway, R. J., McNeill, S. J., Mason, N. W. H., & Carswell, F. E.\n(2014). Propagating uncertainty in plot-based estimates of forest carbon\nstock and carbon stock change. Ecosystems (New York, N.Y.),\n17(ue 4), 627–640. https://doi.org/10.1007/s10021-014-9749-5\n\n\nIPCC. (2006). Chapter 1: introduction. In 2006 IPCC guidelines for\nnational greenhouse gas inventories (Vol. 4). Intergovernmental\nPanel on Climate Change. https://www.ipcc-nggip.iges.or.jp/public/2006gl/pdf/4_Volume4/V4_01_Ch1_Introduction.pdf\n\n\nIPCC. (2010). Revisiting the use of managed land as a proxy for\nestimating national anthropogenic emissions and removals.\nIntergovernmental Panel on Climate Change. https://www.ipcc-nggip.iges.or.jp/public/mtdocs/pdfiles/0905_MLP_Report.pdf\n\n\nIPCC. (2019a). 2019 refinement to the 2006 IPCC guidelines for\nnational greenhouse gas inventories (Agriculture, Forestry and\nOther Land Use, Vol. 4). Intergovernmental Panel on Climate Change. https://www.ipcc-nggip.iges.or.jp/public/2019rf/vol4.html\n\n\nIPCC. (2019b). Chapter 2: Generic methodologies applicable to multiple\nland-use categories. In 2019 refinement to the 2006 IPCC guidelines\nfor national greenhouse gas inventories (Agriculture, Forestry and\nOther Land Use, Vol. 4). Intergovernmental Panel on Climate Change. https://www.ipcc-nggip.iges.or.jp/public/2019rf/pdf/4_Volume4/19R_V4_Ch02_Generic%20Methods.pdf\n\n\nIPCC. (2019c). Chapter 2: Generic methodologies applicable to multiple\nland-use categories. In 2019 refinement to the 2006 IPCC guidelines\nfor national greenhouse gas inventories (Agriculture, Forestry and\nOther Land Use, Vol. 4). Intergovernmental Panel on Climate Change. https://www.ipcc-nggip.iges.or.jp/public/2019rf/pdf/4_Volume4/19R_V4_Ch02_Generic%20Methods.pdf\n\n\nKeller, M., Palace, M., & Hurtt, G. (2001). Biomass estimation in\nthe tapajos national forest, brazil. Forest Ecology and\nManagement, 154(ue 3), 371–382.\n\n\nKöhler, P., & Huth, A. (2010). Towards ground-truthing of spaceborne\nestimates of above-ground life biomass and leaf area index in tropical\nrain forests. Biogeosciences (Online), 7(8),\n2531–2543.\n\n\nKurz, W., Hayne, S., Fellows, M., MacDonald, J., Metsaranta, J., Hafer,\nM., & Blain, D. (2018). Quantifying the impacts of human activities\non reported greenhouse gas emissions and removals in canada’s managed\nforest: Conceptual framework and implementation. Canadian Journal of\nForest Research, 48(10), 1227–1240.\n\n\nMartin, A. (2022). Accuracy and precision in urban forestry tools for\nestimating total tree height. Arboric. Urban For,\n48(6), 319–332.\n\n\nMartı́nez-Sánchez, J. L., Martı́nez-Garza, C., Cámara, L., & Castillo,\nO. (2020). Species-specific or generic allometric equations: Which\noption is better when estimating the biomass of mexican tropical humid\nforests? Carbon Management, 11(3), 241–249.\n\n\nMcRoberts, R. E., & Westfall, J. A. (2016). Propagating uncertainty\nthrough individual tree volume model predictions to large-area volume\nestimates. Annals of Forest Science, 73(ue 3),\n625–633. https://doi.org/10.1007/s13595-015-0473-x\n\n\nMiller, J. D., Skinner, C., Safford, H., Knapp, E. E., & Ramirez, C.\n(2012). Trends and causes of severity, size, and number of fires in\nnorthwestern california, USA. Ecological Applications,\n22(1), 184–203.\n\n\nMolto, Q., Rossi, V., & Blanc, L. (2013). Error propagation in\nbiomass estimation in tropical forests. Methods in Ecology and\nEvolution, 4(ue 2), 175–183. https://doi.org/10.1111/j.2041-210x.2012.00266.x\n\n\nNickless, A., Scholes, R. J., & Archibald, S. (2011). A method for\ncalculating the variance and confidence intervals for tree biomass\nestimates obtained from allometric equations. South African Journal\nof Science, 107(5), 1–10.\n\n\nOjoatre, S., Zhang, C., Hussin, Y. A., Kloosterman, H. E., & Ismail,\nM. H. (2019). Assessing the uncertainty of tree height and aboveground\nbiomass from terrestrial laser scanner and hypsometer using airborne\nLiDAR data in tropical rainforests. IEEE Journal of Selected Topics\nin Applied Earth Observations and Remote Sensing, 12(10),\n4149–4159.\n\n\nParresol, B. R. (1993). Modeling multiplicative error variance: An\nexample predicting tree diameter from stump dimensions in baldcypress.\nForest Science, 39(4), 670–679.\n\n\nPaul, K. I., Roxburgh, S. H., & Larmour, J. S. (2017). Moisture\ncontent correction: Implications of measurement errors on tree-and\nsite-based estimates of biomass. Forest Ecology and Management,\n392, 164–175.\n\n\nPelletier, J., Martin, D., & Potvin, C. (2013). REDD+ emissions\nestimation and reporting: Dealing with uncertainty. Environmental\nResearch Letters, 8(3), 034009.\n\n\nPicard, N., Bosela, F. B., & Rossi, V. (2015). Reducing the error in\nbiomass estimates strongly depends on model selection. Annals of\nForest Science, 72(6), 811–823. https://doi.org/10.1007/s13595-014-0434-9\n\n\nPilli, R., Grassi, G., Kurz, W. A., Viñas, R. A., & Guerrero, N. H.\n(2016). Modelling forest carbon stock changes as affected by harvest and\nnatural disturbances. I. Comparison with countries’ estimates for forest\nmanagement. Carbon Balance and Management, 11(1), 5.\n\n\nPloton, P., Mortier, F., Réjou-Méchain, M., Barbier, N., Picard, N.,\nRossi, V., Dormann, C., Cornu, G., Viennois, G., Bayol, N., & al.,\net. (2020). Spatial validation reveals poor predictive performance of\nlarge-scale ecological mapping models. Nature Communications,\n11(1), 4540.\n\n\nRoxburgh, S., Paul, K., Clifford, D., England, J., & Raison, R.\n(2015). Guidelines for constructing allometric models for the prediction\nof woody biomass: How many individuals to harvest? Ecosphere\n(Washington, D.C), 6(3), 1–27.\n\n\nShang, Y., Xia, Y., Ran, X., Zheng, X., Ding, H., & Fang, Y. (2025).\nAllometric equations for aboveground biomass estimation in natural\nforest trees: Generalized or species-specific? Diversity,\n17(7), 493.\n\n\nSheng, J., Zhou, W., & De Sherbinin, A. (2018). Uncertainty in\nestimates, incentives, and emission reductions in REDD+ projects.\nInternational Journal of Environmental Research and Public\nHealth, 15(7), 1544.\n\n\nSimoes, R., Camara, G., Queiroz, G., Souza, F., Andrade, P. R., Santos,\nL., Carvalho, A., & Ferreira, K. (2021). Satellite image time series\nanalysis for big earth observation data. Remote Sensing,\n13(13), 2428.\n\n\nStinson, G., Magnussen, S., Moudewyn, P., Eichel, F., Russo, G., Cranny,\nM., & Song, A. (2016). Canada. In National forest inventories:\nAssessment of wood availability and use. https://doi.org/10.1007/978-3-319-44015-6\n\n\nSt-Onge, B., Treitz, P., Wulder, M., Kurz, W., & Gillis, M. (2004).\nRetrospective mapping of structural and biomass changes in forest\necosystems using photogrammetry and laser altimetry. AGU Spring\nMeeting Abstracts, 2004, B21B–04.\n\n\nVetter, M., Churkina, G., Jung, M., Reichstein, M., Zaehle, S., Bondeau,\nA., Chen, Y., Ciais, P., Feser, F., Freibauer, A., & al., et.\n(2008). Analyzing the causes and spatial pattern of the european 2003\ncarbon flux anomaly using seven models. Biogeosciences\n(Online), 5(2), 561–583.\n\n\nVorster, A. G., Evangelista, P. H., Stovall, A. E., & Ex, S. (2020).\nVariability and uncertainty in forest biomass estimates from the tree to\nlandscape scale: The role of allometric equations. Carbon Balance\nand Management, 15(1), 8.\n\n\nWayson, C. A., Johnson, K. D., Cole, J. A., Olguı́n, M. I., Carrillo, O.\nI., & Birdsey, R. A. (2015). Estimating uncertainty of allometric\nbiomass equations with incomplete fit error information using a\npseudo-data approach: methods. Annals of Forest Science,\n72(6), 825–834.\n\n\nWhite, G. W., Yamamoto, J. K., Elsyad, D. H., Schmitt, J. F., Korsgaard,\nN. H., Hu, J. K., Gaines III, G. C., Frescino, T. S., & McConville,\nK. S. (2025). Small area estimation of forest biomass via a two-stage\nmodel for continuous zero-inflated data. Canadian Journal of Forest\nResearch, 55, 1–19.\n\n\nYanai, R. D., Battles, J. J., Richardson, A. D., Blodgett, C. A., Wood,\nD. M., & Rastetter, E. B. (2010). Estimating uncertainty in\necosystem budget calculations. Ecosystems (New York, N.Y.),\n13(ue 2), 239–248. https://doi.org/10.1007/s10021-010-9315-8\n\n\nZapata-Cuartas, M., Sierra, C. A., & Alleman, L. (2012). Probability\ndistribution of allometric coefficients and bayesian estimation of\naboveground tree biomass. Forest Ecology and Management,\n277, 173–179.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>References</span>"
    ]
  },
  {
    "objectID": "references/glossary.html",
    "href": "references/glossary.html",
    "title": "Appendix B — Glossary & Addendum",
    "section": "",
    "text": "Modelling vs. Recurring Sources\nFramework from (pelletier2024bayesian?) distinguishes temporal behavior:\nSource Type\nDefinition\nExamples\nTypical Magnitude\nModelling sources\nModel parameters & assumptions\nFallow classification, growth rates\n4-262% (highest)\nRecurring sources\nMeasurement errors\nActivity data, emission factors\n30-50%\nModelling sources vs. recurring sources of uncertainty\n“The highest error propagated using Monte Carlo simulations was caused by modelling sources of uncertainty, which calls for special attention to ensure consistency in REDD+ reporting which is essential for securing environmental integrity.” (pelletier2024bayesian?)\nStrategic implication: Modelling sources can be standardized across jurisdictions (one-time investment), while recurring sources require continuous monitoring (ongoing costs).\nSensitivity Analysis Framework\nSobol indices identify variance contributions:\nFirst-order effects (Si): Direct contribution\nTotal effects (STi): Direct + interactions\nTypical results: Activity data (Si = 0.42) &gt;&gt; Biomass (0.31) &gt;&gt; Combustion factor (0.18) &gt;&gt; Emission factor (0.03)\nComplementary methods:\nPartial correlation coefficients\nTornado diagrams for parameter ranking\nPanama case study (pelletier2024bayesian?): Fallow classification and carbon accumulation = highest sensitivity\nOptimization Strategies\nInvestment hierarchy (based on Sobol indices + cost):\nIntervention\nVariance Reduced\nCost\nROI Tier\nPriority\nActivity data QA/QC\n42% → 30% (12 pp)\n$30-50k\nVery High\n1\nEnhanced plot sampling\n31% → 20% (11 pp)\n$50-100k\nHigh\n2\nTier 2 allometry\n31% → 22% (9 pp)\n$15-30k\nVery High\n3\nGround Cf measurement\n18% → 12% (6 pp)\n$20-40k\nModerate\n4\nFTIR emission factors\n3% → 2% (1 pp)\n$50-100k\nVery Low\n5\nCost-benefit ranking for uncertainty reduction (Chapter 4 detail)\nTemporal aggregation provision:\n5-year recalculation: Aggregate uncertainty across crediting period\nRecovery mechanism: Over-deducted credits issued if cumulative uncertainty decreases\nTypical benefit: 5-10 percentage point reduction from temporal averaging\nExample: Individual-year deductions = 492,500 t CO2; Aggregated = 406,700 t CO2 → Recovery: 85,800 t CO2\nSoftware Systems\nAll analyses in this book use R (≥4.2.0) with the following packages:\nCore packages:\n\nC Statistical analysis\nlibrary(MASS) # Multivariate normal sampling library(boot) # Bootstrap resampling library(caret) # Cross-validation\n\n\nD Monte Carlo simulation\nlibrary(mc2d) # Two-dimensional Monte Carlo library(sensitivity) # Sobol sensitivity analysis\n\n\nE Visualization\nlibrary(ggplot2) # Publication-quality graphics library(plotly) # Interactive plots\nSpecialized packages:\n\n\nF Allometry\nlibrary(BIOMASS) # Pantropical allometric equations library(allodb) # Global allometry database\n\n\nG Spatial analysis\nlibrary(terra) # Raster processing library(sf) # Vector spatial data library(exactextractr) # Zonal statistics\n\n\nH Reporting\nlibrary(knitr) # Dynamic documents library(rmarkdown) # Report generation\nKey Terminology\nPrecision vs. Accuracy:\nPrecision: Reproducibility of measurements (random error)\nAccuracy: Closeness to true value (systematic bias)\nConfidence intervals:\n90% CI: Range containing true value with 90% probability\nHalf-width: Distance from mean to CI bound = (Upper - Lower) / 2\nError types:\nType 1: False rejection of null hypothesis (α error)\nType 2: False acceptance of null hypothesis (β error)\nType 3: Solving the wrong problem (asking the wrong question)\nType 4: Applying results outside valid domain (extrapolation)\nIPCC Tiers:\nTier 1: IPCC default methods and parameters\nTier 2: Country-specific methods or parameters\nTier 3: Higher-order methods (models, repeated measurements)\nLULC Approaches:\nApproach 1: Total area change (no spatial data)\nApproach 2: Tracking of land-use conversions (transition matrices)\nApproach 3: Spatially explicit tracking (wall-to-wall maps)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Glossary & Addendum</span>"
    ]
  }
]